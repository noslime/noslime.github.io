<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>MySQL 索引</title>
      <link href="articles/2021/2341110601.html"/>
      <url>articles/2021/2341110601.html</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL-索引简介"><a href="#MySQL-索引简介" class="headerlink" title="MySQL 索引简介"></a>MySQL 索引简介</h1><h2 id="什么是索引"><a href="#什么是索引" class="headerlink" title="什么是索引"></a>什么是索引</h2><ul><li>官方定义：一种帮助MySQL提高查询效率的数据结构</li><li>索引数据结构：MySQL中索引的存储类型有两种：BTREE和HASH，具体和表的而存储引擎相关：MyINSAM和InnoDB存储引擎只支持BETREE索引；MEMEORY/HEAP 存储引擎可以支持HASH和BTREE索引。</li><li>索引的优点：<ol><li>大大加速数据查询速度，也是创建索引的主要原因。</li><li>加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义</li><li>使用分组和排序子句进行数据查询时，显著减少查询中分组和排序的时间。</li></ol></li><li>索引的缺点：<ol><li>维护索引需要耗费数据库资源</li><li>索引需要占用磁盘空间</li><li>会降低更新表的速度，因为要维护索引，增加了数据得维护速度。</li></ol></li></ul><h2 id="索引的分类"><a href="#索引的分类" class="headerlink" title="索引的分类"></a>索引的分类</h2><ul><li><p>主键索引</p><p>设定为主键后数据库会==自动==创建索引，innodb为聚簇索引，不能有空值。是一种特殊的唯一索引。</p></li><li><p>普通索引</p><p>即一个索引只包含单个列，一个表中可以有多个普通索引，允许空值与重复值。</p></li><li><p>唯一索引</p><p>索引列的值必须唯一，但允许有空值</p></li><li><p>组合索引</p><p>即一个索引包含多个列</p></li><li><p>全文索引（5.7之前只有MyISAM引擎支持，自5.7版本开始，InnoDB也支持了）</p><p>全文索引类型为FULLTEXT，在定音索引的列上支持值得全文索引，允许这些索引列中插入重复值和空值。全文索引可以在char、varchar、text类型列上创建。MySQL只有MYISAM引擎支持全文索引。</p></li><li><p>空间索引</p><p>空间索引是对空间数据类型的字段建立的索引，MySQL种的空间类型有4种，分别是：GEOMETRY、POINT、LINESTRING和POLYGON。MySQL使用SAPTIAL关键字进行扩展。空间索引的列必须声明为NOT NULL。</p></li></ul><h2 id="索引的基本操作"><a href="#索引的基本操作" class="headerlink" title="索引的基本操作"></a>索引的基本操作</h2><h3 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h3><h4 id="创建表的时候创建索引"><a href="#创建表的时候创建索引" class="headerlink" title="创建表的时候创建索引"></a>创建表的时候创建索引</h4><ul><li><p>基本语法格式</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> table_name <span class="token punctuation">[</span>col_name data_type<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token keyword">UNIQUE</span><span class="token operator">|</span>FULLTEXT<span class="token operator">|</span>SPATIAL<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token keyword">INDEX</span><span class="token operator">|</span><span class="token keyword">KEY</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>index_name<span class="token punctuation">]</span><span class="token punctuation">(</span>col_name<span class="token punctuation">[</span>length<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">[</span><span class="token keyword">ASC</span><span class="token operator">|</span><span class="token keyword">DESC</span><span class="token punctuation">]</span></code></pre><p>其中UNIQUE、FULLTEXT、SAPTIAL为可选参数，分别表示唯一索引、全文索引和空间索引；INDEX和KEY为同义词，作用相同，用来指定创建索引；index_name指定索引的名称，为可选参数，若不指定，则默认col_name为索引值；col_name为需要创建索引的字段列；length为可选参数，表示索引的长度，只有字符串类型的字段才能指定索引的长度；ASC或DESC指定升序或者降序的索引值存储。</p></li><li><p>示例</p><ol><li><p>创建普通索引</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token punctuation">`</span>t_user01<span class="token punctuation">`</span> <span class="token punctuation">(</span>  <span class="token punctuation">`</span>id<span class="token punctuation">`</span> <span class="token keyword">int</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token punctuation">`</span>NAME<span class="token punctuation">`</span> <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token keyword">KEY</span><span class="token punctuation">(</span><span class="token punctuation">`</span>NAME<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">ENGINE</span><span class="token operator">=</span><span class="token keyword">InnoDB</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARSET</span><span class="token operator">=</span>utf8<span class="token punctuation">;</span></code></pre></li><li><p>创建唯一索引</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token punctuation">`</span>t_user02<span class="token punctuation">`</span> <span class="token punctuation">(</span>  <span class="token punctuation">`</span>ID<span class="token punctuation">`</span> <span class="token keyword">int</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token punctuation">`</span>NAME<span class="token punctuation">`</span> <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token keyword">UNIQUE</span> <span class="token keyword">KEY</span> <span class="token punctuation">`</span>UniqIdx<span class="token punctuation">`</span> <span class="token punctuation">(</span><span class="token punctuation">`</span>ID<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">ENGINE</span><span class="token operator">=</span><span class="token keyword">InnoDB</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARSET</span><span class="token operator">=</span>utf8<span class="token punctuation">;</span></code></pre></li><li><p>创建组合索引</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token punctuation">`</span>t_user03<span class="token punctuation">`</span> <span class="token punctuation">(</span>  <span class="token punctuation">`</span>id<span class="token punctuation">`</span> <span class="token keyword">int</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token punctuation">`</span>name<span class="token punctuation">`</span> char<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token punctuation">`</span>age<span class="token punctuation">`</span> <span class="token keyword">int</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token punctuation">`</span>info<span class="token punctuation">`</span> <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span> <span class="token keyword">DEFAULT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token keyword">KEY</span> <span class="token punctuation">`</span>MultiIdx<span class="token punctuation">`</span> <span class="token punctuation">(</span><span class="token punctuation">`</span>id<span class="token punctuation">`</span><span class="token punctuation">,</span><span class="token punctuation">`</span>name<span class="token punctuation">`</span><span class="token punctuation">,</span><span class="token punctuation">`</span>age<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">ENGINE</span><span class="token operator">=</span><span class="token keyword">InnoDB</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARSET</span><span class="token operator">=</span>utf8<span class="token punctuation">;</span></code></pre><p>注意：组合索引遵循左前缀原则，并且mysql引擎在查询为了更好利用索引，查询过程会动态调整查询字段顺序以便利用索引。</p></li><li><p>创建全文索引</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token punctuation">`</span>t_user04<span class="token punctuation">`</span> <span class="token punctuation">(</span>  <span class="token punctuation">`</span>id<span class="token punctuation">`</span> <span class="token keyword">int</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token punctuation">`</span>name<span class="token punctuation">`</span> char<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token punctuation">`</span>age<span class="token punctuation">`</span> <span class="token keyword">int</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  <span class="token punctuation">`</span>info<span class="token punctuation">`</span> <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">)</span> <span class="token keyword">DEFAULT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  FULLTEXT <span class="token keyword">KEY</span> <span class="token punctuation">`</span>FullTxtIdx<span class="token punctuation">`</span> <span class="token punctuation">(</span><span class="token punctuation">`</span>info<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">ENGINE</span><span class="token operator">=</span><span class="token keyword">InnoDB</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARSET</span><span class="token operator">=</span>utf8<span class="token punctuation">;</span></code></pre></li><li><p>创建空间索引</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token punctuation">`</span>t_space<span class="token punctuation">`</span> <span class="token punctuation">(</span>  <span class="token punctuation">`</span>p<span class="token punctuation">`</span> <span class="token keyword">point</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>  SPATIAL <span class="token keyword">KEY</span> <span class="token punctuation">`</span>spatIdx<span class="token punctuation">`</span> <span class="token punctuation">(</span><span class="token punctuation">`</span>p<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">ENGINE</span><span class="token operator">=</span><span class="token keyword">InnoDB</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARSET</span><span class="token operator">=</span>utf8<span class="token punctuation">;</span></code></pre></li></ol></li></ul><h4 id="在已存在的表上创建索引"><a href="#在已存在的表上创建索引" class="headerlink" title="在已存在的表上创建索引"></a>在已存在的表上创建索引</h4><ul><li><p>使用<a href="https://dev.mysql.com/doc/refman/5.7/en/alter-table.html">ALTER语句</a>创建</p><ul><li><p>语法格式</p><pre class=" language-text"><code class="language-text">ALTER TABLE tbl_nameADD &#123;UNIQUE | FULLTEXT | SPATIAL&#125; [INDEX | KEY] [index_name]        (key_part,...) [index_option] ...</code></pre></li><li><p>示例</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> t_user01 <span class="token keyword">ADD</span> <span class="token keyword">KEY</span><span class="token punctuation">(</span><span class="token punctuation">`</span>name<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> t_user02 <span class="token keyword">ADD</span> <span class="token keyword">UNIQUE</span> <span class="token keyword">KEY</span> <span class="token punctuation">`</span>UniqIdx<span class="token punctuation">`</span><span class="token punctuation">(</span><span class="token punctuation">`</span>ID<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> t_user03 <span class="token keyword">ADD</span> <span class="token keyword">KEY</span> <span class="token punctuation">`</span>MultiIdx<span class="token punctuation">`</span><span class="token punctuation">(</span><span class="token punctuation">`</span>id<span class="token punctuation">`</span><span class="token punctuation">,</span><span class="token punctuation">`</span>name<span class="token punctuation">`</span><span class="token punctuation">,</span><span class="token punctuation">`</span>age<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> t_user04 <span class="token keyword">ADD</span> FULLTEXT <span class="token keyword">KEY</span> <span class="token punctuation">`</span>FullTxtIdx<span class="token punctuation">`</span> <span class="token punctuation">(</span><span class="token punctuation">`</span>info<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> t_space <span class="token keyword">ADD</span> SAPTIAL <span class="token keyword">KEY</span> <span class="token punctuation">`</span>spatIdx<span class="token punctuation">`</span> <span class="token punctuation">(</span><span class="token punctuation">`</span>p<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></li></ul></li></ul><ul><li><p>使用<a href="https://dev.mysql.com/doc/refman/5.7/en/create-index.html">CREATE语句</a>创建</p><ul><li><p>语法格式</p><pre class=" language-text"><code class="language-text">CREATE [UNIQUE | FULLTEXT | SPATIAL] INDEX index_name    [index_type]    ON tbl_name (key_part,...)    [index_option]    [algorithm_option | lock_option] ...</code></pre></li><li><p>示例</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> <span class="token punctuation">`</span>name<span class="token punctuation">`</span> <span class="token keyword">ON</span> t_user01<span class="token punctuation">(</span><span class="token punctuation">`</span>name<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">CREATE</span> <span class="token keyword">UNIQUE</span> <span class="token keyword">INDEX</span> <span class="token punctuation">`</span>UniqIdx<span class="token punctuation">`</span> <span class="token keyword">ON</span> t_user02<span class="token punctuation">(</span><span class="token punctuation">`</span>ID<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> <span class="token punctuation">`</span>MultiIdx<span class="token punctuation">`</span> <span class="token keyword">ON</span> t_user03<span class="token punctuation">(</span><span class="token punctuation">`</span>id<span class="token punctuation">`</span><span class="token punctuation">,</span><span class="token punctuation">`</span>name<span class="token punctuation">`</span><span class="token punctuation">,</span><span class="token punctuation">`</span>age<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">CREATE</span> FULLTEXT <span class="token keyword">INDEX</span> <span class="token punctuation">`</span>FullTxtIdx<span class="token punctuation">`</span> <span class="token keyword">ON</span> t_user04<span class="token punctuation">(</span><span class="token punctuation">`</span>info<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">CREATE</span> SAPTIAL <span class="token keyword">INDEX</span> <span class="token punctuation">`</span>spatIdx<span class="token punctuation">`</span> <span class="token keyword">ON</span> t_space<span class="token punctuation">(</span><span class="token punctuation">`</span>p<span class="token punctuation">`</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></li></ul></li></ul><h3 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h3><p>删除索引语法格式如下</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">DROP</span> <span class="token keyword">INDEX</span> index_name<span class="token punctuation">;</span><span class="token keyword">DROP</span> <span class="token keyword">INDEX</span> index_name <span class="token keyword">on</span> table_name<span class="token punctuation">;</span></code></pre><h2 id="索引数据结构"><a href="#索引数据结构" class="headerlink" title="索引数据结构"></a>索引数据结构</h2><p>​    考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助。</p><p>​    而在MySQL数据库中一页一般为16kb，MySQL基于页的形式进行索引的管理，结构大致如下图所示，这种数据结构叫做<strong>B+Tree</strong>，B+Tree只有叶子存储实际数据信息，其他节点只存储键值信息，大大降低了树的高度，从而减少了磁盘IO的次数。</p><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/mysql_index01.png"></p><p>​                                                                                图 一</p><p>InnoDB存储引擎中页的大小为16KB，一般若表的主键类型为INT（4个字节）或BIGINT（8个字节），指针类型也一般为4或8个字节，也就是说一个叶节点中大概存储16KB/(8B+8B)=1K个键值，若数据记录为也为16B，则一个深度为3的B+Tree索引理论上可以维护<code>10^3*10^3*500</code>=5亿条记录。因而在数据库中，B+Tree的高度一般都在2~4层，而MySQL的InnoDB存储引擎在在设计时是将<strong>根节点常驻内存</strong>的，也就是说，查找某一键值的行记录最多只需要1~3次IO操作。</p><p>所以一般来说，普通项目B+Tree的高度2层基本够用了。</p><h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><h4 id="B-树的概念简介"><a href="#B-树的概念简介" class="headerlink" title="B-树的概念简介"></a>B-树的概念简介</h4><p>B-树是一种多路平衡查找树。每一个节点最多包含K个孩子，而K又被称为是B树的阶。这个阶取决于磁盘页大小。它类似普通的平衡二叉树，不同的一点是B-树允许每个节点有更多的子节点。</p><h4 id="B-同B-树的不同"><a href="#B-同B-树的不同" class="headerlink" title="B+同B-树的不同"></a>B+同B-树的不同</h4><p>B+树是B-树的变体，也是一种多路搜索树, 它与 B- 树的不同之处在于:</p><ol><li><p>非叶子节点只存储键值信息，数据记录都存放在叶子节点中</p></li><li><p>为所有叶子结点增加了一个链指针</p></li><li><p>B+树只有在叶子节点才会存在数据，所以同样的情况下，一次性能够放入更多的数据进入内存，因此减少了磁盘io，效率更高些。</p></li><li><p>B+树内节点不存储数据，所有 data 存储在叶节点导致查询时间复杂度固定为 log n。而B-树查询时间复杂度不固定，与 key 在树中的位置有关，最好为O(1)。</p></li></ol><h2 id="聚簇索引与非聚簇索引"><a href="#聚簇索引与非聚簇索引" class="headerlink" title="聚簇索引与非聚簇索引"></a>聚簇索引与非聚簇索引</h2><p>聚簇索引：将数据存储与索引放到了一块，索引结构的==叶子节点保存了数据==。</p><p>非聚簇索引：将数据与索引分开存储，索引结构的叶子节点指向了数据所在的位置。</p><blockquote><p>​    在innodb中，在聚簇索引之上创建的索引称之为辅助索引，<strong>非聚簇索引都是辅助索引</strong>，像复合索引、前缀索引、唯一索引。辅助索引叶子节点存储的不再是行的位置，而是主键值，辅助索引访问数据总是需要二次查找。</p></blockquote><ol><li>InnoDB</li></ol><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/2106131655_mysql_index.png"></p><p>​                                                                        图 二  InnoDB 索引检索过程</p><p>如图二所示，InnoDB 默认使用主键作为聚簇索引，如果直接通过主键检索数据，只需检索一次即可获取数据；若通过辅助索引进行检索数据，则要多上一个步骤：即先在辅助索引中检索到树的主键，然后根据主键去主键索引中查找真正数据所在。</p><p>在InnoDB中，主键默认是聚簇索引，若没有指定主键，则会选择一个非空且唯一的索引代替。如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。如果已经设置了主键为聚簇索引有希望再单独设置聚簇索引，必须先删除主键，添加后，再恢复主键。</p><ol start="2"><li>MyISAM</li></ol><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/2106131718_mysql_index.png"></p><p>​                                                图三  MyISAM 索引检索过程</p><p>MyISAM使用的是非聚簇索引，如图三所示，主键索引与辅助索引结构一致，存储的只是数据的地址，而数据存储在专门的位置，所以访问没有区别。</p><h3 id="聚簇索引的优势"><a href="#聚簇索引的优势" class="headerlink" title="聚簇索引的优势"></a>聚簇索引的优势</h3><ol><li>由于行数据和聚簇索引的叶子节点存储在一起，同一页有多条数据，访问同一页数据不同记录时，由于已经加载到缓存中了，直接在内存中拿即可，访问速度更快。</li><li>当行数据发生变化时，索引树的节点也需要分裂变化；或者发生新的IO读数据时，可以避免对辅助索引的维护工作。另外辅助索引放地主键值比放地址更省空间。</li></ol><h3 id="使用聚簇索引需要注意什么"><a href="#使用聚簇索引需要注意什么" class="headerlink" title="使用聚簇索引需要注意什么"></a>使用聚簇索引需要注意什么</h3><ol><li>最好不要使用UUID作为主键，因为太过离散，且可能出现新增加的uuid插入到树的中间，导致索引树调整的复杂度增大。</li><li>建议使用int类型的自增，方便排序，并且默认会在索引树的末尾增加主键值，对索引树结构影响最小。且主键值越大，辅助索引保存的也要跟着增大。</li><li>其中主键自增的好处是，只要索引是相邻的，那么数据一般也在磁盘上相邻。避免了不必要的调整物理地址，分页等，总之就是磁盘碎片化低。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis 配置文件</title>
      <link href="articles/2020/0302061712.html"/>
      <url>articles/2020/0302061712.html</url>
      
        <content type="html"><![CDATA[<p>本文总结下redis常用配置项, 现在软件开发中好多技术都是约定先于配置，而配置又大于编码。而想要掌握一门技术，掌握其配置文件是极其必要的。同时在实际生产环境中，正确的配置往往可以大大提高系统的可用性。</p><hr><h2 id="配置简介"><a href="#配置简介" class="headerlink" title="配置简介"></a>配置简介</h2><p>Redis可以在没有配置文件的情况下通过内置的配置来启动，但是这种启动方式只适用于开发和测试。合理的配置Redis的方式是提供一个Redis配置文件，这个文件通常叫做 <code>redis.conf</code>，一般就在Redis安装目录下。 </p><p>对于配置文件的修改配置，除手动修改配置文件外，从Redis 2.8开始，可以使用<a href="https://redis.io/commands/config-rewrite">CONFIG REWRITE</a>，它会自动扫描redis.conf版归档并更新与当前配置值不匹配的字段。不添加不存在但设置为默认值的字段。配置文件中的注释将被保留。</p><p>以下为<strong>6.0</strong>版本的配置文件概览（依据配置块在配置文件中出现先后排序）</p><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/REDIS-CONFIG.png" alt="图一"></p><h2 id="配置块介绍"><a href="#配置块介绍" class="headerlink" title="配置块介绍"></a>配置块介绍</h2><p>Redis完整的配置文件（6.0版本）正如图一所示大致可以分为24部分，本文将根据复杂度，与本人理解详细介绍一部分，有些配置可能会一笔带过。开始之前，先介绍下redis的单位表示，其中符号对大小写不敏感</p><pre class=" language-text"><code class="language-text">1k => 1000 bytes1kb => 1024 bytes1m => 1000000 bytes1mb => 1024*1024 bytes1g => 1000000000 bytes1gb => 1024*1024*1024 bytes</code></pre><h3 id="Redis-INCLUDES"><a href="#Redis-INCLUDES" class="headerlink" title="Redis INCLUDES"></a>Redis INCLUDES</h3><p><strong>1、INCLUDE</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：配置文件所在位置</p></li><li><p>说明：Redis可以包含进来其他的配置文件片段，其中Redis指令后出现的会覆盖先出现的指令，所以可以根据需要选择include块所在的位置。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">include /path/to/local.confinclude /path/to/other.conf</code></pre></li></ul><h3 id="Redis-MODULES"><a href="#Redis-MODULES" class="headerlink" title="Redis MODULES"></a>Redis MODULES</h3><p><strong>1、loadmodule</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：加载功能模块文件的具体位置</p></li><li><p>说明：Redis 模块功能通过使用外部模块来扩展 Redis 功能，Redis可以根据需要在启动时加载模块。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">loadmodule /path/to/my_module.soloadmodule /path/to/other_module.so</code></pre></li></ul><h3 id="Redis-NETWORK"><a href="#Redis-NETWORK" class="headerlink" title="Redis NETWORK"></a>Redis NETWORK</h3><p><strong>1、bind</strong> </p><ul><li><p>默认：<code>127.0.0.1</code></p></li><li><p>取值：本机网卡所在的IP地址，其中两个特殊值<code>127.0.0.1</code>代表只能本机访问，<code>0.0.0.0</code>代表本机所有地址</p></li><li><p>说明：绑定指令设置redis接受请求来源于哪个网络接口（网卡），可以绑定多个。若不设置则来自任意网络接口的请求均可访问。默认设置为只能本机访问。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text"># 本机访问bind 127.0.0.1# 全都能访问bind 0.0.0.0</code></pre></li><li><p>补充：由于redis侧重点在于性能响应速度，此配置并不能细粒度地控制外网指定IP访问，只能设置本机能访问或全部都能访问。若要设置指定IP，可通过添加防火墙规则进行控制</p><pre class=" language-shell"><code class="language-shell">firewall-cmd  --add-rich-rule="rule family="ipv4" source address="192.168.1.25" port protocol="tcp" port="80" accept" --permanentsystemctl restart firewalld.service</code></pre></li></ul><p><strong>2、protected-mode</strong></p><ul><li><p>默认：yes 即开启</p></li><li><p>取值：yes 或 no</p></li><li><p>说明：保护模式默认是开启的，但只有没有绑定网络接口，而且没有设置访问密码的情况下，保护模式才发挥效用</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">protected-mode yes</code></pre></li></ul><p><strong>3、port</strong></p><ul><li><p>默认：6379</p></li><li><p>取值：1024 - 65535之间的可用端口即可</p></li><li><p>顾名思义，即redis对外提供服务的端口号</p><pre class=" language-text"><code class="language-text">port 6379</code></pre></li></ul><p><strong>4、tcp-backlog</strong></p><ul><li><p>默认：511</p></li><li><p>取值：合适的队列长度即可</p></li><li><p>说明：此参数用来配置完成tcp三次握手队列的长度，用于应对高并发的环境，虽然默认设置为511，但会受到Linux内核参数somaxconn的限制。若不进行修改，redis启动会有以下警告，提示该参数未发挥作用</p><pre class=" language-text"><code class="language-text">WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.</code></pre><p>可以手动修改somaxconn的值，以使配置生效</p><p><em>临时设置</em>：</p><p><code>echo 1024 &gt; /proc/sys/net/core/somaxconn </code></p><p><em>永久设置</em>：</p><p>在<code>/etc/sysctl.conf</code>中添加一行配置：<code>net.core.somaxconn = 1024</code></p><p>然后执行命令<code>sysctl -p</code>，使之永久生效</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">tcp-backlog 511</code></pre></li></ul><p><strong>5、unixsocket</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：redis sock文件的存储位置</p></li><li><p>说明：默认redis的连接方式是TCP，我们还可以让 Redis 以 Unix Socket 的方式运行，以避免 TCP/IP 的性能瓶颈，在高访问场景往往能够实现不错的性能提升。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">unixsocket /tmp/redis.sock</code></pre></li></ul><p><strong>6、unixsocketperm</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：linux权限码</p></li><li><p>说明：Unix socket文件的权限</p><pre class=" language-text"><code class="language-text">unixsocketperm 700</code></pre></li></ul><p><strong>7、timeout</strong></p><ul><li><p>默认：0 </p></li><li><p>取值：一个合适的整数值</p></li><li><p>说明：客户端空闲时，是否设置超时时间，0表示不设置。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text"># Close the connection after a client is idle for N seconds (0 to disable)timeout 0</code></pre></li></ul><p><strong>8、tcp-keepalive</strong></p><ul><li><p>默认：300</p></li><li><p>取值：一个合适的整数值</p></li><li><p>设置redis客户端tcp的保活时间，在指定时间内会一直探测连接是否存活，官方建议300.</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">tcp-keepalive 300</code></pre></li></ul><h3 id="Redis-TLS-SSL"><a href="#Redis-TLS-SSL" class="headerlink" title="Redis TLS/SSL"></a>Redis TLS/SSL</h3><p>配置redis加密传输，此部分需要掌握SSL协议，熟悉对称与非对称加解密算法等。详细可见<a href="https://redis.io/topics/encryption">encryption</a>，文档描写的很详细。</p><h3 id="Redis-GENERAL"><a href="#Redis-GENERAL" class="headerlink" title="Redis GENERAL"></a>Redis GENERAL</h3><p>redis的通用模块</p><p><strong>1、daemonize</strong></p><ul><li><p>默认：no</p></li><li><p>取值：yes|no</p></li><li><p>说明：redis服务默认是运行在前台的，可以通过设置让他以守护进程运行在后台。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">daemonize yes</code></pre></li></ul><p><strong>2、supervisor</strong></p><ul><li><p>默认：no</p></li><li><p>取值：no|upstart|systemd|auto</p></li><li><p>说明：设置redis进程管理程序，可选项有<code>upstart</code> 和<code>systemd</code>以及根据系统环境自动检测，默认关闭。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">supervised no</code></pre></li></ul><p><strong>3、pidfile</strong></p><ul><li><p>默认：<code>/var/run/redis_6379.pid</code></p></li><li><p>取值：pid文件的具体位置</p></li><li><p>说明：进程id文件所在位置。如果指定，服务启动时创建，停止时销毁。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">pidfile /var/run/redis_6379.pid</code></pre></li></ul><p><strong>4、loglevel</strong></p><ul><li><p>默认： notice</p></li><li><p>取值：debug|verbose|notice|warning</p></li><li><p>说明：redis服务日志的级别，以上四个取值日志详实度从左到右递减，一般生产环境，notice即可。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">loglevel notice</code></pre></li></ul><p><strong>5、logfile</strong></p><ul><li><p>默认：””</p></li><li><p>取值：日志文件的位置</p></li><li><p>说明：日志文件的名称，可以带有绝对路径</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text"> logfile "/var/log/redis/redis.log"</code></pre></li></ul><p><strong>6、syslog-enabled</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：yes|no</p></li><li><p>说明：是否将日志记录进系统日志</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">syslog-enabled no</code></pre></li></ul><p><strong>7、syslog-ident</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：系统日志标识ID，一般为应用程序名称</p></li><li><p>说明：指定系统日志标识。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">syslog-ident redis</code></pre></li></ul><p><strong>8、syslog-facility</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：Must be USER or between LOCAL0-LOCAL7</p></li><li><p>说明：指定redis系统日志的设备</p></li><li><p>示例</p><pre class=" language-text"><code class="language-text">syslog-facility local0</code></pre></li></ul><p><strong>9、databases</strong></p><ul><li><p>默认：16</p></li><li><p>取值：合适的整数</p></li><li><p>说明：redis数据库的数量，默认16个，一般一个业务用一个库。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">databases 16</code></pre></li></ul><p><strong>10、always-show-logo</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：是否在redis启动时显示logo艺术字，只有输出到标准输出时才显示。</p></li><li><p>示例：</p><pre><code>always-show-logo yes</code></pre></li></ul><h3 id="Redis-SNAPSHOTTING"><a href="#Redis-SNAPSHOTTING" class="headerlink" title="Redis SNAPSHOTTING"></a>Redis SNAPSHOTTING</h3><p>redis快照部分</p><p><strong>1、save</strong></p><ul><li><p>默认：</p><pre class=" language-text"><code class="language-text">save 900 1save 300 10save 60 10000</code></pre></li><li><p>取值：save seconds changes</p></li><li><p>说明：保存redis数据快照的策略，第一个参数为时间，单位为秒，第二个参数为key更新的次数，默认设置即为900秒内有一个键更新，则触发建立快照；300秒内有10个键值更新，触发建立快照；60秒内10000个键值更新，触发建立快照。若要禁用快照功能，save设空字符串即可。</p></li><li><p>示例即默认</p></li></ul><p><strong>2、stop-writes-on-bgsave-error</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：是否停止写RDB文件，在后台发生错误后。若设置为yes则发生错误后，只有重新启动后，才会重新开启写操作。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">stop-writes-on-bgsave-error yes</code></pre></li></ul><p><strong>3、rdbcompression</strong></p><ul><li><p>默认： yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：是否需要压缩RDB快照文件，默认使用<code>LAF</code>算法进行压缩。</p></li><li><p>示例：</p><pre><code>rdbcompression yes</code></pre></li></ul><p><strong>4、rdbchecksum</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：redis 5以后的版本允许在RDB快照文件尾部加入一个<code>CRC64</code>校验和, 用以防止文件损坏，提高可靠性。但会消耗10%左右的性能。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">rdbchecksum yes</code></pre></li></ul><p><strong>5、dbfilename</strong> </p><ul><li><p>默认：dump.rdb</p></li><li><p>取值：自己定义的快照文件名称</p></li><li><p>说明：快照文件的名称</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">dbfilename dump.rdb</code></pre></li></ul><p><strong>6、rdb-del-sync-files</strong></p><ul><li><p>默认：no</p></li><li><p>取值：yes | no</p></li><li><p>说明：在没有启用持久性的实例中删除复制使用的RDB文件。默认情况下，此选项处于禁用状态。请注意，此选项仅适用于同时禁用AOF与RDB持久性的情况，否则将完全忽略</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">rdb-del-sync-files no</code></pre></li></ul><p><strong>7、dir</strong></p><ul><li><p>默认：./</p></li><li><p>取值：一个目录的路径</p></li><li><p>说明：快照文件RDB，与AOF文件都会存储在这里</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">dir ./</code></pre></li></ul><h3 id="Redis-REPLICATION"><a href="#Redis-REPLICATION" class="headerlink" title="Redis REPLICATION"></a>Redis REPLICATION</h3><p>redis 主从复制部分</p><p><strong>1、replicaof</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：masterip masterport</p></li><li><p>说明：配置该redis数据库主机IP与端口号</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">replicaof 127.0.0.1 6380</code></pre></li></ul><p><strong>2、masterauth</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：主机需要的认证密码</p></li><li><p>说明：如果在主从复制的主机上设置了<code>requirepass</code>，从机在此处必须设置正确才能完成同步的请求获得数据。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">masterauth master-password</code></pre></li></ul><p><strong>3、masteruser</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：用户名</p></li><li><p>说明：如果在redis 6以后的版本中使用了<a href="https://redis.io/topics/acl">ACLs</a>，仅仅设置上个配置项中的访问密码不够，还需要设置访问的用户，即本设置项的作用。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">masteruser username</code></pre></li></ul><p><strong>4、replica-serve-stale-data</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：如果设置为是的话，则从机会一直回复客户端的请求，哪怕数据过期，或者返回一个空串当第一次同步的时候；如果设置为否的话，绝大部分命令请求会直接返回客户端错误信息<strong>SYNC with master in progress</strong>，除了：<code>INFO, REPLICAOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG, SUBSCRIBE,UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB, COMMAND, POST, HOST and LATENCY</code>这些命令。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">replica-serve-stale-data yes</code></pre></li></ul><p><strong>5、replica-read-only</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：设置从机是否只读</p></li><li><p>示例</p><pre class=" language-text"><code class="language-text">replica-read-only yes</code></pre></li></ul><p><strong>6、repl-diskless-sync</strong></p><ul><li><p>默认：no</p></li><li><p>取值：yes | no</p></li><li><p>说明：新增从机或从机恢复连接时，需要一次向主机完全同步的请求。而主机应对这种请求，有两种策略：一种是先写到硬盘上，然后传输到指定从机，适合多个从机同时请求；另一种则是无盘传输，这种适合慢硬盘，大带宽的情形，后来的请求需要进入队列。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">repl-diskless-sync no</code></pre></li></ul><p><strong>7、repl-diskless-sync-delay</strong></p><ul><li><p>默认：5</p></li><li><p>取值：整数，单位为秒</p></li><li><p>说明：主机部分设置，当无盘传输一旦开始的情况下，主服务器不能为新的从机提供服务，因此服务器会设置一个等待延时，以便让更多从机加入。</p></li><li><p>示例</p><pre><code>repl-diskless-sync-delay 5</code></pre></li></ul><p><strong>8、repl-diskless-load</strong></p><ul><li><p>默认：disabled</p></li><li><p>取值：disabled | on-empty-db |swapdb</p></li><li><p>说明：从机部分设置，当主机开始无盘传输时，我们可以选择，先保存到本地完整的RDB快照文件，然后再同步；或者只有当从机数据为空时，直接读取同步；或者先将完整的RDB快照保存到内存中，只有当主机传输完毕时，再从内存同步完整的快照。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">repl-diskless-load disabled</code></pre></li></ul><p><strong>9、repl-ping-replica-period</strong></p><ul><li><p>默认：10</p></li><li><p>取值： 合适的时间间隔，单位秒</p></li><li><p>说明：从机周期性PING主机的时间间隔，定期检查主机状态。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">repl-ping-replica-period 3</code></pre></li></ul><p><strong>10、repl-timeout</strong></p><ul><li><p>默认：60</p></li><li><p>取值：时间，单位为秒</p></li><li><p>说明：主备同步的超时时间</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">repl-timeout 60</code></pre></li></ul><p><strong>11、repl-disable-tcp-nodelay</strong></p><ul><li><p>默认：no</p></li><li><p>取值：yes | no</p></li><li><p>说明：是否开启主从机器简单tcp延时，默认不开启，适合主从机间通信良好，最好在同一机房。而当网络高负荷，主从机再不同机房时，可以开启。降低传输频率。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">repl-disable-tcp-nodelay no</code></pre></li></ul><p><strong>12、repl-backlog-size</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：累计缓存大小，单位mb</p></li><li><p>说明：复制缓冲区大小，这是一个环形复制缓冲区，用来保存最新复制的命令。当redis存在从机时，若从机断开连接，重新连接时不一定需要进行全量同步。设置了累计缓存大小后，从机首先获取累计缓存，进行部分同步。若部分同步不能解决问题，再进行全量同步。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">repl-baklog-size 1mb</code></pre></li></ul><p><strong>13、repl-backlog-ttl</strong> </p><ul><li><p>默认：未配置</p></li><li><p>取值：合适的正整数，单位秒</p></li><li><p>说明：复制缓冲区的过期时间，0表示永不释放这块的内存。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">repl-backlog-ttl 3600</code></pre></li></ul><p><strong>14、replica-priority</strong> </p><ul><li><p>默认：100</p></li><li><p>取值：一个整数</p></li><li><p>说明：从机的优先级，数字越小，优先级越高。例如有三个从机优先级分别为10，25，100，则再主机不可用后，redis通过哨兵机制，选择优先为10的从机顶替主机。 其中特殊值 0 代表永不能成为主机。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">replica-priority 100</code></pre></li></ul><p><strong>15、min-replicas-to-write  &amp; min-replicas-max-lag</strong></p><ul><li><p>默认： min-replicas-to-write 0   min-replicas-max-lag 10</p></li><li><p>取值：均为一个整数值，前者单位为个，后者为秒</p></li><li><p>说明：这两条配置限制主机是否继续接受写命令，前者表示最少的从机节点为几个，后者表示根据从副本接收的最后一次ping计算的延迟时间。只有存在符合延迟时间的指定个数的健康从机，主机才继续写命令。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">min-replicas-to-write 3min-replicas-max-lag 10</code></pre></li></ul><p><strong>16、replica-announce-ip  &amp; replica-announce-port</strong></p><ul><li><p>默认： 未配置</p></li><li><p>取值： 前者为IP地址，后者为端口号</p></li><li><p>说明： 当从及IP及端口固定时，从机上报的IP与端口号，供哨兵发现各个从机。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">replica-announce-ip 192.168.0.20replica-announce-port 6379</code></pre></li></ul><h3 id="Redis-KEYS-TRACKING"><a href="#Redis-KEYS-TRACKING" class="headerlink" title="Redis KEYS TRACKING"></a>Redis KEYS TRACKING</h3><p>Redis辅助支持的客户端缓存，详情可见<a href="https://redis.io/topics/client-side-caching">Redis server-assisted client side caching</a></p><p><strong>1、tracking-table-max-keys</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：缓存键的数量</p></li><li><p>说明：redis可以帮助实现客户端缓存，并维持一个无效表，用以跟踪键值，当键值改变时，通知客户端重新获取，而此参数定义无效表的大小。需要注意的是，若使用的是广播模式的键值追踪，则此参数无效。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">tracking-table-max-keys 1000000</code></pre></li></ul><h3 id="Redis-SECURITY"><a href="#Redis-SECURITY" class="headerlink" title="Redis SECURITY"></a>Redis SECURITY</h3><p>Redis安全模块，由于Redis速度很快，外部用户可以尝试 每秒100万个密码。这意味着你应该使用很强的密码，否则很容易被破解。 请注意，因为密码实际上是客户端与服务器之间的共享机密，不应该被任何人记住密码可以是/dev/urandom中的一个长字符串，所以使用长而不可预测的密码避免暴力攻击将是可能的。</p><p><strong>1、user</strong></p><ul><li><p>命令模式： <code>user &lt;username&gt; ... acl rules ...</code></p></li><li><p>默认：未配置</p></li><li><p>说明：指定用户名，是否启用规则，访问控制规则及认证密码，可在客户端通过<code>ACL LIST</code>指令获取当前的权限规则列表，具体的权限赋予规则详情可见<a href="https://redis.io/topics/acl">Redis ACL</a>。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text"># 允许默认用户所有频道所有命令的权限，且不需要密码认证user default on nopass ~* &* +@all</code></pre></li></ul><p><strong>2、acllog-max-len</strong></p><ul><li><p>默认：128</p></li><li><p>取值：一个正整数</p></li><li><p>说明：ACL日志跟踪与ACL关联的失败命令和身份验证事件。此配置设置日志的长度，ACL日志存储在内存中。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">acllog-max-len 128</code></pre></li></ul><p><strong>3、aclfile</strong> </p><ul><li><p>默认：未配置</p></li><li><p>取值：ACL文件所在位置</p></li><li><p>说明：ACL文件所在位置，可以在外部配置user规则，只需通过此配置引入即可，但需要注意的是，配置文件中配置与ACL文件是冲突的，只能在一处配置。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">aclfile /etc/redis/users.acl</code></pre></li></ul><p><strong>4、requirepass</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：密码值</p></li><li><p>说明：此处的密码仅仅是设置默认用户<code>default</code>的密码</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">requirepass foobared</code></pre></li></ul><p><del><strong>5、rename-command</strong></del> </p><ul><li><p>命令模式：rename-command commandname  newcommandname</p></li><li><p>默认：未配置</p></li><li><p>说明：重命名命令名称，已经弃用，新版本建议用ACL进行权限控制。需要注意的是，更改命令记录到AOF文件或传输给从机可能会导致错误。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">rename-command CONFIG "SecretConfig"</code></pre></li></ul><h3 id="Redis-CLIENTS"><a href="#Redis-CLIENTS" class="headerlink" title="Redis CLIENTS"></a>Redis CLIENTS</h3><p>Redis客户端配置</p><p><strong>1、maxclients</strong> </p><ul><li><p>默认：10000</p></li><li><p>取值：客户端连接数量</p></li><li><p>说明：允许连接的客户端数量，最小为32（作为内部文件描述符使用），而一旦超过连接数量后的连接返回错误<code>max number of clients reached</code>。重要提示：当使用Redis集群时，最大连接数也与集群总线共享：集群中的每个节点将使用两个连接，一个传入，另一个传出。在非常大的簇的情况下，相应地调整限制的大小是很重要的。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">maxclients 100000</code></pre></li></ul><h3 id="Redis-MEMORY-MANAGEMENT"><a href="#Redis-MEMORY-MANAGEMENT" class="headerlink" title="Redis MEMORY MANAGEMENT"></a>Redis MEMORY MANAGEMENT</h3><p>Redis内存管理配置</p><p><strong>1、maxmemory</strong></p><ul><li><p>默认：未设置</p></li><li><p>取值：正整数 单位字节bytes</p></li><li><p>说明：redis使用内存的最大限制</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">maxmemory 1024*1024*1024*8</code></pre></li></ul><p><strong>2、maxmemory-policy</strong></p><ul><li><p>默认：noeviction</p></li><li><p>取值：volatile-lru | allkeys-lru | volatile-lfu | allkeys-lfu | volatile-random | allkeys-random |volatile-ttl</p><p>| noeviction</p></li><li><p>说明：当达到设置的最大内存后，redis选择的移除策略，其中lru为最近最久未使用算法，lfu为最近最少使用算法。以下为每个设置的简要介绍。</p><ul><li>volatile-lru：使用LRU算法清除设置了expire过期时间的数据。</li><li>allkeys-lru：使用LRU算法清除任意数据。</li><li>volatile-lfu：使用LFU算法清除设置了expire过期时间的数据。</li><li>allkeys-lfu：使用LFU算法清除任意数据。</li><li>volatile-random：随机清除设置了expire过期时间的数据。</li><li>allkeys-random：随机清除任意数据。</li><li>volatile-ttl：删除最接近过期时间的数据。</li><li>noeviction：不删除任何内容，只在写操作时返回一个错误。</li></ul><p>注意：对于上述任何策略，当没有合适的数据删除时，Redis都会在写操作时返回一个错误。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">maxmemory-policy noeviction</code></pre></li></ul><p><strong>3、maxmemory-samples</strong></p><ul><li><p>默认：5</p></li><li><p>取值：一个正整数</p></li><li><p>说明：上条配置指令中介绍的LRU、LFU和minimal-TTL算法不是精确算法，而是近似算法（为了节省内存），因此您可以调整它的速度或精度。默认情况下，Redis将检查五个键并选择最近使用过的一个，您可以使用以下配置指令更改样本大小。<br>默认值为5会产生足够好的结果。10非常接近真实的LRU，但需要更多的CPU。3更快，但不是很准确。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">maxmemory-samples 5</code></pre></li></ul><p><strong>4、replica-ignore-maxmemory</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：从redis版本5开始，redis从机默认忽略maxmemory的设置，而内存清除策略也只工作在master主机上，从机清除依赖主机传递的删除命令，从而保持一致性。但是如果你的从机时可写入的，且能保证所有写操作都是幂等的，可以更改此选项。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">replica-ignore-maxmemory</code></pre></li></ul><p><strong>5、active-expire-effort</strong></p><ul><li><p>默认：1</p></li><li><p>取值：[1-10]</p></li><li><p>说明：影响redis定期删除策略的一个参数，effort改变了取样基数、定期回收任务间隔，过期键可占内存的最大百分比，最大占用cpu的百分比等，effort越大，cpu负担越重，所以根据自己的需要设置effort的值。这是内存、CPU和延迟之间的权衡。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">active-expire-effort 1</code></pre></li></ul><h3 id="Redis-LAZY-FREEING"><a href="#Redis-LAZY-FREEING" class="headerlink" title="Redis LAZY FREEING"></a>Redis LAZY FREEING</h3><p>Redis有两种方式来删除键。一种叫做DEL，是对对象的阻塞性删除。这意味着服务器停止处理新命令，以便以同步方式回收与对象关联的所有内存。如果删除的键与一个小对象关联，则执行DEL命令所需的时间非常小，与Redis中大多数其他O（1）或O（log_N）命令相比是非常小的。但是，如果键与一个包含数百万个元素的聚合值相关联，服务器可能会长时间（甚至几秒钟）阻塞以完成操作。</p><p>基于上述原因，Redis还提供了UNLINK（non-blocking DEL）和FLUSHDB命令的ASYNC选项等非阻塞删除原语，以便在后台回收内存。这些命令在固定时间内执行。另一个线程将以最快的速度增量释放后台的对象。</p><p>FLUSHALL和FLUSHDB的DEL、UNLINK和ASYNC选项由用户控制。这取决于应用程序的设计来理解何时使用其中一个。然而，由于其他操作的副作用，Redis服务器有时不得不删除密钥或刷新整个数据库。具体来说，在以下场景中，Redis独立于用户调用删除对象：</p><p>1） 回收内存时，由于maxmemory和maxmemory策略配置，为了给新数据腾出空间，而不超过指定的内存限制。</p><p>2） 因为expire：必须从内存中删除具有相关生存时间的密钥（请参阅expire命令）。</p><p>3） 因为命令的副作用是将数据存储在可能已经存在的键上。例如，重命名命令可能会删除旧的键内容，当它被另一个替换时。类似地，SUNIONSTORE或SORT with STORE选项可能会删除现有的键值。SET命令本身删除指定键的任何旧内容，以便用指定的字符串替换它。</p><p>4） 在复制过程中，当从机与其主机执行完全重新同步时，整个数据库的内容将被删除，以便加载刚刚传输的RDB文件。</p><p>在上述所有情况下，默认情况是以阻塞方式删除对象，就像调用DEL一样。但是，您可以具体地配置每种情况，以便使用以下配置指令以非阻塞方式释放内存，就像调用UNLINK一样。</p><pre class=" language-text"><code class="language-text"># 默认全为 no， 可取值：yes | nolazyfree-lazy-eviction yeslazyfree-lazy-expire yeslazyfree-lazy-server-del yesreplica-lazy-flush yes</code></pre><p>其中lazyfree可译为惰性删除或延迟释放；当删除键的时候，redis提供异步延时释放key内存的功能，把key释放操作放在bio(Background I/O)单独的子线程处理中，减少删除big key对redis主线程的阻塞。有效地避免删除big key等带来的性能和可用性问题。</p><p>在用UNLINK调用替换用户代码DEL调用并不容易的情况下，还可以使用以下配置指令修改DEL命令的默认行为，使其与UNLINK完全相同：</p><pre class=" language-text"><code class="language-text"># 默认为no，可取值：yes | nolazyfree-lazy-user-del yes</code></pre><h3 id="Redis-THREADED-I-O"><a href="#Redis-THREADED-I-O" class="headerlink" title="Redis THREADED I/O"></a>Redis THREADED I/O</h3><p>输入输出线程，现在还可以在不同的I/O线程中处理Redis客户端的套接字读写。由于编写速度非常慢，通常Redis用户使用流水线来提高每个核心的Redis性能，并生成多个实例以扩展更多。使用I/O线程，可以轻松地将Redis的速度提高两倍，而无需使用流水线或实例切分。</p><p>默认情况下，线程设置被禁用，redis建议只在至少有4个或更多内核的计算机中启用它，并至少保留一个备用内核。使用超过8个线程不大可能有多大帮助。redis还建议仅当您实际存在性能问题时才使用线程I/O，因为Redis实例会占用相当大比例的CPU时间，否则使用此功能没有任何意义。</p><p>例如，如果你有一个4核的容器，尝试使用2或3个I/O线程，如果你有一个8核，尝试使用6个线程。要启用I/O线程，请使用以下配置指令：</p><pre class=" language-text"><code class="language-text"> io-threads 4</code></pre><p>将<code>io-threads</code>设置为1只会像往常一样使用主线程。当启用I/O多线程时，我们只使用线程进行写入，即线程写入（2）系统调用并将客户机缓冲区传输到套接字。但是，也可以使用以下配置指令启用读取线程和协议解析，方法是将其设置为“yes”：</p><pre class=" language-text"><code class="language-text">io-threads-do-reads no</code></pre><p>通常线程读取并没有多大帮助。</p><p>注1：此配置指令不能在运行时通过<code>CONFIG SET</code>进行更改。启用SSL时，此功能当前不起作用。</p><p>注2：如果你想用Redis benchmark来测试Redis的加速，请确保你也在线程模式下运行基准测试，使用–threads选项来匹配Redis线程的数量，否则你将无法测试出提升。</p><h3 id="Redis-KERNEL-OOM-CONTROL"><a href="#Redis-KERNEL-OOM-CONTROL" class="headerlink" title="Redis KERNEL OOM CONTROL"></a>Redis KERNEL OOM CONTROL</h3><p>Linux 内核有个机制叫OOM killer（Out-Of-Memory killer），该机制会监控那些占用内存过大，尤其是瞬间很快消耗大量内存的进程，为了防止内存耗尽而内核会把该进程杀掉。</p><p><strong>1、oom-score-adj</strong></p><ul><li><p>默认：no</p></li><li><p>取值：yes | no</p></li><li><p>说明：此功能启用，使得redis主动给自己所有的进程进行评分，提供OOM killer机制触发时，进程的灭杀顺序。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">oom-score-adj no</code></pre></li></ul><p><strong>2、oom-score-adj-values</strong></p><ul><li>指令模式及默认值：<code>oom-score-adj-values 0 200 800</code></li><li>说明：当<code>oom-score-adj</code>指令启用时，这条指令指定主机，从机和后台子进程的分数。分数值在区间[-1000, 1000]内，值越大越先被杀掉。</li><li>示例同指令模式</li></ul><h3 id="Redis-APPEND-ONLY-MODE"><a href="#Redis-APPEND-ONLY-MODE" class="headerlink" title="Redis APPEND ONLY MODE"></a>Redis APPEND ONLY MODE</h3><p>默认情况下，Redis将数据集异步转储到磁盘上。这种模式在许多应用程序中已经足够好了，但是Redis进程出现问题或断电可能会导致几分钟的写丢失（取决于配置的保存点）。<br>AOF模式是一种可选的持久性模式，它提供了更好的持久性。例如，如果使用默认的数据fsync策略，Redis在服务器断电等戏剧性事件中可能只会丢失一秒钟的写入操作，或者如果Redis进程本身发生了问题，但操作系统仍在正常运行，则只会丢失一次写入操作。</p><p><strong>1、appendonly</strong></p><ul><li><p>默认：no</p></li><li><p>取值：yes | no</p></li><li><p>说明：是否开启AOF持久化，AOF和RDB两种持久化可以并存，并且redis启动时，会优先加载AOF持久化文件。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">appendonly yes</code></pre></li></ul><p><strong>2、appendfilename</strong></p><ul><li><p>默认：appendonly.aof</p></li><li><p>取值：文件名</p></li><li><p>说明：AOF持久化文件名称</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">appendfilename "appendonly.aof"</code></pre></li></ul><p><strong>3、appendfsync</strong></p><ul><li><p>默认：everysec</p></li><li><p>取值：always | everysec | no</p></li><li><p>说明：追加同步的策略</p><ul><li><p>no：不会调用fsync， 由系统决定什么时候刷磁盘。 速度最快。</p></li><li><p>always：每次写操作都调用fsync同步AOF文件。速度最慢，但安全性高。</p></li><li><p>everysec：每秒调用一次fsync同步AOF文件。以上两种方式的折中方案。</p></li></ul></li><li><p>示例</p><pre class=" language-text"><code class="language-text">appendfsync everysec</code></pre></li></ul><p><strong>4、no-appendfsync-on-rewrite</strong></p><ul><li><p>默认：no</p></li><li><p>取值：yes | no</p></li><li><p>说明：当AOF fsync策略设置为always或everysec，并且后台保存进程（后台保存或AOF日志后台重写）正在对磁盘执行大量I/O时，在某些Linux配置中，Redis可能会在fsync（）调用上阻塞太长时间。请注意，目前还没有解决此问题的方法，因为即使在不同的线程中执行fsync，也会阻止我们的同步写入调用。<br>为了缓解这个问题，可以使用此选项来防止在进行BGSAVE或bwriteAOF时在主进程中调用fsync（）。<br>这意味着，当另一个子进程在存储时，Redis的持久性与“appendfsync none”相同。实际上，这意味着在最坏的情况下（使用默认的Linux设置），可能会丢失最多30秒的日志。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">no-appendfsync-on-rewrite no</code></pre></li></ul><p><strong>5、auto-aof-rewrite-percentage &amp; auto-aof-rewrite-min-size</strong></p><ul><li><p>默认及示例：</p><pre class=" language-text"><code class="language-text">auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb</code></pre></li><li><p>取值：第一条为百分比，100表示比原来大一倍；第二条表示触发重写规则的最小AOF文件大小</p></li><li><p>说明：AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，调用指令<code>bgrewriteaof</code>进行重写，只保留可以恢复数据的最小指令集。</p><p>Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。其中AOF重写时会fork出一条新进程来将文件重写(也是先写临时文件最后再rename)，遍历新进程的内存中数据，每条记录有一条的Set语句。重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件。</p></li></ul><p><strong>6、aof-load-truncated</strong></p><ul><li><p>默认：yes    </p></li><li><p>取值：yes | no</p></li><li><p>说明：redis发现AOF文件尾部命令错误的时候是否继续启动服务。当运行Redis的系统崩溃时，尤其是在没有data=ordered选项的情况下挂载ext4文件系统时，可能会发生这种情况（但是，当Redis本身崩溃或中止，但操作系统仍然正常工作时，这种情况就不会发生）。如果选择的是yes，当截断的aof文件被导入的时候，会忽视有错误的尾部，并且自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">aof-load-truncated yes</code></pre></li></ul><p><strong>7、aof-use-rdb-preamble yes</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：4.0以后出现的混合持久化模式，在重写AOF文件时，Redis能够在AOF文件中使用RDB前导码以加快重写和恢复。启用此选项时，重写的AOF文件由两个不同的节组成：[RDB文件] [AOF tail]，新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据。</p><p>加载时，Redis识别出AOF文件以“Redis”字符串开头并加载带前缀的RDB文件，然后继续加载AOF尾部。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">aof-use-rdb-preamble yes</code></pre></li></ul><h3 id="Redis-LUA-SCRIPTING"><a href="#Redis-LUA-SCRIPTING" class="headerlink" title="Redis LUA SCRIPTING"></a>Redis LUA SCRIPTING</h3><p>Redis从2.6.0开始支持lua脚本，通过内置的 Lua 解释器，可以使用 EVAL和EVALSHA命令对一次在服务端执行大量操作。Redis 使用单个 Lua 解释器去运行所有脚本，并且， Redis 也保证脚本会以原子性(atomic)的方式执行： 当某个脚本正在运行的时候，不会有其他脚本或 Redis 命令被执行。</p><p><code>EVAL</code> 命令要求你在每次执行脚本的时候都发送一次脚本主体(script body)。Redis 有一个内部的缓存机制，因此它不会每次都重新编译脚本，不过在很多场合，付出无谓的带宽来传送脚本主体并不是最佳选择。</p><p>为了减少带宽的消耗， Redis 实现了 <a href="http://www.redis.cn/commands/evalsha.html">EVALSHA</a> 命令，它的作用和 <code>EVAL</code> 一样，都用于对脚本求值，但它接受的第一个参数不是脚本，而是脚本的 SHA1 校验和(sum)。</p><p>EVALSHA 命令的表现如下：</p><p>如果服务器还记得给定的 SHA1 校验和所指定的脚本，那么执行这个脚本 如果服务器不记得给定的 SHA1 校验和所指定的脚本，那么它返回一个特殊的错误，提醒用户使用 EVAL 代替 EVALSHA</p><p><strong>1、lua-time-limit</strong></p><ul><li><p>默认：5000</p></li><li><p>取值：毫秒</p></li><li><p>说明：lua 脚本的最大执行限制时间</p><p>当一个脚本达到最大执行时间的时候，它并不会自动被 Redis 结束，因为 Redis 必须保证脚本执行的原子性，而中途停止脚本的运行意味着可能会留下未处理完的数据在数据集(data set)里面。</p><p>因此，当脚本运行的时间超过最大执行时间后，以下动作会被执行：</p><ul><li>Redis 记录一个脚本正在超时运行</li><li>Redis 开始重新接受其他客户端的命令请求，但是只有 <a href="http://www.redis.cn/commands/script-kill.html">SCRIPT KILL</a> 和 <code>SHUTDOWN NOSAVE</code> 两个命令会被处理，对于其他命令请求， Redis 服务器只是简单地返回 BUSY 错误。</li><li>可以使用 <a href="http://www.redis.cn/commands/script-kill.html">SCRIPT KILL</a> 命令将一个仅执行只读命令的脚本杀死，因为只读命令并不修改数据，因此杀死这个脚本并不破坏数据的完整性</li><li>如果脚本已经执行过写命令，那么唯一允许执行的操作就是 <code>SHUTDOWN NOSAVE</code> ，它通过停止服务器来阻止当前数据集写入磁盘</li></ul></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">lua-time-limit 5000</code></pre></li></ul><h3 id="Redis-REDIS-CLUSTER"><a href="#Redis-REDIS-CLUSTER" class="headerlink" title="Redis REDIS CLUSTER"></a>Redis REDIS CLUSTER</h3><p>Resid集群相关的设置</p><p><strong>1、cluster-enabled</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：yes | no</p></li><li><p>说明：普通的redis实例并不能成为redis集群的一部分，只有节点以集群节点启动才能加入，此处的配置便是让redis以集群节点的形式启动。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">cluster-enabled yes</code></pre></li></ul><p><strong>2、cluster-config-file</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：文件名称</p></li><li><p>说明：redis集群系统中，每个节点必须有自己独立的配置文件，此处为配置文件的名称。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">cluster-config-file nodes-6379.conf</code></pre></li></ul><p><strong>3、cluster-node-timeout</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：毫秒</p></li><li><p>说明：redis集群节点无法访问多长时间才被是为故障节点。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">cluster-node-timeout 15000</code></pre></li></ul><p><strong>4、cluster-replica-validity-factor</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：一个非负整数</p></li><li><p>说明：启动故障切换的时间系数。其中关于它应用场景的官方参考翻译如下：</p><p>如果发生故障的主机的从机的数据看起来太旧，它将避免启动故障转移。</p><p>对于从机来说，没有一种简单的方法来实际精确测量其“数据期限”，因此需要执行以下两种检查：</p><p>1） 如果有多个从机能够进行故障转移，它们会交换消息，以便尝试以最佳复制偏移量（处理来自主服务器的更多数据）为从机提供优势。从机将尝试按偏移量获取其级别，并在故障转移开始时应用与其级别成比例的延迟。</p><p>2） 每个副本都计算最后一次与主副本交互的时间。这可以是上一次接收到的ping或命令（如果主服务器仍处于“已连接”状态），也可以是自与主服务器断开连接后经过的时间（如果复制链接当前处于关闭状态）。如果最后一次交互太旧，从机根本不会尝试故障转移</p><p>其中第二点可以有我们用户把控。指明一个从机是否能够进行故障迁移，看它上次和主机交互过去的时间有没有超过：<code>(node-timeout * cluster-replica-validity-factor) + repl-ping-replica-period</code></p><p>例如：节点超时时间30秒，时间系数为10， 从机检查周期10秒，则从机如果超过310秒没有与主机进行交互，则不能进行故障转移。</p><p>较大的时间系数可能允许数据太旧的从机故障转移到主服务器，而太小的值可能会阻止群集选择从机。<br>为了获得最大可用性，可以将时间系数设置为0，这意味着从机将始终尝试故障转移主服务器，而不管它们上次与主服务器交互的时间。（但是他们总是尝试应用与偏移量成比例的延迟）。<br>零是唯一能够保证当所有分区恢复时，集群始终能够继续运行的值。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">cluster-replica-validity-factor 10</code></pre></li></ul><p><strong>5、cluster-migration-barrier</strong></p><ul><li><p>默认：1</p></li><li><p>取值：非负整数</p></li><li><p>说明：<code>cluster-migration-barrier</code>属性可以保证redis集群中不会出现孤立主机，当某个主节点的从节点挂掉裸奔后，会从其他富余的主节点分配一个从节点过来，确保每个主节点都有至少一个从节点，不至于因为主节点挂掉而没有相应从节点替换为主节点导致集群崩溃不可用。</p><p>只有当旧主机的其他从机的数量至少为给定数量时，从机才会迁移到孤立主机。这个数字就是“移民壁垒”。迁移屏障为1意味着一个从机只有在其主副本至少有一个其他从机时才会迁移，以此类推。它通常反映了集群中每个主机所需的从机数量。</p><p>默认值为1（仅当从机的主节点至少保留一个从机时，从机才会迁移）。要禁用迁移，只需将其设置为非常大的值。可以设置值0，但仅对调试有用，在生产中很危险。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">cluster-migration-barrier 1</code></pre></li></ul><p><strong>6、cluster-require-full-coverage</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：默认情况下，如果Redis集群节点检测到至少有一个散列槽未覆盖（没有可用的节点为其提供服务），那么它们将停止接受查询。这样，如果集群部分关闭（例如，一系列哈希槽不再覆盖），那么所有集群最终都将不可用。一旦所有插槽再次被覆盖，它就会自动返回可用。<br>但是，有时您希望正在工作的集群的子集继续接受对仍然被覆盖的密钥空间部分的查询。为此，只需将cluster require full coverage选项设置为no。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">cluster-require-full-coverage yes</code></pre></li></ul><p><strong>7、 cluster-replica-no-failover</strong></p><ul><li><p>默认：no</p></li><li><p>取值：yes | no</p></li><li><p>说明：此选项设置为“yes”时，可防止从机在主服务器出现故障时尝试故障转移其主服务器。但是，主服务器仍然可以执行手动故障转移。<br>这在不同的场景中非常有用，特别是在多个数据中心操作的情况下，如果不是在整个DC故障的情况下，我们希望永远不会单独升级一端。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text"> cluster-replica-no-failover no</code></pre></li></ul><p><strong>8、cluster-allow-reads-when-down</strong></p><ul><li><p>默认：no</p></li><li><p>取值：yes | no</p></li><li><p>说明：</p><p>默认为no, 表示当集群因主节点数量达不到最小值或有散列槽没有分配而被标记为失效时, 节点将停止所有的客户端通讯(stop serving all traffic). 这样可以避免潜在从一个不知道集群状态变化的节点读到不一致数据的危险. 设为yes则允许集群失效时仍可以由节点中读取数据. 这样既保证读操作的高可用性, 亦避免不一致写操作(inconsistent writes). 同时, 当Redis Cluster 仅包含1至2个节点, 而某个节点失效后无可用从节点替代, 且因节点数量不足, 无法自动重新分配散列槽, 则该参数设为yes可保证节点仍然可执行读操作.</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">cluster-allow-reads-when-down no</code></pre></li></ul><h3 id="Redis-CLUSTER-DOCKER-NAT-support"><a href="#Redis-CLUSTER-DOCKER-NAT-support" class="headerlink" title="Redis CLUSTER DOCKER/NAT support"></a>Redis CLUSTER DOCKER/NAT support</h3><p>在某些部署中，Redis集群节点地址发现失败，原因是地址是NAT的，或者是端口被转发（典型的情况是Docker和其他容器）。<br>为了使Redis集群在这样的环境中工作，需要一个静态配置，其中每个节点都知道自己的公共地址。以下两个选项用于此范围，分别是：<br>cluster-announce-ip    集群通知ip<br>cluster-announce-port    集群通知端口<br>cluster-announce-bus-port    集群通知总线端口<br>每个都指示节点关于其地址、客户机端口和集群消息总线端口。然后在总线包的报头中发布信息，以便其他节点能够正确地映射发布信息的节点的地址。<br>如果不使用上述选项，将使用正常的Redis集群自动检测。<br>请注意，当重新映射时，总线端口可能不在客户端端口+10000的固定偏移量处，因此您可以根据重新映射的方式指定任何端口和总线端口。如果没有设置总线端口，将像往常一样使用固定偏移量10000。<br>示例：</p><pre class=" language-text"><code class="language-text">cluster-announce-ip 10.1.1.5cluster-announce-port 6379cluster-announce-bus-port 6380</code></pre><h3 id="Redis-SLOW-LOG"><a href="#Redis-SLOW-LOG" class="headerlink" title="Redis SLOW LOG"></a>Redis SLOW LOG</h3><p>Redis Slow Log是一个记录超过指定执行时间的查询的系统。执行时间不包括与客户机对话、发送应答等I/O操作，而只是实际执行命令所需的时间（这是命令执行的唯一一个阶段，线程被阻塞，不能同时处理其他请求）</p><p>您可以使用两个参数来配置慢日志：一个参数告诉Redis为了记录命令要超过的执行时间（以微秒为单位），另一个参数是慢日志的长度。记录新命令时，最旧的命令将从记录的命令队列中删除。</p><p><strong>1、slowlog-log-slower-than</strong></p><ul><li><p>默认：10000</p></li><li><p>取值：微秒</p></li><li><p>说明：此参数时间以微秒表示，因此1000000相当于1秒。请注意，负数将禁用慢速日志，而值为零将强制记录每个命令。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text"> slowlog-log-slower-than 10000</code></pre></li></ul><p><strong>2、slowlog-max-len</strong></p><ul><li><p>默认：128</p></li><li><p>取值：一个正整数</p></li><li><p>说明：慢日志的长度，没有限制，但会消耗内存。可以通过命令<code>SLOWLOG RESET</code>回收慢日志占用的内存。</p></li><li><p>示例：</p><pre><code>slowlog-max-len 128</code></pre></li></ul><h3 id="Redis-LATENCY-MONITOR"><a href="#Redis-LATENCY-MONITOR" class="headerlink" title="Redis LATENCY MONITOR"></a>Redis LATENCY MONITOR</h3><p>Redis 2.8.13引入<strong>延迟监控（Latency Monitoring）</strong>的新特性，帮助用户检查和排除可能的延迟问题。</p><p>Redis延迟监控子系统在运行时对不同的操作进行采样，以便收集与Redis实例的可能延迟源相关的数据。<br>通过LATENCY命令，用户可以打印图形并获取报告。<br>系统只记录在大于或等于通过延迟监视器阈值配置指令指定的毫秒数的时间内执行的操作。当其值设置为零时，将关闭延迟监视器。<br>默认情况下，延迟监视是禁用的，因为如果没有延迟问题，则通常不需要延迟监视，并且收集数据会对性能产生影响，虽然影响很小，但可以在大负载下进行测量。如果需要，可以使用命令<code>CONFIG SET Latency monitor threshold&lt;millises&gt;</code>在运行时轻松启用延迟监视。</p><p><strong>1、latency-monitor-threshold</strong></p><ul><li><p>默认：0</p></li><li><p>取值：毫秒数</p></li><li><p>说明：延迟监控的阈值，只有超过延迟阈值的操作才会被延迟监控系统记录。其中特殊值0表示关闭延迟监控。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">latency-monitor-threshold 0</code></pre></li></ul><h3 id="Redis-EVENT-NOTIFICATION"><a href="#Redis-EVENT-NOTIFICATION" class="headerlink" title="Redis EVENT NOTIFICATION"></a>Redis EVENT NOTIFICATION</h3><p>键空间通知功能自2.8.0版本开始可用。</p><p>键空间通知允许客户端订阅发布/订阅频道，以便以某种方式接收影响Redis数据集的事件。</p><p>可能接收的事件示例如下：</p><ul><li>所有影响给定键的命令。</li><li>所有接收LPUSH操作的键。</li><li>所有在数据库0中到期的键。</li></ul><p>事件使用Redis的普通发布/订阅层传递，因此实现了发布/订阅的客户端无需修改即可使用此功能。</p><p>由于Redis的发布/订阅是<em>fire and forget</em>，因此如果你的应用要求<strong>可靠的事件通知</strong>，目前还不能使用这个功能，也就是说，如果你的发布/订阅客户端断开连接，并在稍后重连，那么所有在客户端断开期间发送的事件将会丢失。</p><p>默认情况下，键空间事件通知是不启用的，因为虽然不太明智，但该功能会消耗一些CPU。可以使用redis.conf中的<code>notify-keyspace-events</code>或者使用<strong>CONFIG SET</strong>命令来开启通知。</p><p>将参数设置为空字符串会禁用通知。 为了开启通知功能，使用了一个非空字符串，由多个字符组成，每一个字符都有其特殊的含义，具体参见下表：</p><pre class=" language-text"><code class="language-text">K     键空间事件，以__keyspace@<db>__前缀发布。E     键事件事件，以__keyevent@<db>__前缀发布。g     通用命令（非类型特定），如DEL，EXPIRE，RENAME等等$     字符串命令l     列表命令s     集合命令h     哈希命令z     有序集合命令x     过期事件（每次键到期时生成的事件）e     被驱逐的事件（当一个键由于达到最大内存而被驱逐时产生的事件）A     g$lshzxe的别名，因此字符串AKE表示所有的事件。</code></pre><p>字符串中应当至少存在<code>K</code>或者<code>E</code>，否则将不会传递事件，不管字符串中其余部分是什么。</p><p>例如，要为列表开启键空间事件，则配置参数必须设置为<code>Kl</code>，以此类推。</p><p>字符串<code>KEA</code>可以用于开启所有可能的事件。</p><p>配置指令示例：</p><pre class=" language-text"><code class="language-text">notify-keyspace-events ""</code></pre><h3 id="Redis-GOPHER-SERVER"><a href="#Redis-GOPHER-SERVER" class="headerlink" title="Redis GOPHER SERVER"></a>Redis GOPHER SERVER</h3><p>Redis包含了RFC1436中指定的Gopher协议的实现.</p><p>Gopher是Internet上一个非常有名的信息查找系统，它将Internet上文件组织成某种索引，很方便地将用户从Internet的一处带到另一处。允许用户使用层叠结构的菜单与文件，以发现和检索信息，它拥有世界上最大、最神奇的编目。</p><p>Redis Gopher支持使用Redis的内联协议，特别是两种无论如何都是非法的内联请求：空请求或任何以“/”开头的请求（没有以这样的斜杠开头的Redis命令）。正常的RESP2/RESP3请求完全脱离了Gopher协议实现的路径，也照常提供服务。</p><p>请注意，当启用“io-threads-do-reads”时，Gopher不可用。</p><p>启用命令示例：</p><pre class=" language-text"><code class="language-text"> gopher-enabled yes</code></pre><h3 id="Redis-ADVANCED-CONFIG"><a href="#Redis-ADVANCED-CONFIG" class="headerlink" title="Redis ADVANCED CONFIG"></a>Redis ADVANCED CONFIG</h3><p>Redis高级配置部分。</p><p><strong>1、hash-max-ziplist-entries &amp; hash-max-ziplist-value</strong></p><ul><li><p>默认与示例：</p><pre><code>hash-max-ziplist-entries 512hash-max-ziplist-value 64</code></pre></li><li><p>取值：哈希表内字段数量与单个字段值的大小</p></li><li><p>说明：当散列有少量的条目，并且最大的条目不超过给定的阈值时，使用内存高效的数据结构对散列进行编码，以节约空间提高效率。以上示例中配置表示，当hash内元素数量不超过512个且单个元素的值不大于64个字节时，Redis以其特有的数据结构<code>ziplist</code>存储数据以加快查询速度。</p></li></ul><p><strong>2、list-max-ziplist-size</strong></p><ul><li><p>默认：-2</p></li><li><p>取值：-5 | -4 | -3 | -2 | -1 | 正数</p></li><li><p>说明：列表也以一种特殊的方式编码以节省大量空间。每个内部列表节点允许的条目数可以指定为固定的最大大小或最大元素数。</p><p>对于固定的最大大小，请使用-5到-1，意思是：</p><ul><li> -5: max size: 64 Kb  &lt;– 不建议用于正常工作负载</li><li>-4: max size: 32 Kb  &lt;– 不建议的</li><li>-3: max size: 16 Kb  &lt;– 不太建议</li><li>-2: max size: 8 Kb   &lt;– 建议</li><li>-1: max size: 4 Kb   &lt;– 建议</li></ul><p>正数表示每个列表节点最多可存储的元素数。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">list-max-ziplist-size -2</code></pre></li></ul><p><strong>3、list-compress-depth</strong></p><ul><li><p>默认：0</p></li><li><p>取值：非负整数</p></li><li><p>说明：列表也可以压缩。<br>Compress depth是从列表的每侧排除压缩的节点数。列表的头和尾总是未压缩的，以便进行快速推/弹出操作。其中数字的代表意义为：</p><ul><li>0： 特殊值，禁用所有列表压缩</li><li>1： depth 1表示头部和尾部一个元素不压缩，如：[head]-&gt;node-&gt;node-&gt;…-&gt;node-&gt;[tail]，其中 [head], [tail] 将不会被压缩，压缩所有之间的节点。</li><li>2：depth2 表示头部和尾部的两个元素不压缩。如：[head]-&gt;[next]-&gt;node-&gt;node-&gt;…-&gt;node-&gt;[prev]-&gt;[tail]，这里的意思是：不要压缩head或head-&gt;next或tail-&gt;prev或tail，而是压缩它们之间的所有节点。</li><li>3 …依次类推</li></ul></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">list-compress-depth 0</code></pre></li></ul><p><strong>4、set-max-intset-entries</strong></p><ul><li><p>默认：512</p></li><li><p>取值：正整数 元素个数</p></li><li><p>说明：集合只有一种特殊的编码方式：当一个集合由恰好是基数为10的64位有符号整数范围内的整数组成时。为了使用这种特殊的内存节省编码，此处的配置设置设置了集合大小的限制。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">set-max-intset-entries 512</code></pre></li></ul><p><strong>5、zset-max-ziplist-entries  &amp; zset-max-ziplist-value</strong> </p><ul><li><p>默认及示例：</p><pre class=" language-text"><code class="language-text">zset-max-ziplist-entries 128zset-max-ziplist-value 64</code></pre></li><li><p>取值：有序集合中元素个数以及单个元素最大大小</p></li><li><p>说明：与散列和列表类似，排序集也经过特殊编码以节省大量空间。此编码仅在排序集的长度和元素低于指定限制时使用。示例表示有续集元素数量小于128且单个元素小于64字节时，使用特殊编码以节约空间。</p></li></ul><p><strong>6、hll-sparse-max-byte</strong></p><ul><li><p>默认： 3000</p></li><li><p>取值：0-16000</p></li><li><p>说明：HyperLogLog稀疏表示字节数限制。该限制包括16字节头。当使用稀疏表示的HyperLogLog超过此限制时，它将转换为密集表示。<br>大于16000的值是完全无用的，因为在这一点上，密集表示更高效。<br>建议值为<del>3000，以便在不减慢过多PFADD（稀疏编码为O（N））的情况下利用空间高效编码的优点。当CPU不是问题，但空间是问题，并且数据集由基数在0-15000范围内的许多HyperLogLog组成时，该值可以提高到</del>10000。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">hll-sparse-max-bytes 3000</code></pre></li></ul><p><strong>7、stream-node-max-bytes  &amp; stream-node-max-entries</strong> </p><ul><li><p>默认及示例：</p><pre class=" language-text"><code class="language-text">stream-node-max-bytes 4096stream-node-max-entries 100</code></pre></li><li><p>取值：前者为流节点大小，后者为最大元素数量</p></li><li><p>说明：Streams宏节点最大大小/项。流数据结构是一个由大节点组成的基数树，其中对多个项进行编码。使用此配置，可以配置单个节点的大小（以字节为单位），以及在附加新的流条目时切换到新节点之前可能包含的最大项数。如果将以下任何设置设置为零，则会忽略该限制，因此，例如，可以通过将max bytes设置为0，将max entries设置为所需的值来设置max entires限制。</p></li></ul><p><strong>8、activerehashing</strong></p><ul><li><p> 默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：是否重置Hash表,设置成yes后redis将每100毫秒使用1毫秒CPU时间来对redis的hash表重新hash，可降低内存的使用,当使用场景有较为严格的实时性需求,不能接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no,如果没有这么严格的实时性要求,可以设置为 yes,以便能够尽可能快的释放内存</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">activerehashing yes</code></pre></li></ul><p><strong>9、client-output-buffer-limit</strong></p><ul><li><p>默认及示例：</p><pre class=" language-text"><code class="language-text">client-output-buffer-limit normal 0 0 0client-output-buffer-limit replica 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60</code></pre></li><li><p>配置语法：<code>client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;</code></p></li><li><p>说明：客户机输出缓冲区限制可用于强制断开由于某种原因从服务器读取数据速度不够快的客户机的连接（一个常见的原因是Pub/Sub客户机不能像发布服务器生成消息那样快地使用消息）。<br>对于三种不同类型的客户端，可以设置不同的限制，对应配置的第一个字段：</p><ul><li><p>normal -&gt;普通客户端，包括监视客户端</p></li><li><p>replica -&gt;从机客户端</p></li><li><p>pubsub-&gt;订阅了至少一个pubsub频道或模式的客户端</p></li></ul><p>后面的三个参数的含义时，硬限制，软限制以及软限制的持续时间。具体含义为：一旦达到硬限制，或者如果达到软限制并保持达到指定秒数（连续），对应客户端将立即断开连接。例如：<code>client-output-buffer-limit normal 32mb 16mb 60</code>的含义为，如果输出缓冲区的大小达到32mb，normal类型的客户端，会断开连接；或者输出缓冲区的大小达到16mb，而且持续时间超过60秒，则断开连接。</p><p>默认情况下，普通客户机不受限制，因为它们不会在没有请求（以推送方式）的情况下接收数据，而是在请求之后接收数据，因此只有异步客户机可能会创建这样一种场景，即请求数据的速度比读取数据的速度快。<br>相反，pubsub和从机客户端有一个默认限制，因为订阅者和副本以推送方式接收数据。<br>硬限制或软限制都可以通过将其设置为零来禁用。</p></li></ul><p><strong>10、client-query-buffer-limit</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：缓存大小</p></li><li><p>说明：客户端查询缓冲区累积新指令。默认情况下，它们被限制为固定数量，以避免协议去同步（例如，由于客户端中的错误）将查询缓冲区中未绑定的内存使用。但是，如果您有非常特殊的需求，比如我们的multi/exec请求或类似请求，您可以在这里配置它。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">client-query-buffer-limit 1gb</code></pre></li></ul><p><strong>11、proto-max-bulk-len</strong></p><ul><li><p>默认：512mb</p></li><li><p>取值：请求大小</p></li><li><p>说明：在Redis协议中，批量请求（即表示单个字符串的元素）通常限制为512MB。不过，您可以在此处更改此限制，但必须为1mb或更大。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">proto-max-bulk-len 512mb</code></pre></li></ul><p><strong>12、hz</strong></p><ul><li><p>默认：10</p></li><li><p>取值：1-500</p></li><li><p>说明：Redis执行内部任务的频率，值越大，单位时间执行的次数越多。Redis调用一个内部函数来执行许多后台任务，比如在超时时关闭客户端的连接，清除从未请求的过期密钥，等等。并非所有任务都以相同的频率执行，但是Redis会根据指定的“hz”值检查要执行的任务。<br>默认情况下，“hz”设置为10。当Redis空闲时，提高该值将使用更多的CPU，但同时当有许多键同时过期时，将使Redis更具响应性，并且可以更精确地处理超时。<br>范围在1到500之间，但是值超过100通常不是一个好主意。大多数用户应该使用默认值10，并且仅在需要非常低延迟的环境中才将其提高到100。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">hz 10</code></pre></li></ul><p><strong>13、dynamic-hz</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：通常，HZ值与连接的客户机数量成比例是有用的。例如，为了避免每次后台任务调用都要处理太多的客户机以避免延迟峰值，这一点非常有用。由于默认HZ值被保守地设置为10，Redis提供并启用了使用自适应HZ值的功能，当有许多连接的客户端时，该功能将临时提高。启用动态HZ时，实际配置的HZ将用作基线，但一旦连接更多客户端，实际将根据需要使用配置的HZ值的倍数。这样，空闲的实例将使用很少的CPU时间，而繁忙的实例将更具响应性。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">dynamic-hz yes</code></pre></li></ul><p><strong>14、aof-rewrite-incremental-fsync</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：当子进程进行重写AOF文件时，如果启用此选项，则该文件将每生成32mb的数据进行一次文件同步。这对于以渐进的方式将文件提交到磁盘和避免较大的延迟峰值非常有用。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">aof-rewrite-incremental-fsync yes</code></pre></li></ul><p><strong>15、rdb-save-incremental-fsync</strong></p><ul><li><p> 默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：当redis保存RDB文件时，如果启用了此选项，则文件将每生成32mb的数据进行一次文件同步。这对于以渐进的方式将文件提交到磁盘和避免较大的延迟峰值非常有用。</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">rdb-save-incremental-fsync yes</code></pre></li></ul><p><strong>16、 lfu-log-factor &amp; lfu-decay-time</strong></p><ul><li><p>默认及示例：</p><pre class=" language-text"><code class="language-text">lfu-log-factor 10lfu-decay-time 1</code></pre></li><li><p>取值：都为一个整数，其中后者单位为分钟</p></li><li><p>说明：</p><p>Redis LFU清理算法（参见maxmemory设置）可以进行调优。但是，最好以默认设置开始，在研究如何提高性能以及键的LFU算法如何随时间变化后才建议进行更改，这可以通过OBJECT FREQ命令进行检查。<br>Redis LFU实现中有两个可调参数：计数器对数因子(<code>lfu-log-factor</code>)和计数器衰减时间(<code>lfu-decay-time</code>)。在改变这两个参数之前，了解这两个参数的含义是很重要的。<br>LFU计数器每个键只有8位，它的最大值是255，所以Redis使用了基于概率的对数计数器。给定旧计数器的值，当访问键时，计数器按以下方式递增：</p><ul><li><p>提取0到1之间的随机数R。</p></li><li><p>概率P的计算公式为1/(old_value*<code>lfu_log_factor</code>+1)。</p></li><li><p>只有当R&lt;P时，计数器才递增。</p></li></ul><p>默认<code>lfu log factor</code>为10，值越大，频率增长越慢。这是一个频率计数器如何随不同对数因子的不同访问次数而变化的表：</p><table><thead><tr><th>factor</th><th>100 hits</th><th>1000 hits</th><th>100k hits</th><th>1M hits</th><th>10M hits</th></tr></thead><tbody><tr><td>0</td><td>104</td><td>255</td><td>255</td><td>255</td><td>255</td></tr><tr><td>1</td><td>18</td><td>49</td><td>255</td><td>255</td><td>255</td></tr><tr><td>10</td><td>10</td><td>18</td><td>142</td><td>255</td><td>255</td></tr><tr><td>100</td><td>8</td><td>11</td><td>49</td><td>143</td><td>255</td></tr></tbody></table><p>注：上表是通过运行以下命令获得的：</p><pre class=" language-text"><code class="language-text">redis-benchmark -n 1000000 incr fooredis-cli object freq foo</code></pre><p>注2：计数器初始值为5，以便给新对象一个累积命中的机会。</p><p>计数器衰减时间是键计数器除以2所必须经过的时间，单位为分钟（如果值小于等于10，则递减）衰减时间用于配置热点键访问频率衰减的速度，值越大，衰减越慢，热点数据保存的时间越长。<br><code>lfu-decay-time</code>的默认值为1。一个特殊的值0意味着每次扫描计数器时它都会衰减。</p></li></ul><h3 id="Redis-ACTIVE-DEFRAGMENTATION"><a href="#Redis-ACTIVE-DEFRAGMENTATION" class="headerlink" title="Redis ACTIVE DEFRAGMENTATION"></a>Redis ACTIVE DEFRAGMENTATION</h3><p>什么是活动碎片整理？</p><p>活动（在线）碎片整理允许Redis服务器压缩内存中数据碎片和释放之间的空间，从而允许回收内存。<br>碎片化是每个分配器（但幸运的是，Jemalloc的情况较好）和某些工作负载都会发生的自然过程。通常需要重新启动服务器以降低碎片，或者至少清除所有数据并重新创建。不过，由于Oran Agra for Redis4.0实现了这个特性，这个过程可以在服务器运行时以“热”的方式在运行时发生。</p><p>基本上，当碎片超过某个级别（见下面的配置选项）时，Redis将开始利用某些特定的Jemalloc特性在连续内存区域中创建值的新副本（以便了解分配是否导致碎片并将其分配到更好的位置），同时，将释放数据的旧拷贝。这个过程，对所有键进行增量重复，将使得碎片降回正常值。</p><p>需要了解的重要事项：</p><ul><li>此功能在默认情况下是禁用的，并且仅当您编译Redis以使用我们随Redis源代码提供的Jemalloc副本时才起作用。这是Linux版本的默认设置。</li><li>如果没有碎片问题，就不需要启用此功能。</li><li>一旦遇到碎片，可以在需要时使用命令“CONFIG SET activedefrag yes”启用此功能。</li></ul><p>配置参数能够微调碎片整理过程的行为。如果您不确定它们的含义，那么最好保持默认值不变。</p><p><strong>1、activedefrag</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：yes | no</p></li><li><p>说明：是否开启碎片整理</p></li><li><p>示例：</p><pre><code>activedefrag no</code></pre></li></ul><p><strong>2、 active-defrag-ignore-bytes</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：碎片浪费的内存大小</p></li><li><p>说明：启动活动碎片整理的最小碎片大小</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text"> active-defrag-ignore-bytes 100mb</code></pre></li></ul><p><strong>3、active-defrag-threshold-lower</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：一个整数表示百分比</p></li><li><p>说明：启动活动碎片整理的最小碎片百分比</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">active-defrag-threshold-lower</code></pre></li></ul><p><strong>4、active-defrag-threshold-upper</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：一个整数表示百分比</p></li><li><p>说明：内存碎片超过 100%，则尽最大努力整理</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">active-defrag-threshold-upper 100</code></pre></li></ul><p><strong>5、active-defrag-cycle-min</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：百分比</p></li><li><p>说明：占用的CPU资源百分比，在达到较低阈值时使用</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">active-defrag-cycle-min 1</code></pre></li></ul><p><strong>6、active-defrag-cycle-max</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：百分比</p></li><li><p>说明：占用的CPU资源百分比，在达到最高阈值时使用</p></li><li><p>示例：</p><pre><code>active-defrag-cycle-max 25</code></pre></li></ul><p><strong>7、active-defrag-max-scan-fields</strong></p><ul><li><p>默认：未配置</p></li><li><p>取值：一个正整数</p></li><li><p>说明：碎片整理 扫描set/hash/zset/list时，仅当 set/hash/zset/list 的长度小于此阀值时，才会将此key加入碎片整理</p></li><li><p>示例</p><pre class=" language-text"><code class="language-text">active-defrag-max-scan-fields 1000</code></pre></li></ul><p><strong>8、jemalloc-bg-thread</strong></p><ul><li><p>默认：yes</p></li><li><p>取值：yes | no</p></li><li><p>说明：默认情况下，将启用用于清除的Jemalloc后台线程</p></li><li><p>示例：</p><pre class=" language-text"><code class="language-text">jemalloc-bg-thread yestexy</code></pre></li></ul><p><strong>9、固定redis线程或进程所用的CPU核心</strong></p><ul><li><p>默认：未配置</p></li><li><p>说明：可以将Redis的不同线程和进程固定到系统中的特定cpu上，以最大限度地提高服务器的性能。将不同的Redis线程固定在不同的cpu中非常有用，同时也可以确保在同一主机上运行的多个Redis实例将被固定到不同的cpu上。</p><p>通常，您可以使用“taskset”命令来执行此操作，但是也可以通过Redis配置直接执行此操作，无论是在Linux还是FreeBSD中。<br>您可以固定服务器/IO线程、bio线程、aof重写子进程和bgsave子进程。指定cpu列表的语法与taskset命令相同：</p><p>将redis服务器/io线程与cpu核心0,2,4,6 绑定：</p><pre class=" language-text"><code class="language-text">server_cpulist 0-7:2</code></pre><p>将bio线程与cpu核心1,3 绑定：</p><pre class=" language-text"><code class="language-text">bio_cpulist 1,3</code></pre><p>将aof rewrite子进程与cpu核心8、9、10、11 绑定：</p><pre class=" language-text"><code class="language-text">aof_rewrite_cpulist 8-11</code></pre><p>将bgsave子进程与cpu 核心 1,10,11 绑定：</p><pre class=" language-text"><code class="language-text">bgsave_cpulist 1,10-11</code></pre></li></ul><h2 id="官方完整配置"><a href="#官方完整配置" class="headerlink" title="官方完整配置"></a>官方完整配置</h2><p><a href="https://raw.githubusercontent.com/redis/redis/6.0/redis.conf">=========================传送门=========================</a> </p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> REDIS </tag>
            
            <tag> CONFIG </tag>
            
            <tag> NOSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>keepalived&#39;s log</title>
      <link href="articles/2020/3601090912.html"/>
      <url>articles/2020/3601090912.html</url>
      
        <content type="html"><![CDATA[<p>上次搭建nginx集群，并没有处理keepalived的日志，而keepalived的配置文件默认输出到系统日志<code>/var/log/message</code>中，比较混乱。今天实现日志文件自定义输出位置，以便查看。</p><hr><p><strong>1.修改/etc/sysconfig/keepalived</strong></p><p>将<code>KEEPALIVED_OPTIONS=&quot;-D&quot; </code>修改为<code>KEEPALIVED_OPTIONS=&quot;-D -S 0&quot;</code></p><pre class=" language-text"><code class="language-text"># Options for keepalived. See `keepalived --help' output and keepalived(8) and# keepalived.conf(5) man pages for a list of all options. Here are the most# common ones :## --vrrp               -P    Only run with VRRP subsystem.# --check              -C    Only run with Health-checker subsystem.# --dont-release-vrrp  -V    Dont remove VRRP VIPs & VROUTEs on daemon stop.# --dont-release-ipvs  -I    Dont remove IPVS topology on daemon stop.# --dump-conf          -d    Dump the configuration data.# --log-detail         -D    Detailed log messages.# --log-facility       -S    0-7 Set local syslog facility (default=LOG_DAEMON)## KEEPALIVED_OPTIONS="-D"KEEPALIVED_OPTIONS="-D -S 0"~                                </code></pre><p><strong>2.在/etc/rsyslog.conf里添加</strong></p><pre class=" language-text"><code class="language-text">local0.*  /var/log/keepalived.log </code></pre><p><strong>3.重新启动keepalived和rsyslog服务</strong> </p><pre class=" language-shell"><code class="language-shell">systemctl restart rsyslogsystemctl restart keepalived</code></pre><p><strong>4.查看日志信息</strong></p><pre class=" language-shell"><code class="language-shell">tail -f -n 150 /var/log/keepalived.log</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KEEPALIVED </tag>
            
            <tag> LOG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nginx cluster</title>
      <link href="articles/2020/3501060812.html"/>
      <url>articles/2020/3501060812.html</url>
      
        <content type="html"><![CDATA[<p>nginx虽然实现了应用服务器的负载均衡，但其本身也有down掉的风险，所以为了避免nginx作为分发器时发生单点故障，搭建nginx的集群是有必要的。目前，搭建nginx集群主流方案，是由高可用监控软件Keepalived实现的，本文记录一次搭建过程。</p><h1 id="Nginx-Cluster"><a href="#Nginx-Cluster" class="headerlink" title="Nginx Cluster"></a>Nginx Cluster</h1><h2 id="一、主备模式"><a href="#一、主备模式" class="headerlink" title="一、主备模式"></a>一、主备模式</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>使用两台服务器，一台主服务器和一台热备服务器，当主服务器发生故障时，热备服务器接管主服务器的公网虚拟IP，提供负载均衡服务。主备模式对外提供一个VIP。</p><h3 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h3><h4 id="安装keepalived软件"><a href="#安装keepalived软件" class="headerlink" title="安装keepalived软件"></a>安装keepalived软件</h4><h5 id="安装指令"><a href="#安装指令" class="headerlink" title="安装指令"></a>安装指令</h5><pre class=" language-shell"><code class="language-shell">yum install keepalived -y</code></pre><h5 id="操作指令"><a href="#操作指令" class="headerlink" title="操作指令"></a>操作指令</h5><pre class=" language-shell"><code class="language-shell">systemctl start keepalivedsystemctl stop keepalivedsystemctl restart keepalivedsystemctl status keepalived</code></pre><h4 id="修改keepalived配置文件"><a href="#修改keepalived配置文件" class="headerlink" title="修改keepalived配置文件"></a>修改keepalived配置文件</h4><h5 id="master机器"><a href="#master机器" class="headerlink" title="master机器"></a>master机器</h5><pre class=" language-text"><code class="language-text">! Configuration File for keepalivedglobal_defs &#123;   notification_email &#123;     nickname@qq.com   &#125;   notification_email_from nickname@qq.com   smtp_server 127.0.0.1   smtp_connect_timeout 30   router_id vrrp020   script_user root   enable_script_security &#125;vrrp_script check_nginx &#123;    script "/etc/keepalived/nginx_check.sh"    interval 3    weight -20    fall 2    rise 1&#125;vrrp_instance nginx &#123;    state MASTER    interface ens33    mcast_src_ip 192.168.0.20    virtual_router_id 66    priority 100    advert_int 1    authentication &#123;        auth_type PASS        auth_pass 1111    &#125;    virtual_ipaddress &#123;        192.168.0.251    &#125;    track_script &#123;        check_nginx    &#125;&#125;</code></pre><h5 id="backup机器"><a href="#backup机器" class="headerlink" title="backup机器"></a>backup机器</h5><pre class=" language-text"><code class="language-text">! Configuration File for keepalivedglobal_defs &#123;   notification_email &#123;     nickname@qq.com   &#125;   notification_email_from nickname@qq.com   smtp_server 127.0.0.1   smtp_connect_timeout 30   router_id vrrp022   script_user root   enable_script_security&#125;vrrp_script check_nginx &#123;    script "/etc/keepalived/nginx_check.sh"    interval 3    weight -20    fall 2    rise 1&#125;vrrp_instance nginx &#123;    state BACKUP    interface ens33    mcast_src_ip 192.168.0.22    virtual_router_id 66    priority 80    advert_int 1    authentication &#123;        auth_type PASS        auth_pass 1111    &#125;    virtual_ipaddress &#123;        192.168.0.251    &#125;    track_script &#123;        check_nginx    &#125;&#125;</code></pre><h4 id="编写检查脚本"><a href="#编写检查脚本" class="headerlink" title="编写检查脚本"></a>编写检查脚本</h4><p>此脚本的作用是配合keepalived监控nginx的状态，提供唤醒功能，并在nginx无法唤醒的情况下，结束故障服务器的keepalived进程，以实现VIP漂移。</p><pre class=" language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span>counter<span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token function">ps</span> -C nginx --no-heading<span class="token operator">|</span><span class="token function">wc</span> -l<span class="token variable">)</span></span><span class="token keyword">echo</span> <span class="token string">"<span class="token variable">$counter</span>"</span><span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">"$&amp;#123;counter&amp;#125;"</span> <span class="token operator">=</span> <span class="token string">"0"</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>    nginx -c /usr/local/nginx/conf/nginx.conf    <span class="token function">sleep</span> 2    counter<span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token function">ps</span> -C nginx --no-heading<span class="token operator">|</span><span class="token function">wc</span> -l<span class="token variable">)</span></span>    <span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">"$&amp;#123;counter&amp;#125;"</span> <span class="token operator">=</span> <span class="token string">"0"</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>        systemctl stop keepalived    <span class="token keyword">fi</span><span class="token keyword">fi</span></code></pre><h4 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h4><p>分别在主机和从机上启动nginx与keepalived。</p><pre class=" language-shell"><code class="language-shell">nginx -c /usr/local/nginx/conf/nginx.confsystemctl start keepalived</code></pre><h4 id="测试服务"><a href="#测试服务" class="headerlink" title="测试服务"></a>测试服务</h4><p>若顺利启动主备模式后则可以通过访问虚拟IP的地址得到想要的结果</p><pre class=" language-shell"><code class="language-shell">curl -i 192.168.0.251   #返回为nginx代理的服务即可</code></pre><p>手动关闭主机nginx后，可以很快重新恢复服务</p><pre class=" language-shell"><code class="language-shell">nginx -s stopps aux | grep nginx  #一两秒后nginx进程自动恢复则正常</code></pre><p>手动关闭主机keepalived后，短暂延时后可以正常访问nginx代理的服务</p><pre class=" language-shell"><code class="language-shell">systemctl stop keepalivedcurl -i 192.168.0.251    #短暂延时后，可以正常根据VIP访问</code></pre><h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><p><strong>第一次启动失败</strong></p><p>通过<code>sytemctl status keepalived</code>查看状态发现状态为<strong>dead</strong>，核心提示如下</p><pre class=" language-text"><code class="language-text">Keepalived_vrrp exited with permanent error CONFIG. Terminating</code></pre><p>提示出现永久的配置出错，一时也发现不了错误，配置文件也没动过，所以第一时间去看日志。keepalived的日志文件默认在<code>/var/log/message</code>中，通过日志文件，得到线索如下</p><pre><code>keepalived.service: Can&#39;t open PID file /var/run/keepalived.pid (yet?) after start: No such file or directory</code></pre><p>上述日志提示进程ID文件不存在，手动创建即可。</p><pre class=" language-text"><code class="language-text">WARNING - interface eth0 for vrrp_instance VI_1 doesn't existNon-existent interface specified in configuration</code></pre><p>上述日志提示配置文件中网卡 <strong>eht0</strong> 不存在，通过<code>ip addr</code>命令发现，虚拟机中的网卡名为<strong>ens33</strong>。修改keepalived配置文件，将网卡名称替换为实际存在的即可。其中keepalived的配置文件的默认位置为<code>/etc/keepalived/keepalived.conf</code></p><hr><p><strong>第二次启动失败</strong></p><p>将日志提示的错误修改完成后重新启动keepalived发现，还是启不来，并提示使用<code>journalctl -Ex</code>命令查看系统日志</p><p>系统日志如下</p><pre class=" language-text"><code class="language-text">SELinux is preventing keepalived from read access on the file keepalived.pid. For complete SELinux messages run: seal>SELinux is preventing keepalived from read access on the file keepalived.pid.</code></pre><p>提示安全系统<strong>SELinux</strong> 阻止读取进程ID文件，此时可以根据提示生成本地策略以允许此访问</p><pre class=" language-shell"><code class="language-shell"># ausearch -c 'keepalived' --raw | audit2allow -M my-keepalived# semodule -X 300 -i my-keepalived.pp</code></pre><p>或者也可以关闭SELinux的Enforcing模式，开启宽容模式</p><pre class=" language-shell"><code class="language-shell"># setenforce 0</code></pre><hr><p><strong>主机与从机均绑定了VIP</strong></p><ol><li><p>首先执行命令<code> tcpdump -i ens33 vrrp -n</code>查看下网卡<code>ens33</code>上的组播报文</p><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/tcpdumvrrp.png"></p><p>可见，主机20和备机22都在发送组播报文</p></li><li><p>主从模式中，备机收到报文后是不会再发的，可见备机没有收到组播消息。初步判断防火墙问题。</p></li><li><p>首先直接关闭防火墙，以<em>centos7</em>为例，</p><pre class=" language-shell"><code class="language-shell"># systemctl stop firewalld </code></pre><p>可见关闭后只有主机在发报文</p><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/tcpdumpvrrp2.png"></p></li><li><p>通过<code>ip add</code> 发现只有主机绑定了 <em>192.168.0.251</em>这个虚拟IP，符合了我们的预期</p><p>主机部分</p><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/keepalivevip2.png"></p><p>备机部分</p><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/keepalivevip1.png"></p></li><li><p>更优雅一点，通过防火墙开启vrrp组播通信的权限，而不是直接关闭防火墙，命令如下</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface ens33 --destination 224.0.0.18 --protocol vrrp -j ACCEPT</span><span class="token comment" spellcheck="true"># firewall-cmd --reload</span></code></pre><p>其中<strong>224.0.0.18</strong> 是vrrp组播通信的默认广播地址。</p><hr></li></ol><h2 id="二、双主模式"><a href="#二、双主模式" class="headerlink" title="二、双主模式"></a>二、双主模式</h2><h3 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h3><p>主从模式中，一台做主，一台做备。虽然一定程度上实现了高可用，但备机大多数情况下处于浪费状态。为了解决备机的浪费问题，可以让两台机器互为主备，即每一台机器既担当主机的角色，又拥有备机的身份，这就是双主模式。双主模式对外提供两个VIP。</p><h3 id="实现过程-1"><a href="#实现过程-1" class="headerlink" title="实现过程"></a>实现过程</h3><p>双主模式只要在<em>keepalived</em>的配置文件中配置两个实例即可，在主备模式的基础上，只需要以下两步：</p><p>1、在主机配置文件中增加备机实例</p><pre class=" language-text"><code class="language-text">vrrp_instance nginx02 &#123;    state BACKUP    interface ens33    mcast_src_ip 192.168.0.20    virtual_router_id 68    priority 80    advert_int 1    authentication &#123;        auth_type PASS        auth_pass 1111    &#125;    virtual_ipaddress &#123;        192.168.0.252    &#125;    track_script &#123;        check_nginx    &#125;&#125;</code></pre><p>2、在备机配置文件中增加主机实例</p><pre class=" language-text"><code class="language-text">vrrp_instance nginx02 &#123;    state MASTER    interface ens33    mcast_src_ip 192.168.0.22    virtual_router_id 68    priority 100    advert_int 1    authentication &#123;        auth_type PASS        auth_pass 1111    &#125;    virtual_ipaddress &#123;        192.168.0.252    &#125;    track_script &#123;        check_nginx    &#125;&#125;</code></pre><blockquote><p>其中，同原实例相比，需要修改的部分有：</p><p>实例名称：vrrp_instance</p><p>实例初始状态：state</p><p>节点优先级：priority</p><p>虚拟IP地址：virtual_ipaddress</p><p>虚拟路由ID：virtual_router_id  相同vrid的为一组</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NGINX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Markdown表格中代码块竖线问题</title>
      <link href="articles/2020/0220080712.html"/>
      <url>articles/2020/0220080712.html</url>
      
        <content type="html"><![CDATA[<p>当我们编写markdown格式的文档，不可避免的会用到表格，有时候我们会在表格中用到 <code>|</code> 符号，由于这个符号属于markdown表格定义符号，所以不可避免会遇到一些显示问题。当我用typora编写markdown文件通过hexo生成网页时，由于在表格里写了代码块，恰好发生了格式显示错误，本文记录解决过程。</p><h2 id="一、首行代码块中存在竖线"><a href="#一、首行代码块中存在竖线" class="headerlink" title="一、首行代码块中存在竖线"></a>一、首行代码块中存在竖线</h2><h3 id="问题表现"><a href="#问题表现" class="headerlink" title="问题表现"></a>问题表现</h3><h4 id="Tpory编辑器显示："><a href="#Tpory编辑器显示：" class="headerlink" title="Tpory编辑器显示："></a>Tpory编辑器显示：</h4><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/vertical_line02.png"></p><h4 id="Hexo网页显示"><a href="#Hexo网页显示" class="headerlink" title="Hexo网页显示"></a>Hexo网页显示</h4><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/vertical_line03.png"></p><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h4><p>首先查看markdown源码</p><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/vertical_line01.png"></p><p>通过源码可知，markdown编辑器默认帮我们给非代码部分的 <code>|</code>字符添加了转义字符 <code>\</code>  ，所以可以手动给代码块部分添加</p><h4 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h4><p>通过标签插件提供的 {%raw%} {%endraw%} 标签包裹不需要解析的位置。</p><h4 id="方案三"><a href="#方案三" class="headerlink" title="方案三"></a>方案三</h4><p>直接使用HTML标签&lt;code&gt;替代反引号包裹含有竖线的代码块</p><h2 id="二、非首行代码块中存在竖线"><a href="#二、非首行代码块中存在竖线" class="headerlink" title="二、非首行代码块中存在竖线"></a>二、非首行代码块中存在竖线</h2><h3 id="问题表现-1"><a href="#问题表现-1" class="headerlink" title="问题表现"></a>问题表现</h3><h4 id="Tpory编辑器显示：-1"><a href="#Tpory编辑器显示：-1" class="headerlink" title="Tpory编辑器显示："></a>Tpory编辑器显示：</h4><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/vertical_line04.png"></p><h4 id="Hexo网页显示-1"><a href="#Hexo网页显示-1" class="headerlink" title="Hexo网页显示"></a>Hexo网页显示</h4><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/vertical_line05.png"></p><blockquote><p> 虽然导致错误形式不同，但解决方案同问题一，此处不在赘述</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MARKDOWN </tag>
            
            <tag> CASE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NGINX限流</title>
      <link href="articles/2020/2206060612.html"/>
      <url>articles/2020/2206060612.html</url>
      
        <content type="html"><![CDATA[<h1 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h1><hr><h2 id="一、限流介绍"><a href="#一、限流介绍" class="headerlink" title="一、限流介绍"></a>一、限流介绍</h2><p>限流（rate limiting）是NGINX众多特性中的重要特性之一。该特性可以限制某个用户在一个给定时间段内能够产生的HTTP请求数以及请求的处理速率。用于安全目的上，比如减慢暴力密码破解攻击。通过限制进来的请求速率，并且（结合日志）标记出目标URLs来帮助防范DDoS攻击，保护带宽及服务器的IO资源。一般地说，限流是用在保护上游应用服务器不被在同一时刻的大量用户请求湮没</p><h2 id="二、相关模块"><a href="#二、相关模块" class="headerlink" title="二、相关模块"></a>二、相关模块</h2><h3 id="1-ngx-http-limit-conn-module"><a href="#1-ngx-http-limit-conn-module" class="headerlink" title="1) ngx_http_limit_conn_module"></a>1) ngx_http_limit_conn_module</h3><p>此模块用于限制每个定义的键的连接数，特别是来自单个IP地址的连接数。 不是所有的连接都被计算在内。 只有当一个连接被服务器处理并且整个请求头已经被读取时，它才会被计数。用来限制同一时间连接数，即并发限制。</p><p><strong>配置示例</strong></p><pre><code>http &#123;    limit_conn_zone $binary_remote_addr zone=addr:10m;    ...    server &#123;        ...        location /download/ &#123;            limit_conn addr 1;&#125;</code></pre><p><strong>相关指令</strong></p><table><thead><tr><th align="left">Syntax:</th><th><code>limit_conn zone number;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td>—</td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><p>设置共享内存区域和给定键值的最大允许连接数。 当超过此限制时，服务器将返回定义的错误界面。 例如</p><pre><code>limit_conn_zone $binary_remote_addr zone=addr:10m;server &#123;    location /download/ &#123;        limit_conn addr 1;&#125;</code></pre><p>每个IP每次只允许一个连接，在HTTP/2和SPDY中，每个并发请求都被认为是一个单独的连接。</p><p>可以有多个limit_conn指令。例如，以下配置将限制每个客户端IP与服务器的连接数量，同时限制与虚拟服务器的连接总数：</p><pre><code>limit_conn_zone $binary_remote_addr zone=perip:10m;limit_conn_zone $server_name zone=perserver:10m;server &#123;    ...    limit_conn perip 10;    limit_conn perserver 100;&#125;</code></pre><table><thead><tr><th align="left">Syntax:</th><th><code>limit_conn_dry_run on | off;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>limit_conn_dry_run off;</code></td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><p>启用干运行模式（ 1.17.6）。 在这种模式下，连接的数量不受限制，但在共享内存区域中，过度连接的数量照常计算。</p><table><thead><tr><th>Syntax:</th><th><code>limit_conn_log_level info | notice | warn | error;</code></th></tr></thead><tbody><tr><td>Default:</td><td><code>limit_conn_log_level error;</code></td></tr><tr><td>Context:</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><p>设置服务器限制连接数量的情况下所需的日志记录级别（0.8.18）。</p><table><thead><tr><th align="left">Syntax:</th><th><code>limit_conn_status code;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>limit_conn_status 503;</code></td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><p>设置要返回的状态代码以响应被拒绝的请求(1.3.15)。</p><table><thead><tr><th align="left">Syntax:</th><th><code>limit_conn_zone key zone=name:size;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td>—</td></tr><tr><td align="left">Context:</td><td><code>http</code></td></tr></tbody></table><p>设置共享内存区域的参数，该区域将保留各种键的状态。 其中，状态包括当前连接数。 键可以包含文本，变量及其组合。 不计算带空键值的请求。在版本1.7.6之前，一个键只能包含一个变量。</p><p>使用示例</p><pre><code>limit_conn_zone $binary_remote_addr zone=addr:10m;</code></pre><p>其中内置参数<code>$binary_remote_addr</code>为客户端的IP地址，与 <code>$remote_addr</code>相比，前者为定长，后者不定长。addr 为共享内存区域的名字，10m为大小。</p><h3 id="2-ngx-http-limit-req-module"><a href="#2-ngx-http-limit-req-module" class="headerlink" title="2)   ngx_http_limit_req_module"></a>2)   ngx_http_limit_req_module</h3><p>此模块（0.7.21）用于限制每个定义的键的请求处理速率，特别是来自单个IP地址的请求的处理速率。 限制是使用“漏桶”算法（缓存请求、匀速处理、多余的请求直接丢弃）完成的。单位时间的请求数，速率限制。</p><p><strong>配置示例</strong></p><pre><code>http &#123;    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;    ...    server &#123;        ...        location /search/ &#123;            limit_req zone=one burst=5; &#125;</code></pre><p><strong>相关指令</strong></p><table><thead><tr><th align="left">Syntax:</th><th><code>limit_req zone=name [burst=number] [nodelay | delay=number];</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td>—</td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><p>共享内存区的大小和请求的最大值。如果请求速率超过为区域配置的速率，则它们的处理将被延迟，以便以定义的速率处理请求。过多的请求会被延迟，直到它们的数量超过最大突发大小，在这种情况下，请求会因错误而终止。默认情况下，最大突发大小等于零。</p><pre><code>limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;server &#123;    location /search/ &#123;        limit_req zone=one burst=5;&#125;</code></pre><p>上述配置表示平均每秒允许不超过1个请求，突发请求不超过5个。burst这个配置的意思是设置一个大小为5的缓冲区当有大量请求（爆发）过来时，超过了访问频次限制的请求可以先放到这个缓冲区内。</p><p>延迟参数（1.15.7）指定了过度请求被延迟的限制。 默认值为零，即所有超速的请求都被延迟了</p><p>如果不希望在请求受到限制时延迟过多的请求，则应该使用参数nodelay：</p><pre><code>limit_req zone=one burst=5 nodelay;</code></pre><p>如果设置，超过访问频次而且缓冲区也满了的时候就会直接返回错误503，如果没有设置，则所有请求会等待排队。</p><p>可以配置多个limit_req指令。 例如，以下配置将限制来自单个IP地址的请求的处理速率，同时限制虚拟服务器的请求处理速率：</p><pre><code>limit_req_zone $binary_remote_addr zone=perip:10m rate=1r/s;limit_req_zone $server_name zone=perserver:10m rate=10r/s;server &#123;    ...    limit_req zone=perip burst=5 nodelay;    limit_req zone=perserver burst=10;&#125;</code></pre><table><thead><tr><th align="left">Syntax:</th><th><code>limit_req_dry_run on | off;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>limit_req_dry_run off;</code></td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><p>启用干运行模式（1.17.1）。在这种模式下，请求处理速率不受限制，但是在共享内存区中，过量请求的数量照常计算</p><table><thead><tr><th align="left">Syntax:</th><th><code>limit_req_log_level info | notice | warn | error;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>limit_req_log_level error;</code></td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><p>为服务器因速率超过而拒绝处理请求或延迟请求处理的情况设置所需的日志记录级别（ 0.8.18）。延迟的日志记录级别比拒绝的记录级别低一分；例如，如果指定了“limit_req_log_level notice”，则延迟将用info级别记录。</p><table><thead><tr><th align="left">Syntax:</th><th><code>limit_req_status code;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>limit_req_status 503;</code></td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><p>设置要返回的状态代码以响应被拒绝的请求 (1.3.15)</p><table><thead><tr><th align="left">Syntax:</th><th><code>limit_req_zone key zone=name:size rate=rate [sync];</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td>—</td></tr><tr><td align="left">Context:</td><td><code>http</code></td></tr></tbody></table><p>为共享内存区域设置参数，该区域将保持各种键的状态。其中，状态存储当前过多请求的数量。键可以包含文本、变量及其组合。不计算键值为空的请求。在版本1.7.6之前，一个键只能包含一个变量。</p><p>指令示例</p><pre><code>limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;</code></pre><p>在这里，状态被保存在一个10兆字节的区域“one”，并且该区域的平均请求处理速率不能超过每秒1个请求</p><p>如果区域存储耗尽，则删除最近使用最少的状态。 如果在此之后无法创建新状态，则请求将以错误终止。</p><p>速率在每秒请求(r/s)中指定)。 如果要求每秒少于一个请求的速率，则在每分钟请求(r/m)中指定)。 例如，每秒半请求为30r/m</p><h2 id="三、其他限制指令"><a href="#三、其他限制指令" class="headerlink" title="三、其他限制指令"></a>三、其他限制指令</h2><h3 id="1-限速"><a href="#1-限速" class="headerlink" title="1)限速"></a>1)限速</h3><table><thead><tr><th align="left">Syntax:</th><th><code>limit_rate rate;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>limit_rate 0;</code></td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code>, <code>if in location</code></td></tr></tbody></table><p>限制对客户端的响应传输速率。 速率以每秒字节为单位指定。 零值禁用速率限制。 限制是根据请求设置的，因此如果客户端同时打开两个连接，则总速率将是指定限制的两倍</p><p>参数值可以包含变量（1.17.0）。在根据特定条件限制速率的情况下，该方法可能有用：</p><pre><code>map $slow $rate &#123;    1     4k;    2     8k;&#125;limit_rate $rate;</code></pre><p>速率限制也可以在$limit_rate变量中设置，但是，由于版本1.17.0，不推荐使用此方法：</p><pre><code>server &#123;    if ($slow) &#123;        set $limit_rate 4k;    &#125;    ...&#125;</code></pre><table><thead><tr><th align="left">Syntax:</th><th><code>limit_rate_after size;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>limit_rate_after 0;</code></td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code>, <code>if in location</code></td></tr></tbody></table><p>设置初始数量，在此之后，对客户端的响应的进一步传输将受到速率限制。参数值可以包含变量（1.17.0）。</p><pre><code>location /flv/ &#123;    flv;    limit_rate_after 500k;    limit_rate       50k;&#125;</code></pre><h3 id="2-限制HTTP方法"><a href="#2-限制HTTP方法" class="headerlink" title="2)限制HTTP方法"></a>2)限制HTTP方法</h3><table><thead><tr><th align="left">Syntax:</th><th><code>limit_except method ... &#123; ... &#125;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td>—</td></tr><tr><td align="left">Context:</td><td><code>location</code></td></tr></tbody></table><p>限制一个位置内允许的HTTP方法。方法参数可以是以下参数之一：GET、HEAD、POST、PUT、DELETE、MKCOL、COPY、MOVE、OPTIONS、PROPFIND、PROPPATCH、LOCK、UNLOCK或PATCH。允许GET方法使HEAD方法也被允许。可以使用ngx_http_Access_module、ngx_http_auth_basic_module和ngx_http_auth_jwt_module（1.13.10）modules指令来限制对其他方法的访问：</p><pre><code>limit_except GET &#123;    allow 192.168.1.0/32;    deny  all;&#125;</code></pre><p>请注意，这将限制对所有方法的访问，除了GET和HEAD。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NGINX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis datatype and command</title>
      <link href="articles/2020/2314030312.html"/>
      <url>articles/2020/2314030312.html</url>
      
        <content type="html"><![CDATA[<p>因为redis的数据类型大都比较简明易懂，也拥有着极其丰富中英文社区文档，所以仅以此文总结下<strong>常用的数据类型</strong>及其操作命令==简介== ，主要目的为学习一遍数据类型及其相关命令，方便今后自己查阅。若要查阅命令详情，请访问<a href="https://redis.io/commands">redis Commands</a>  或 <a href="http://www.redis.cn/commands.html">redis 中文</a>。</p><blockquote><p>当前redis版本 ==6.2.0==</p></blockquote><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>redis的数据类型常见的有字符串（String）、哈希表（Hash）、列表（List）、集合（Set）、有序集合（zset）五种，另外还有位图（bitmaps）、HyperLogLogs、Streams。本文主要记录下前五种数据类型及命令简介。</p><hr><h2 id="Redis-keys"><a href="#Redis-keys" class="headerlink" title="Redis keys"></a>Redis keys</h2><p>redis键是二进制安全的，这意味着可以使用任何二进制序列作为键，比如ipg图片或者序列化的对象， 空字符串也是有效的键。</p><p>键允许的最大值为512M。</p><h3 id="相关命令"><a href="#相关命令" class="headerlink" title="相关命令"></a>相关命令</h3><table><thead><tr><th align="left">命令</th><th>起始版本</th><th>时间复杂度</th><th>基本语法</th><th align="left">简述</th></tr></thead><tbody><tr><td align="left">TYPE</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>TYPE  key</td><td align="left">用于返回 key 所储存的值的类型。</td></tr><tr><td align="left">PEXPIREAT</td><td><strong>2.6.0</strong></td><td>O(1)</td><td>PEXPIREAT key milliseconds-timestamp</td><td align="left">设置 key 到什么时候过期，以毫秒计。</td></tr><tr><td align="left">RENAME</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>RENAME key newkey</td><td align="left">修改 key 的名称</td></tr><tr><td align="left">PERSIST</td><td><strong>2.2.0</strong></td><td>O(1)</td><td>PERSIST  key</td><td align="left">移除 key 的过期时间，key 将持久保持。</td></tr><tr><td align="left">MOVE</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>MOVE key db</td><td align="left">将当前数据库的 key 移动到给定的数据库 db 当中。</td></tr><tr><td align="left">RANDOMKEY</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>RANDOMKEY</td><td align="left">从当前数据库中随机返回一个 key 。</td></tr><tr><td align="left">DUMP</td><td><strong>2.6.0</strong></td><td>O(1)</td><td>DUMP  key</td><td align="left">序列化给定 key ，并返回被序列化的值。</td></tr><tr><td align="left">TTL</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>TTL  key</td><td align="left">以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。</td></tr><tr><td align="left">EXPIRE</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>EXPIRE key seconds</td><td align="left">为给定 key 设置过期时间。</td></tr><tr><td align="left">DEL</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>DEL key [key …]</td><td align="left">该命令用于在 key 存在时删除 key。</td></tr><tr><td align="left">PTTL</td><td><strong>2.6.0</strong></td><td>O(1)</td><td>PTTL key</td><td align="left">以毫秒为单位返回 key 的剩余的过期时间。</td></tr><tr><td align="left">RENAMENX</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>RENAMENX key newkey</td><td align="left">仅当 newkey 不存在时，将 key 改名为 newkey 。</td></tr><tr><td align="left">EXISTS</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>EXISTS key [key …]</td><td align="left">判断当前key是否存在</td></tr><tr><td align="left">EXPIREAT</td><td><strong>1.2.0</strong></td><td>O(1)</td><td>EXPIREAT key timestamp</td><td align="left">EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。</td></tr><tr><td align="left">KEYS</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>KEYS pattern</td><td align="left">查找所有符合给定模式( pattern)的 key 。</td></tr></tbody></table><hr><h2 id="Redis-Strings"><a href="#Redis-Strings" class="headerlink" title="Redis Strings"></a>Redis Strings</h2><p>字符串是最基本的Redis值。 Redis Strings是二进制安全的，这意味着Redis字符串可以包含任何类型的数据，例如JPEG图像或序列化的JAVA对象。字符串值的长度可以达到最大512兆字节。</p><h3 id="相关命令-1"><a href="#相关命令-1" class="headerlink" title="相关命令"></a>相关命令</h3><table><thead><tr><th align="left">命令</th><th>起始版本</th><th>时间复杂度</th><th>基本语法</th><th align="left">简述</th></tr></thead><tbody><tr><td align="left">SETNX</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>SETNX key value</td><td align="left">只有在 key 不存在时设置 key 的值。</td></tr><tr><td align="left">GETRANGE</td><td><strong>2.4.0</strong></td><td>O(N)</td><td>GETRANGE key start end</td><td align="left">返回 key 中字符串值的子字符 起始0，结束-1</td></tr><tr><td align="left">MSET</td><td><strong>1.0.1</strong></td><td>O(N)</td><td>MSET key value [key value …]</td><td align="left">同时设置一个或多个 key-value 对，是原子操作。</td></tr><tr><td align="left">MSETNX</td><td><strong>1.0.1</strong></td><td>O(N)</td><td>MSETNX key value [key value …]</td><td align="left">同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。</td></tr><tr><td align="left">SETEX</td><td><strong>2.0.0</strong></td><td>O(1)</td><td>SETEX key seconds value</td><td align="left">将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。</td></tr><tr><td align="left">PSETEX</td><td><strong>2.6.0</strong></td><td>O(1)</td><td>PSETEX key milliseconds value</td><td align="left">这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间</td></tr><tr><td align="left">SET</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>SET key value [EX seconds|PX milliseconds|KEEPTTL] [NX|XX] [GET]</td><td align="left">设置指定 key 的值<br />&gt;= 2.6.12: Added the EX, PX, NX and XX options.<br/>&gt;= 6.0: Added the KEEPTTL option.<br/>&gt;= 6.2: Added the GET option.</td></tr><tr><td align="left">GET</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>GET key</td><td align="left">获取指定 key 的值。</td></tr><tr><td align="left">GETBIT</td><td><strong>2.2.0</strong></td><td>O(1)</td><td>GETBIT key offset</td><td align="left">对 key 所储存的字符串值，获取指定偏移量上的位(bit)。是二进制位的偏移量。</td></tr><tr><td align="left">SETBIT</td><td><strong>2.2.0</strong></td><td>O(1)</td><td>SETBIT key offset value</td><td align="left">对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。是二进制位的偏移量。</td></tr><tr><td align="left">DECR</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>DECR key</td><td align="left">将 key 中储存的数字值减一。</td></tr><tr><td align="left">DECRBY</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>DECRBY key decrement</td><td align="left">key 所储存的值减去给定的减量值（decrement） 。</td></tr><tr><td align="left">STRLEN</td><td><strong>2.2.0</strong></td><td>O(1)</td><td>STRLEN key</td><td align="left">返回 key 所储存的字符串值的长度。</td></tr><tr><td align="left">INCR</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>INCR key</td><td align="left">将 key 中储存的数字值增一。</td></tr><tr><td align="left">Incrby</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>INCRBY key increment</td><td align="left">将 key 所储存的值加上给定的增量值（increment） 。</td></tr><tr><td align="left">INCRBYFLOAT</td><td><strong>2.6.0</strong></td><td>O(1)</td><td>INCRBYFLOAT key increment</td><td align="left">将 key 所储存的值加上给定的浮点增量值（increment） 。</td></tr><tr><td align="left">SETRANGE</td><td><strong>2.2.0</strong></td><td>O(1)</td><td>SETRANGE key offset value</td><td align="left">用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始。</td></tr><tr><td align="left">APPEND</td><td><strong>2.0.0</strong></td><td>O(1)</td><td>APPEND key value</td><td align="left">如果 key 已经存在并且是一个字符串， APPEND 命令将 value 追加到 key 原来的值的末尾。</td></tr><tr><td align="left">GETSET</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>GETSET key value</td><td align="left">将给定 key 的值设为 value ，并返回 key 的旧值(old value)。</td></tr><tr><td align="left">MGET</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>MGET key [key …]</td><td align="left">获取所有(一个或多个)给定 key 的值。</td></tr></tbody></table><hr><h2 id="Redis-List"><a href="#Redis-List" class="headerlink" title="Redis List"></a>Redis List</h2><p>Redis lists允许重复值，并且基于Linked Lists实现，。这意味着即使在一个list中有数百万个元素，在头部或尾部添加一个元素的操作，其时间复杂度也是常数级别的。LPUSH 命令插入一个新元素到列表头部，而RPUSH命令 插入一个新元素到列表的尾部。当对一个空key执行其中某个命令时，将会创建一个新表。</p><h3 id="相关命令-2"><a href="#相关命令-2" class="headerlink" title="相关命令"></a>相关命令</h3><table><thead><tr><th align="left">命令</th><th>起始版本</th><th>时间复杂度</th><th>基本语法</th><th align="left">简述</th></tr></thead><tbody><tr><td align="left">LPUSH</td><td><strong>1.0.0</strong></td><td>O(1) or O(N)</td><td>LPUSH key element [element …]</td><td align="left">将一个或多个值插入到列表头部</td></tr><tr><td align="left">LPUSHX</td><td><strong>2.2.0</strong></td><td>O(1) or O(N)</td><td>LPUSHX key element [element …]</td><td align="left">将一个或多个值插入到列表头部，当且仅当列表存在时插入</td></tr><tr><td align="left">RPUSH</td><td><strong>1.0.0</strong></td><td>O(1) or O(N)</td><td>RPUSH key element [element …]</td><td align="left">在列表尾部插入所有指定的值。</td></tr><tr><td align="left">RPUSHX</td><td><strong>2.2.0</strong></td><td>O(1) or O(N)</td><td>RPUSHX key element [element …]</td><td align="left">只有当键已经存在并持有列表时，才在存储在键的列表尾部插入指定值</td></tr><tr><td align="left">LPOP</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>LPOP key</td><td align="left">移除并返回存储在列表的第一个元素。</td></tr><tr><td align="left">RPOP</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>RPOP key</td><td align="left">移除并返回存储在列表的最后一个元素</td></tr><tr><td align="left">RPOPLPUSH</td><td><strong>1.2.0</strong></td><td>O(1)</td><td>RPOPLPUSH source destination</td><td align="left">移除列表的最后一个元素，并将该元素添加到另一个列表头部并返回</td></tr><tr><td align="left">LREM</td><td><strong>1.0.0</strong></td><td>O(N+M)</td><td>LREM key count element</td><td align="left">移除列表中指定count数量的与element相同的元素<br /> count=0 移除所有相等元素<br /> count&gt;0 从队首开始移除指定个数<br /> count&lt;0 从队尾开始移除指定个数</td></tr><tr><td align="left">LLEN</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>LLEN key</td><td align="left">返回列表长度</td></tr><tr><td align="left">LINDEX</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>LINDEX key index</td><td align="left">返回指定索引的元素</td></tr><tr><td align="left">LINSERT</td><td><strong>2.2.0</strong></td><td>O(N)</td><td>LINSERT key BEFORE|AFTER pivot element</td><td align="left">在指定元素前后插入元素</td></tr><tr><td align="left">LSET</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>LSET key index element</td><td align="left">设置指定索引处的元素</td></tr><tr><td align="left">LRANGE</td><td><strong>1.0.0</strong></td><td>O(S+N)</td><td>LRANGE key start stop</td><td align="left">获取列表指定范围内的元素</td></tr><tr><td align="left">LTRIM</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>LTRIM key start stop</td><td align="left">截取列表，只保留指定范围内的元素</td></tr><tr><td align="left">LPOS</td><td><strong>6.0.6</strong></td><td>O(N)</td><td>LPOS key element [RANK rank] [COUNT num-matches] [MAXLEN len]</td><td align="left">返回列表中匹配列表的索引，rank指定返回第几个匹配元素的索引，count指定返回几个匹配元素的索引， maxlen指定比较的次数。</td></tr><tr><td align="left">BLPOP</td><td><strong>2.0.0</strong></td><td>O(1)</td><td>BLPOP key [key …] timeout</td><td align="left">该命令返回Redis列表中匹配元素的索引该命令返回Redis列表中匹配元素的索引移除并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</td></tr><tr><td align="left">BRPOP</td><td><strong>2.0.0</strong></td><td>O(1)</td><td>BRPOP key [key …] timeout</td><td align="left">移除并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</td></tr><tr><td align="left">BRPOPLPUSH</td><td><strong>2.2.0</strong></td><td>O(1)</td><td>BRPOPLPUSH source destination timeout</td><td align="left">移除列表的最后一个元素，并将该元素添加到另一个列表头部并返回，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</td></tr><tr><td align="left">LMOVE</td><td><strong>6.2.0</strong></td><td>O(1)</td><td>LMOVE source destination LEFT|RIGHT LEFT|RIGHT</td><td align="left">原子性地返回并移除存储在源中的列表的第一个/最后一个元素，并将元素推送到存储在目标位置的列表的第一个/最后一个元素。<br /> 此命令可以用来代替不太推荐的<code>RPOPLPUSH</code>命令</td></tr><tr><td align="left">BLMOVE</td><td><strong>6.2.0</strong></td><td>O(1)</td><td>BLMOVE source destination LEFT|RIGHT LEFT|RIGHT timeout</td><td align="left">此命令是<code>LMOVE</code>的阻塞变体</td></tr></tbody></table><hr><h2 id="Redis-Hash"><a href="#Redis-Hash" class="headerlink" title="Redis Hash"></a>Redis Hash</h2><p>Redis Hashes是字符串字段和字符串值之间的映射，hash特别适合用于存储对象。类似java里面的Map&lt;String,Object&gt;，每个散列最多可存储(2^32)-1个字段值对（超过40亿）。</p><h3 id="相关命令-3"><a href="#相关命令-3" class="headerlink" title="相关命令"></a>相关命令</h3><table><thead><tr><th align="left">命令</th><th>起始版本</th><th>时间复杂度</th><th>基本语法</th><th align="left">简述</th></tr></thead><tbody><tr><td align="left">HSET</td><td><strong>2.0.0</strong></td><td>O(1) or O(N)</td><td>HSET key field value [field value …]</td><td align="left">设置存储在哈希表中一个或多个字段的值</td></tr><tr><td align="left">HSETNX</td><td><strong>2.0.0</strong></td><td>O(1)</td><td>HSETNX key field value</td><td align="left">设置哈希表中一个字段的值，当且仅当字段不存在时起作用。</td></tr><tr><td align="left"><del>HMSET</del></td><td><strong>2.0.0</strong></td><td>O(N)</td><td>HMSET key field value [field value …]</td><td align="left">4.0.0以后已弃用，作用同<code>HSET</code></td></tr><tr><td align="left">HGET</td><td><strong>2.0.0</strong></td><td>O(1)</td><td>HGET key field</td><td align="left">返回存储在键处的哈希中与字段关联的值</td></tr><tr><td align="left">HGETALL</td><td><strong>2.0.0</strong></td><td>O(N)</td><td>HGETALL key</td><td align="left">返回存储在键处的哈希的所有字段和值。</td></tr><tr><td align="left">HMGET</td><td><strong>2.0.0</strong></td><td>O(N)</td><td>HMGET key field [field …]</td><td align="left">返回存储在哈希中与指定字段关联的一个或多个值。</td></tr><tr><td align="left">HEXISTS</td><td><strong>2.0.0</strong></td><td>O(1)</td><td>HEXISTS key field</td><td align="left">返回字段在哈希中是否存在。1存在 0不存在</td></tr><tr><td align="left">HDEL</td><td><strong>2.0.0</strong></td><td>O(N)</td><td>HDEL key field [field …]</td><td align="left">删除哈希表中指定的字段</td></tr><tr><td align="left">HLEN</td><td><strong>2.0.0</strong></td><td>O(1)</td><td>HLEN key</td><td align="left">返回哈希表中字段的数量</td></tr><tr><td align="left">HSTRLEN</td><td><strong>3.2.0</strong></td><td>O(1)</td><td>HSTRLEN key field</td><td align="left">返回存储在键处的哈希中与字段关联的值的字符串长度。如果键或字段不存在，则返回0。</td></tr><tr><td align="left">HINCRBY</td><td><strong>2.0.0</strong></td><td>O(1)</td><td>HINCRBY key field increment</td><td align="left">为哈希表 key 中的指定字段的整数值加上增量 increment 。返回增长后的值</td></tr><tr><td align="left">HINCRBYFLOAT</td><td><strong>2.6.0</strong></td><td>O(1)</td><td>HINCRBYFLOAT key field increment</td><td align="left">为哈希表 key 中的指定字段的浮点数值加上增量 increment 。</td></tr><tr><td align="left">HKEYS</td><td><strong>2.0.0</strong></td><td>O(N)</td><td>HKEYS key</td><td align="left">返回存储在哈希表中所有的字段名称</td></tr><tr><td align="left">HVALS</td><td><strong>2.0.0</strong></td><td>O(N)</td><td>HVALS key</td><td align="left">返回存储在哈希表中所有的字段的值</td></tr><tr><td align="left">HSCAN</td><td><strong>2.8.0</strong></td><td>O(1) or O(N)</td><td>HSCAN key cursor [MATCH pattern] [COUNT count]</td><td align="left">用于迭代哈希中的键值对。数据量较小时count不工作。</td></tr></tbody></table><hr><h2 id="Redis-Set"><a href="#Redis-Set" class="headerlink" title="Redis Set"></a>Redis Set</h2><p>Redis集合是一个无序的字符串合集。它是通过HashTable实现的，你可以以<strong>O(1)</strong> 的时间复杂度完成 添加、删除以及测试元素是否存在的操作。</p><h3 id="相关命令-4"><a href="#相关命令-4" class="headerlink" title="相关命令"></a>相关命令</h3><table><thead><tr><th align="left">命令</th><th>起始版本</th><th>时间复杂度</th><th>基本语法</th><th align="left">简述</th></tr></thead><tbody><tr><td align="left">SADD</td><td><strong>1.0.0</strong></td><td>O(1) or O(N)</td><td>SADD key member [member …]</td><td align="left">向集合中添加一个或多个元素</td></tr><tr><td align="left">SISMEMBER</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>SISMEMBER key member</td><td align="left">判断元素是否是集合的成员</td></tr><tr><td align="left">SPOP</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>SPOP key [count]</td><td align="left">移除并返回集合中的一个或指定数量随机元素</td></tr><tr><td align="left">SRANDMEMBER</td><td><strong>1.0.0</strong></td><td>O(1) or O(N)</td><td>SRANDMEMBER key [count]</td><td align="left">随机访问集合中的一个或指定数量随机元素并返回</td></tr><tr><td align="left">SREM</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>SREM key member [member …]</td><td align="left">移除列出的元素</td></tr><tr><td align="left">SMOVE</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>SMOVE source destination member</td><td align="left">将一个集合中的指定元素移动到另一个集合中去</td></tr><tr><td align="left">SCARD</td><td><strong>1.0.0</strong></td><td>O(1)</td><td>SCARD key</td><td align="left">获取集合的成员数</td></tr><tr><td align="left">SMEMBERS</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>SMEMBERS key</td><td align="left">返回集合中的所有成员</td></tr><tr><td align="left">SSCAN</td><td><strong>2.8.0</strong></td><td>O(1) or O(N)</td><td>SSCAN key cursor [MATCH pattern] [COUNT count]</td><td align="left">迭代集合中的元素</td></tr><tr><td align="left">SINTER</td><td><strong>1.0.0</strong></td><td>O(N*M)</td><td>SINTER key [key …]</td><td align="left">返回给定所有集合的交集</td></tr><tr><td align="left">SINTERSTORE</td><td><strong>1.0.0</strong></td><td>O(N*M)</td><td>SINTERSTORE destination key [key …]</td><td align="left">返回给定所有集合的交集并存储在 destination 中</td></tr><tr><td align="left">SUNION</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>SUNION key [key …]</td><td align="left">返回给定所有集合的并集</td></tr><tr><td align="left">SUNIONSTORE</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>SUNIONSTORE destination key [key …]</td><td align="left">返回给定所有集合的并集并存储在 destination 中</td></tr><tr><td align="left">SDIFF</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>SDIFF key [key …]</td><td align="left">返回给定所有集合的差集，只返回第一个集合的差集</td></tr><tr><td align="left">SDIFFSTORE</td><td><strong>1.0.0</strong></td><td>O(N)</td><td>SDIFFSTORE destination key [key …]</td><td align="left">返回给定所有集合的差集并存储在 destination 中</td></tr><tr><td align="left">SMISMEMBER</td><td><strong>6.2.0</strong></td><td>O(N)</td><td>SMISMEMBER key member [member …]</td><td align="left">返回每个成员是否是存储在集合的成员。 对于每个成员，如果值是集合的成员，则返回1，如果元素不是集合的成员，或者如果键不存在，则返回0。</td></tr></tbody></table><hr><h2 id="Redis-Sorted-sets"><a href="#Redis-Sorted-sets" class="headerlink" title="Redis Sorted sets"></a>Redis Sorted sets</h2><p>类似Sets,但是每个字符串元素都关联到一个叫<em>score</em>浮动数值（floating number value）。里面的元素总是通过score进行着排序，其中zset的成员是唯一的，但分数（score）却可以重复。</p><h3 id="相关命令-5"><a href="#相关命令-5" class="headerlink" title="相关命令"></a>相关命令</h3><table><thead><tr><th align="left">命令</th><th>起始版本</th><th>时间复杂度</th><th>基本语法</th><th align="left">简述</th></tr></thead><tbody><tr><td align="left">ZADD</td><td><strong>1.2.0</strong></td><td>O(log(N))</td><td>ZADD key [NX|XX] [GT|LT] [CH] [INCR] score member [score member …]</td><td align="left">将具有指定分数的所有指定成员添加到存储在键处的有序集中。<br />&gt;=2.4：接受多个元素。在2.4版之前的Redis版本中，每次调用都只能添加或更新一个成员。<br/>&gt;=3.0.2：增加了XX、NX、CH和INCR选项。<br/>&gt;=6.2:添加了GT和LT选项。</td></tr><tr><td align="left">ZSCORE</td><td><strong>1.2.0</strong></td><td>O(1)</td><td>ZSCORE key member</td><td align="left">返回有序集合中单个成员的分数</td></tr><tr><td align="left">ZMSCORE</td><td><strong>6.2.0</strong></td><td>O(N)</td><td>ZMSCORE key member [member …]</td><td align="left">返回有序集合中一个或多个成员的分数</td></tr><tr><td align="left">ZRANK</td><td><strong>2.0.0</strong></td><td>O(log(N))</td><td>ZRANK key member</td><td align="left">返回有序集合中指定成员的索引</td></tr><tr><td align="left">ZINCRBY</td><td><strong>1.2.0</strong></td><td>O(log(N))</td><td>ZINCRBY key increment member</td><td align="left">有序集合中对指定成员的分数加上增量 increment</td></tr><tr><td align="left">ZCARD</td><td><strong>1.2.0</strong></td><td>O(1)</td><td>ZCARD key</td><td align="left">获取有序集合的成员数</td></tr><tr><td align="left">ZCOUNT</td><td><strong>2.0.0</strong></td><td>O(log(N))</td><td>ZCOUNT key min max</td><td align="left">计算在有序集合中指定区间分数的成员数</td></tr><tr><td align="left">ZLEXCOUNT</td><td><strong>2.8.9</strong></td><td>O(log(N))</td><td>ZLEXCOUNT key min max</td><td align="left">在有序集合中计算指定字典区间内成员数量</td></tr><tr><td align="left">ZRANGE</td><td><strong>1.2.0</strong></td><td>O(log(N)+M)</td><td>ZRANGE key start stop [WITHSCORES]</td><td align="left">返回存储在键处的排序集中的指定元素范围。</td></tr><tr><td align="left">ZRANGEBYLEX</td><td><strong>2.8.9</strong></td><td>O(log(N)+M)</td><td>ZRANGEBYLEX key min max [LIMIT offset count]</td><td align="left">ZRANGEBYLEX 返回指定成员区间内的成员，按成员字典正序排序, 分数必须相同。</td></tr><tr><td align="left">ZRANGEBYSCORE</td><td><strong>1.0.5</strong></td><td>O(log(N)+M)</td><td>ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]</td><td align="left">通过分数返回有序集合指定区间内的成员</td></tr><tr><td align="left">ZREVRANGE</td><td><strong>1.2.0</strong></td><td>O(log(N)+M)</td><td>ZREVRANGE key start stop [WITHSCORES]</td><td align="left">返回有序集中指定区间内的成员，通过索引，分数从高到底</td></tr><tr><td align="left">ZREVRANGEBYLEX</td><td><strong>2.8.9</strong></td><td>O(log(N)+M)</td><td>ZREVRANGEBYLEX key max min [LIMIT offset count]</td><td align="left">ZREVRANGEBYLEX 返回指定成员区间内的成员，按成员字典倒序排序, 分数必须相同。</td></tr><tr><td align="left">ZREVRANGEBYSCORE</td><td><strong>2.2.0</strong></td><td>O(log(N)+M)</td><td>ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]</td><td align="left">返回有序集合中指定分数区间内的成员，分数由高到低排序。</td></tr><tr><td align="left">ZREVRANK</td><td><strong>2.0.0</strong></td><td>O(log(N))</td><td>ZREVRANK key member</td><td align="left">返回有序集合中指定成员的索引，有序集成员按分数值递减(从大到小)排序</td></tr><tr><td align="left">ZREM</td><td><strong>1.2.0</strong></td><td>O(M*log(N))</td><td>ZREM key member [member …]</td><td align="left">从存储在键处的有序集中移除指定的成员。</td></tr><tr><td align="left">ZREMRANGEBYSCORE</td><td><strong>1.2.0</strong></td><td>O(log(N)+M)</td><td>ZREMRANGEBYSCORE key min max</td><td align="left">移除有序集合中给定的分数区间的所有成员</td></tr><tr><td align="left">ZREMRANGEBYLEX</td><td><strong>2.8.9</strong></td><td>O(log(N)+M)</td><td>ZREMRANGEBYLEX key min max</td><td align="left">移除有序集合中给定的字典区间的所有成员</td></tr><tr><td align="left">ZREMRANGEBYRANK</td><td><strong>2.0.0</strong></td><td>O(log(N)+M)</td><td>ZREMRANGEBYRANK key start stop</td><td align="left">移除有序集合中给定的索引区间的所有成员</td></tr><tr><td align="left">ZPOPMAX</td><td><strong>5.0.0</strong></td><td>O(log(N)*M)</td><td>ZPOPMAX key [count]</td><td align="left">删除并返回最多count个排序集中得分最高的成员。</td></tr><tr><td align="left">ZPOPMIN</td><td><strong>5.0.0</strong></td><td>O(log(N)*M)</td><td>ZPOPMIN key [count]</td><td align="left">删除并返回最多count个排序集中得分最低的成员。</td></tr><tr><td align="left">BZPOPMAX</td><td><strong>5.0.0</strong></td><td>O(log(N))</td><td>BZPOPMAX key [key …] timeout</td><td align="left"><code>BZPOPMAX</code>是有序集合<code>ZPOPMAX</code>原语的阻塞版本。</td></tr><tr><td align="left">BZPOPMIN</td><td><strong>5.0.0</strong></td><td>O(log(N))</td><td>BZPOPMIN key [key …] timeout</td><td align="left"><code>BZPOPMIN</code>是有序集合<code>ZPOPMIN</code>原语的阻塞版本。</td></tr><tr><td align="left">ZUNION</td><td><strong>6.2.0</strong></td><td>O(N)+O(M*log(M))</td><td>ZUNION numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX] [WITHSCORES]</td><td align="left">计算给定的一个或多个有序集的并集</td></tr><tr><td align="left">ZUNIONSTORE</td><td><strong>2.0.0</strong></td><td>O(N)+O(M log(M))</td><td>ZUNIONSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX]</td><td align="left">计算给定的一个或多个有序集的并集，并存储在新的有序集合中</td></tr><tr><td align="left">ZINTER</td><td><strong>6.2.0</strong></td><td>O(N<em>K)+O(M</em>log(M))</td><td>ZINTER numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX] [WITHSCORES]</td><td align="left">计算给定的一个或多个有序集的交集</td></tr><tr><td align="left">ZINTERSTORE</td><td><strong>2.0.0</strong></td><td>O(N<em>K)+O(M</em>log(M))</td><td>ZINTERSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX]</td><td align="left">计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合中</td></tr><tr><td align="left">ZDIFF</td><td><strong>6.2.0</strong></td><td>O(L + (N-K)log(N))</td><td>ZDIFF numkeys key [key …] [WITHSCORES]</td><td align="left">计算给定的一个或多个有序集的差集</td></tr><tr><td align="left">ZDIFFSTORE</td><td><strong>6.2.0</strong></td><td>O(L + (N-K)log(N))</td><td>ZDIFFSTORE destination numkeys key [key …]</td><td align="left">计算给定的一个或多个有序集的差集并将结果集存储在新的有序集合中</td></tr><tr><td align="left">ZSCAN</td><td><strong>2.8.0</strong></td><td>O(1) or O(N)</td><td>ZSCAN key cursor [MATCH pattern] [COUNT count]</td><td align="left">迭代有序集合中的元素（包括元素成员和元素分值）</td></tr></tbody></table><hr><h2 id="Redis-Bitmaps"><a href="#Redis-Bitmaps" class="headerlink" title="Redis Bitmaps"></a>Redis Bitmaps</h2><p>位图不是实际的数据类型，而是在字符串类型上定义的一组面向位的操作。由于字符串是二进制安全blob，其最大长度为512MB，因此它们适合设置多达232个不同的位。<br>位操作分为两组：恒定时间的单位操作，如将位设置为1或0，或获取其值，以及对位组的操作，例如在给定的位范围内计算设定位的数量（例如，总体计数）。<br>位图的最大优点之一是，在存储信息时，它们通常可以极大地节省空间。例如，在一个用递增的用户id表示不同用户的系统中，仅使用512MB内存就可以记住40亿用户的一个比特信息（例如，知道用户是否希望接收新闻稿）。</p><h2 id="Redis-HyperLogLogs"><a href="#Redis-HyperLogLogs" class="headerlink" title="Redis HyperLogLogs"></a>Redis HyperLogLogs</h2><p>Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。</p><p>在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。</p><p>但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。</p><h2 id="Redis-Streams"><a href="#Redis-Streams" class="headerlink" title="Redis Streams"></a>Redis Streams</h2><p>Stream是Redis 5.0版本引入的一个新的数据类型，它以更抽象的方式模拟<em>日志数据结构</em>，但日志仍然是完整的：就像一个日志文件，通常实现为以只附加模式打开的文件，Redis流主要是一个仅附加数据结构。至少从概念上来讲，因为Redis流是一种在内存表示的抽象数据类型，他们实现了更加强大的操作，以此来克服日志文件本身的限制。</p><p>Stream是Redis的数据类型中最复杂的，尽管数据类型本身非常简单，它实现了额外的非强制性的特性：提供了一组允许消费者以阻塞的方式等待生产者向Stream中发送的新消息，此外还有一个名为<strong>消费者组</strong>的概念。</p><p>消费者组最早是由名为Kafka（TM）的流行消息系统引入的。Redis用完全不同的术语重新实现了一个相似的概念，但目标是相同的：允许一组客户端相互配合来消费同一个Stream的不同部分的消息。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> REDIS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>REDIS安装</title>
      <link href="articles/2020/2214010312.html"/>
      <url>articles/2020/2214010312.html</url>
      
        <content type="html"><![CDATA[<h1 id="Redis的安装"><a href="#Redis的安装" class="headerlink" title="Redis的安装"></a>Redis的安装</h1><h3 id="安装命令"><a href="#安装命令" class="headerlink" title="安装命令"></a>安装命令</h3><pre class=" language-shell"><code class="language-shell">$ wget https://download.redis.io/releases/redis-6.0.9.tar.gz$ tar xzf redis-6.0.9.tar.gz$ cd redis-6.0.9$ make$ make install </code></pre><p>运行服务端</p><pre class=" language-shell"><code class="language-shell">reids-server  /usr/local/redis/redis.conf</code></pre><p>测试客户端</p><pre class=" language-shell"><code class="language-shell">$ redis-cliredis> pingPONG</code></pre><h3 id="可能遇到的问题"><a href="#可能遇到的问题" class="headerlink" title="可能遇到的问题"></a>可能遇到的问题</h3><h4 id="未安装GCC"><a href="#未安装GCC" class="headerlink" title="未安装GCC"></a>未安装GCC</h4><pre class=" language-shell"><code class="language-shell"># cc: command not foundsudo yum install gcc</code></pre><h4 id="默认内存分配器错误"><a href="#默认内存分配器错误" class="headerlink" title="默认内存分配器错误"></a>默认内存分配器错误</h4><pre class=" language-shell"><code class="language-shell"># fatal error: jemalloc/jemalloc.h: No such file or directorysudo make MALLOC=libc</code></pre><h4 id="gcc版本过低"><a href="#gcc版本过低" class="headerlink" title="gcc版本过低"></a>gcc版本过低</h4><pre class=" language-shell"><code class="language-shell"># error: expected specifier-qualifier-list before ‘_Atomic’sudo yum install centos-release-sclsudo yum install devtoolset-8-gcc*scl enable devtoolset-8 bash# 然后清理下错误编译make distclean</code></pre><h4 id="无法正常关闭redis服务"><a href="#无法正常关闭redis服务" class="headerlink" title="无法正常关闭redis服务"></a>无法正常关闭redis服务</h4><ul><li>客户端报错</li></ul><blockquote><p>127.0.0.1:6379&gt; SHUTDOWN<br>(error) ERR Errors trying to SHUTDOWN. Check logs.</p></blockquote><ul><li>日志信息</li></ul><blockquote><p>User requested shutdown…<br>Saving the final RDB snapshot before exiting.<br>Failed opening the RDB file dump.rdb (in server root dir /usr/local/redis-6.0.9) for saving: Permission denied<br>Error trying to save the DB, can’t exit.</p></blockquote><ul><li>修改权限信息</li></ul><pre class=" language-shell"><code class="language-shell">sudo chmod 777 dump.rdbsudo chmod 777 /usr/local/redisdir</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> REDIS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux设置静态IP</title>
      <link href="articles/2020/2219062811.html"/>
      <url>articles/2020/2219062811.html</url>
      
        <content type="html"><![CDATA[<h3 id="CentOS-7-设置静态IP"><a href="#CentOS-7-设置静态IP" class="headerlink" title="CentOS  7  设置静态IP"></a>CentOS  7  设置静态IP</h3><ol><li><p>查看网卡信息</p><p>执行<code>ifconfig</code>命令查看网卡名称</p><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/linuxifconfig.png"></p><p>如图网卡名称为ens33</p><p>在<code>/etc/sysconfig/network-scripts</code> 文件夹下查找ens33对应的配置文件，如在我的系统中为<code>ifcfg-ens33</code> ，首先备份配置文件（若文件不存在，可自行创建一个）</p><pre class=" language-shell"><code class="language-shell">cp /etc/sysconfig/network-scripts/ifcfg-ens33 /etc/sysconfig/network-scripts/ifcfg-ens33.bakup</code></pre></li><li><p>然后在其中添加以下语句设置静态IP，请勿复制注释信息</p><pre class=" language-shell"><code class="language-shell">DEVICE="ens33"            #描述网卡对应的设备别名BOOTPROTO="static"        #设置网卡获得ip地址的方式，可能的选项为static，默认dhcp动态获取IPADDR="192.168.0.20"       #设置的静态IP地址NETMASK="255.255.255.0"     #子网掩码GATEWAY="192.168.0.1"       #网关地址DNS1="223.5.5.5"           #dns信息DNS2="8.8.8.8"               #dns信息ONBOOT="yes"              # 开机启用</code></pre></li><li><p>重启网络服务</p><pre class=" language-shell"><code class="language-shell">systemctl restart network  //centos 7或nmcli c reload        //centos 8  需重启</code></pre></li></ol><h3 id="Ubuntu-20-04-设置静态IP"><a href="#Ubuntu-20-04-设置静态IP" class="headerlink" title="Ubuntu 20.04 设置静态IP"></a>Ubuntu 20.04 设置静态IP</h3><p>​    ubuntu20版本系统设置静态IP需要修改<code>/etc/netplan</code> 下面的<code>1-network-manager-all.yaml</code>文件</p><ol><li><p>同样执行<code>ifconfig</code>查看当前网卡信息</p><p>网卡依旧是ens33，就不截图了</p></li><li><p>备份原配置文件</p><pre class=" language-shell"><code class="language-shell">sudo cp /etc/netplan/01-network-manager-all.yaml /etc/netplan/01-network-manager-all.yaml.backup</code></pre></li><li><p>修改<code>1-network-manager-all.yaml</code>文件为：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># Let NetworkManager manage all devices on this system</span><span class="token key atrule">network</span><span class="token punctuation">:</span>  <span class="token key atrule">version</span><span class="token punctuation">:</span> <span class="token number">2</span>  <span class="token key atrule">renderer</span><span class="token punctuation">:</span> NetworkManager  <span class="token key atrule">ethernets</span><span class="token punctuation">:</span>      <span class="token key atrule">ens33</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#网卡</span>        <span class="token key atrule">dhcp4</span><span class="token punctuation">:</span> <span class="token boolean important">false </span><span class="token comment" spellcheck="true">#关闭动态获取ip</span>      <span class="token key atrule">addresses</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>192.168.0.21/24<span class="token punctuation">]</span>   <span class="token comment" spellcheck="true">#IP及掩码长度</span>      <span class="token key atrule">geteway4</span><span class="token punctuation">:</span> 192.168.0.1    <span class="token comment" spellcheck="true">#网关</span>      <span class="token key atrule">nameservers</span><span class="token punctuation">:</span>          <span class="token key atrule">addresses</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>223.5.5.5<span class="token punctuation">,</span> 8.8.8.8<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#DNS</span></code></pre></li><li><p>使更改生效</p><pre class=" language-shell"><code class="language-shell">sudo netplan --debug apply</code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CASE </tag>
            
            <tag> LINUX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux创建用户并赋予root权限</title>
      <link href="articles/2020/2209062811.html"/>
      <url>articles/2020/2209062811.html</url>
      
        <content type="html"><![CDATA[<h3 id="一、创建用户"><a href="#一、创建用户" class="headerlink" title="一、创建用户"></a>一、创建用户</h3><p>创建一个带有家目录，并且可以登录bash的用户</p><pre class=" language-shell"><code class="language-shell">su        //切换root用户创建用户useradd -m -s /bin/bash noslime    </code></pre><p>给创建的用户分配密码，并切换到noslime用户</p><pre class=" language-shell"><code class="language-shell">passwd noslimesu - noslime</code></pre><h3 id="二、赋予root权限"><a href="#二、赋予root权限" class="headerlink" title="二、赋予root权限"></a>二、赋予root权限</h3><p>方案一</p><p>修改/etc/sudoers文件，使得用户noslime免密使用sudo命令</p><pre class=" language-shell"><code class="language-shell">echo "nolime ALL=(ALL:ALL)  NOPASSWD:ALL" >> /etc/sudoers</code></pre><p>方案二</p><p>将用户添加到管理员用户组wheel中去，有的linux发行版，需要将<code>/etc/sudoers</code>文件中以下一行的注释打开：</p><pre class=" language-shell"><code class="language-shell">%wheel  ALL=(ALL)       ALL  //centos 7 8 ubuntu20版本默认打开,看一下不费事</code></pre><p>将用户添加到wheel管理员用户组中</p><pre class=" language-shell"><code class="language-shell">usermod -g wheel noslime   //给用户指定主用户组usermod -G wheel noslime   //给用户指定用户组，添加操作，但会去除原有附加组gpasswd -a user_name group_name   //添加用户到组 建议操作gpasswd -d user_name group_name   //将用户从指定组中删除</code></pre><p>修改成功后通过<code>groups username</code> 或 <code>id username</code>查看用户的组是否添加成功，添加成功后如无作用，可<strong>重启系统</strong>使之生效，即可使用sudo命令获得管理员权限。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CASE </tag>
            
            <tag> LINUX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NGINX反向代理与负载均衡</title>
      <link href="articles/2020/2217152711.html"/>
      <url>articles/2020/2217152711.html</url>
      
        <content type="html"><![CDATA[<p>nginx的反向代理与负载均衡是我们日常工作中经常用到的功能，并且给我们带来了较大的便利。</p><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><blockquote><p>​        反向代理在计算机网络中是代理服务器的一种。服务器根据客户端的请求，从其关系的一组或多组后端服务器上获取资源，然后再将这些资源返回给客户端，客户端只会得知反向代理的IP地址，而不知道在代理服务器后面的服务器集群的存在。</p></blockquote><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p><strong>1)提高了内部服务器的安全</strong></p><blockquote><p>​        外部网络用户通过反向代理访问内部服务器，只能看到反向代理服务器的IP地址和端口号，内部服务器对于外部网络是完全不可见的。 此外，没有信息资源被保存在反向代理服务器上。 所有网页程序都存储在内部服务器上。 对反向代理服务器的攻击不会破坏真实的网页信息系统，从而提高了内部服务器的安全性。</p></blockquote><p><strong>2)加快了对内部服务器的访问速度</strong></p><blockquote><p>​        反向代理服务器的缓存功能还可以加快用户的访问速度。</p></blockquote><p><strong>3)节约了有限的IP资源</strong></p><blockquote><p>​         公共网络分配的IP地址数量是有限的。 如果为每个服务器分配了一个公共网络地址，则不可能，反向代理技术可以解决IP地址不足的问题。</p></blockquote><p><strong>4)应用场景</strong></p><blockquote><ul><li>堡垒机，保护后端服务器的安全</li><li>将多个服务器通过虚拟主机的方式发布到公网</li><li>缓存服务器，CDN加速</li></ul></blockquote><h3 id="NGINX反向代理"><a href="#NGINX反向代理" class="headerlink" title="NGINX反向代理"></a>NGINX反向代理</h3><h4 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h4><blockquote><pre><code>server &#123;    listen 80;    server_name localhost;    lacation / &#123;        index index.html index.htm;        proxy_pass  http://target_server:port;  //代理的目标服务器    &#125;&#125;</code></pre></blockquote><h4 id="可配参数"><a href="#可配参数" class="headerlink" title="可配参数"></a>可配参数</h4><blockquote><pre><code>server &#123;listen 80;server_name localhost;    location / &#123;           index index.html index.htm;           proxy_pass  http://target_server:port;  //代理的目标服务器           proxy_set_header Host      $host;       //设置请求主机名           proxy_set_header X-Real-IP $remote_addr;//设置上游访问IP           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for //客户端访问IP           proxy_buffering  on       //默认为on，开启缓冲后端服务器响应           proxy_buffer_size 16k;   //代理服务器保存响应头信息的缓冲区大小，默认情况也为分页大小           proxy_buffers 4 64k;     //用于读响应体的缓冲区数目和大小，默认情况也为分页大小, 网页平均64k以下           proxy_busy_buffers_size 128k;  //用来设置处于busy状态的buffer有多大，默认为proxy_buffers的两倍           proxy_connect_timeout 60;   //和后端服务器连接超时时间           proxy_send_timeout 90;   //向后端服务器发送一次数据包的超时时间           proxy_read_timeout 90;   //定义从后端服务器读取（接收）数据的超时时间           client_max_body_size    10m;    //单次通过nginx上传文件的大小           client_body_buffer_size 128k;    //用户端请求缓冲区的最大字节数           proxy_max_temp_file  1024m      //开启响应缓冲后，临时文件的最大大小, 默认1G           proxy_temp_file_write_size 128k //开启响应缓冲后，每次写数据到临时文件的大小           proxy_temp_path /spool/nginx/proxy_temp 1 2;　　 //缓冲文件位置及命名规则    &#125;&#125;</code></pre></blockquote><p>​        <strong>proxy_busy_buffers_size</strong></p><blockquote><p>配置项<code>proxy_busy_buffers_size</code> 用来设置处于busy状态的buffer有多大，默认为proxy_buffers的两倍。这个参数的作用是限制处于busy（开启响应缓存的情况下，读满数据的缓存响应客户端的过程不能被打断）状态的buffer大小，下述两条配置  {<code>proxy_buffers 4 64k;</code>    <code>proxy_busy_buffers_size 128k;</code>}  便是当用掉两个缓存区（2*64k=128k）的大小后，后面的缓存即使读到数据但不响应给客户端，若读满剩余缓存还不能读完后端服务器响应，则会写到临时文件中。</p></blockquote><p>其他指令：</p><p>​       <strong>proxy_redirect</strong></p><blockquote><p><em>Context: http,server, location</em></p><p>设置后端服务器“Location”响应头和“Refresh”响应头的替换文本。 假设后端服务器返回的响应头是 “Location: <a href="http://localhost:8000/two/some/uri/%E2%80%9D%EF%BC%8C%E9%82%A3%E4%B9%88%E6%8C%87%E4%BB%A4">http://localhost:8000/two/some/uri/”，那么指令</a></p><pre><code>proxy_redirect http://localhost:8000/two/ http://frontend/one/;</code></pre><p>会被重写为  “<code>Location: http://frontend/one/some/uri/</code>”.</p><p>以下指令<code>replacement</code>字符串将省略服务器名</p><pre><code>proxy_redirect http://localhost:8000/two/ /;</code></pre><p>此时将使用代理服务器的主域名和端口号来替换。如果端口是80，可以不加。</p><p>默认的参数<code>default</code>替换使用了location和proxy_pass指令的参数，使用以下两种配置是等价的:</p><pre><code>location /one/ &#123;    proxy_pass     http://upstream:port/two/;    proxy_redirect default;</code></pre><pre><code>location /one/ &#123;    proxy_pass     http://upstream:port/two/;    proxy_redirect http://upstream:port/two/ /one/;</code></pre><p>如果proxy_pass包含变量，则不能使用<code>default</code> ，但是proxy_redirect中可以使用变量，如下：</p><pre><code>proxy_redirect http://localhost:8000/ http://$host:$server_port/;proxy_redirect http://$proxy_host:8000/ /;</code></pre><p>在1.11及以后的版本里，可以使用正则匹配，’’<del>“ 大小写敏感 ，”</del>*” 不区分大小写开始匹配。</p><pre><code>proxy_redirect ~^(http://[^:]+):\d+(/.+)$ $1$2;proxy_redirect ~*/user/([^/]+)/(.+)$      http://$1.example.com/$2;</code></pre><p>可以定义多条</p><pre><code>proxy_redirect default;proxy_redirect http://localhost:8000/  /;proxy_redirect http://www.example.com/ /;</code></pre><p>如果多条指令可以应用到代理服务器的响应头中，只有第一个匹配的被选择。</p><p>使用以下指令，也可以将主机名添加到代理服务器发出的相对重定向：</p><pre><code>proxy_redirect / /;</code></pre></blockquote><p>​       <strong>proxy_next_upstream</strong></p><blockquote><p>当你使用Nginx proxy代理时，如果是代理到后端是使用upstream，那么这个指令就是指定在何种情况下，一个失败的请求应该被发送到下一台后端服务器。</p><p>error – 和后端服务器建立连接时，或向后端服务器发送请求时，或从后端服务器读取响应时，出现错误；</p><p>timeout – 和后端服务器建立连接时，或向后端服务器发送请求时，或从后端服务器读取响应时，出现超时；</p><p>invalid_header – 后端服务器返回空响应或者非法响应头；</p><p>http_500 – 后端服务器返回的响应状态码为500；</p><p>http_502 – 后端服务器返回的响应状态码为502；</p><p>http_503 – 后端服务器返回的响应状态码为503；</p><p>http_504 – 后端服务器返回的响应状态码为504；</p><p>http_404 – 后端服务器返回的响应状态码为404；</p><p>http_403 – 后端服务器返回的响应状态码为403；</p><p>http_429 – 后端服务器返回的响应状态码为429；(1.11.13)</p><p>non_idempotent–通常，如果请求已发送到上游服务器（1.9.13），则使用非幂等方法(POST、LOCK、PATCH)的请求不会传递给下一个服务器；启用此选项显式允许重试此类请求；</p><p>off – 关闭proxy_next_upstream功能—出错就选择另一台上游服务器再次转发。</p><p>只有在没有向客户端发送任何请求的情况下，才有可能将请求传递给下一个服务器。 也就是说，如果在传输响应的过程中发生错误或超时，那么修复这个错误是不可能的。</p><p>将请求传递给下一个服务器可以受到尝试次数和时间的限制，默认均为0， 即失败满足条件立即重试，以下为指令定义 （1.7.5）</p><table><thead><tr><th align="left">Syntax:</th><th><code>proxy_next_upstream_timeout time;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>proxy_next_upstream_timeout 0;</code></td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table><hr><table><thead><tr><th align="left">Syntax:</th><th><code>proxy_next_upstream_tries number;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>proxy_next_upstream_tries 0;</code></td></tr><tr><td align="left">Context:</td><td><code>http</code>, <code>server</code>, <code>location</code></td></tr></tbody></table></blockquote><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><h3 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h3><blockquote><p>负载均衡，英文名称为Load Balance，其含义就是指将互联网或内网的流量（工作任务）进行平衡、分摊到多个操作单元上进行运行，例如FTP服务器、Web服务器、企业核心应用服务器和其它主要任务服务器等，从而协同完成工作任务。</p></blockquote><h3 id="作用-1"><a href="#作用-1" class="headerlink" title="作用"></a>作用</h3><blockquote><p>负载均衡构建在原有网络结构之上，它提供了一种透明且廉价有效的方法扩展服务器和网络设备的带宽、加强网络数据处理能力、增加吞吐量、提高网络的可用性和灵活性。它可以通过流量分发，隐藏实际服务端口，消除服务的单点故障，达到提高应用系统可用性，增强安全性，提升可靠性的要求</p></blockquote><h3 id="NGINX负载均衡"><a href="#NGINX负载均衡" class="headerlink" title="NGINX负载均衡"></a>NGINX负载均衡</h3><h4 id="基本配置-1"><a href="#基本配置-1" class="headerlink" title="基本配置"></a>基本配置</h4><p>默认情况下，使用加权轮询平衡方法在服务器之间分配请求。 在下面的示例中，每7个请求将被分发如下：5个请求转到backend1.example.com，一个请求发送到第二和第三个服务器中的每个服务器。 如果在与服务器通信期间发生错误，请求将被传递到下一个服务器，以此类推，直到所有功能服务器都被尝试为止。 如果无法从任何服务器获得成功的响应，客户端将收到与最后一台服务器通信的结果。</p><blockquote><pre><code>upstream backend &#123;    server backend1.example.com       weight=5;    server backend2.example.com:8080;    server unix:/tmp/backend3;    server backup1.example.com:8080   backup;    server backup2.example.com:8080   backup;&#125;server &#123;    location / &#123;        proxy_pass http://backend;    &#125;&#125;</code></pre></blockquote><blockquote><p>关于 <code>server unix:/tmp/backend3;</code> “unix：”前缀之后指定的UNIX域套接字路径</p><p>Unix domain socket也叫 IPC socket (inter-process communication socket)，即进程间通信 socket，主要用于同一主机上的进程间通信。与主机间的进程通信不同，它不是通过 “IP地址 + TCP或UDP端口号” 的方式进程通信，而是使用 socket 类型的文件来完成通信。</p></blockquote><h5 id="SERVER配置项"><a href="#SERVER配置项" class="headerlink" title="SERVER配置项"></a>SERVER配置项</h5><p>SERVER指定了一台上游服务器的名字，这个名字可以是域名、IP地址端口、UNIX句柄等，在其后还可以跟下列参数:</p><blockquote><ul><li><p><strong>weight=number</strong>：</p><p>​    设置向这台上游服务器转发的权重，默认为1。</p></li><li><p><strong>max_fails=number</strong>：</p><p>​    该选项与fail_timeout配合使用，指在fail_timeout时间段内，如果向当前的上游服务器转 发失败次数超过number，则认为在当前的fail_timeout时间段内这台上游服务器不可用。max_fails默认为1，如果设置为0，则表示 不检查失败次数。</p></li><li><p><strong>fail_timeout=time：fail_timeout</strong></p><p>​    表示该时间段内转发失败多少次后就认为上游服务器暂时不可用，用于优化反向代理功能。它与向上游服务器建立连接的超时时间、读取上游服务器的响应超时时间等完全无关。fail_timeout默认为10秒。</p></li><li><p><strong>down</strong>：</p><p>​    表示所在的上游服务器永久下线，只在使用ip_hash配置项时才有用。</p></li><li><p><strong>backup</strong>：</p><p>​    在使用ip_hash配置项时它是无效的。它表示所在的上游服务器只是备份服务器，只有在所有的非备份上游服务器都失效后，才会向所在的上游服务器转发请求。</p></li></ul></blockquote><h5 id="keepalive"><a href="#keepalive" class="headerlink" title="keepalive"></a>keepalive</h5><blockquote><table><thead><tr><th align="left">Syntax:</th><th><code>keepalive connections;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td>—</td></tr><tr><td align="left">Context:</td><td><code>upstream</code></td></tr></tbody></table><p>This directive appeared in version 1.1.4.</p><p>连接参数设置到上游服务器的空闲keepalive连接的最大数量，这些连接保存在每个工作进程的缓存中。 当超过此数字时，关闭最近使用最少的连接。</p><p>应该特别注意的是，keepalive指令没有限制nginx工作进程可以打开的连接到上游服务器的总数。 连接参数应该设置为足够小的数字，以便上游服务器处理新的传入连接。</p><p>当使用默认轮询方法以外的负载平衡方法时，必须在keepalive指令之前激活它们。</p><p>对于HTTP，proxy_http_version指令应该设置为“1.1”，并且应该清除“连接”头字段：</p><pre><code>upstream http_backend &#123;    server 127.0.0.1:8080;    keepalive 16;&#125;server &#123;    ...    location /http/ &#123;        proxy_pass http://http_backend;        proxy_http_version 1.1;        proxy_set_header Connection &quot;&quot;;        ...    &#125;&#125;</code></pre><p>或者，HTTP/1.0持久连接可以通过将“Connection：Keep-Alive”头字段传递给上游服务器来使用，尽管不推荐使用此方法。</p><p>对于FastCGI服务器，需要为保持连接设置fastcgi_keep_conn以工作：</p><pre><code>upstream fastcgi_backend &#123;    server 127.0.0.1:9000;    keepalive 8;&#125;server &#123;    ...    location /fastcgi/ &#123;        fastcgi_pass fastcgi_backend;        fastcgi_keep_conn on;        ...    &#125;&#125;</code></pre><p>SCGI和uwsgi协议没有保持连接的概念。</p></blockquote><h5 id="keepalive-requests"><a href="#keepalive-requests" class="headerlink" title="keepalive_requests"></a>keepalive_requests</h5><blockquote><table><thead><tr><th align="left">Syntax:</th><th><code>keepalive_requests number;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>keepalive_requests 100;</code></td></tr><tr><td align="left">Context:</td><td><code>upstream</code></td></tr></tbody></table><p>This directive appeared in version 1.15.3.</p><p>设置可以通过一个保持连接服务的请求的最大数量。 请求的最大数量后，连接关闭。<br>定期关闭连接是必要的，以释放每个连接内存分配。 因此，使用过高的最大请求数可能导致内存使用过多，不推荐使用。</p></blockquote><h5 id="keepalive-timeout"><a href="#keepalive-timeout" class="headerlink" title="keepalive_timeout"></a>keepalive_timeout</h5><blockquote><table><thead><tr><th align="left">Syntax:</th><th><code>keepalive_timeout timeout;</code></th></tr></thead><tbody><tr><td align="left">Default:</td><td><code>keepalive_timeout 60s;</code></td></tr><tr><td align="left">Context:</td><td><code>upstream</code></td></tr></tbody></table><p>This directive appeared in version 1.15.3.</p><p>设置一个到上游服务器的空闲保持连接超时时间。</p></blockquote><h4 id="负载均衡算法"><a href="#负载均衡算法" class="headerlink" title="负载均衡算法"></a>负载均衡算法</h4><h5 id="1、轮询（默认）"><a href="#1、轮询（默认）" class="headerlink" title="1、轮询（默认）"></a>1、轮询（默认）</h5><p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</p><blockquote><p>upstream myapp1 {<br>        server srv1.example.com;<br>        server srv2.example.com;<br>        server srv3.example.com;<br>}</p></blockquote><h5 id="2、weight"><a href="#2、weight" class="headerlink" title="2、weight"></a>2、weight</h5><p>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。</p><blockquote><p>upstream myapp1 {<br>        server srv1.example.com weight=3;<br>        server srv2.example.com weight=2;<br>        server srv3.example.com weight=2;<br>    }</p></blockquote><h5 id="3、least-conn"><a href="#3、least-conn" class="headerlink" title="3、least_conn"></a>3、least_conn</h5><p>指定组应该使用负载均衡方法，其中将请求传递给活动连接数量最少的服务器，同时考虑到服务器的权重。 如果有几个这样的服务器，则使用加权循环平衡方法依次尝试。</p><blockquote><p>upstream myapp1 {<br>    least_conn;<br>    server srv1.example.com;<br>    server srv2.example.com;<br>    server srv3.example.com;<br>}</p></blockquote><h5 id="4、ip-hash"><a href="#4、ip-hash" class="headerlink" title="4、ip_hash"></a>4、ip_hash</h5><p>每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题<br>如果其中一个服务器需要暂时移除，则应该用向下参数标记，以保持客户端IP地址的当前散列。</p><blockquote><p>upstream myapp1 {<br>        ip_hash;<br>        server srv1.example.com;<br>        server srv2.example.com  down;<br>        server srv3.example.com;<br>    }</p></blockquote><h5 id="5、hash-key-consistent"><a href="#5、hash-key-consistent" class="headerlink" title="5、hash key [consistent]"></a>5、<strong>hash</strong> key [<code>consistent</code>]</h5><p>  客户机-服务器映射基于散列键值。 键可以包含文本，变量及其组合。 请注意，从组中添加或删除服务器可能会导致将大多数键重映射到不同的服务器。 该方法与缓存：Memcached Perl库兼容。如果指定了一致参数，则将使用ketama一致性散列方法。 该方法确保当一个服务器被添加到或从组中删除时，只有少数密钥将被重新映射到不同的服务器。 这有助于为缓存服务器实现更高的缓存命中率。 该方法与缓存：Memcached：：Fast Perl库兼容，ketama_points参数设置为160。</p><blockquote><p>upstream myapp1 {<br>        hash $request_uri;<br>        server srv1.example.com;<br>        server srv2.example.com;<br>        server srv3.example.com;<br>    }</p></blockquote><h5 id="6、fair（第三方）"><a href="#6、fair（第三方）" class="headerlink" title="6、fair（第三方）"></a>6、fair（第三方）</h5><p>​    按后端服务器的响应时间来分配请求，响应时间短的优先分配。 需要安装fair模块</p><blockquote><p>​    upstream myapp1 {<br>​        fair;<br>​        server srv1.example.com;<br>​        server srv2.example.com;<br>​        server srv3.example.com;<br>​    }</p></blockquote><p>​    ……………………………………………………………………………………………………………………………</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NGINX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NGINX的web服务</title>
      <link href="articles/2020/2218122711.html"/>
      <url>articles/2020/2218122711.html</url>
      
        <content type="html"><![CDATA[<h1 id="nginx的web服务"><a href="#nginx的web服务" class="headerlink" title="nginx的web服务"></a>nginx的web服务</h1><p>nginx这款优秀的web服务器，作为后起之秀，在日益拉近与服务器老大哥Apathe的距离，自然有启独特之处，所以值得认真学习一下。本文是一次自己学习nginx的课程记录，课程来源：<a href="https://www.bilibili.com/video/BV1fr4y1c7Gz">baism</a> </p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h4 id="默认网站"><a href="#默认网站" class="headerlink" title="默认网站"></a><strong>默认网站</strong></h4><p>如果nginx只有一个server，这个server就是默认的网站，会默认访问index.html， 以下为初始的默认网站</p><pre><code>server &#123;    listen       80;    server_name  localhost;    location / &#123;        root   html;        index  index.html index.htm;    &#125;    error_page   500 502 503 504  /50x.html;        location = /50x.html &#123;        root   html;    &#125;&#125;</code></pre><h4 id="目录浏览"><a href="#目录浏览" class="headerlink" title="目录浏览"></a><strong>目录浏览</strong></h4><p>显示服务器根目录的目录列表，需要删除默认的index.html文件</p><pre><code>server &#123;    listen       80;    server_name  localhost;    location / &#123;        autoindex on;  //开启目录浏览        autoindex_exact_size off;  //关闭确切大小，便于人眼识别。默认为bytes.        autoindex_localtime on;   //显示文件的服务器时间    &#125;    error_page   500 502 503 504  /50x.html;        location = /50x.html &#123;        root   html;    &#125;&#125;</code></pre><h4 id="访问控制"><a href="#访问控制" class="headerlink" title="访问控制"></a><strong>访问控制</strong></h4><p>见文知意，访问控制就是对访问者进行限制，以下根据具体IP控制访问</p><pre class=" language-config"><code class="language-config">#只允许本机访问a目录，其他返回百度location /a &#123;    autoindex on;    allow 127.0.0.1;    deny all;    return http://www.biadu.com;&#125;</code></pre><h4 id="登录验证"><a href="#登录验证" class="headerlink" title="登录验证"></a><strong>登录验证</strong></h4><p>需要输入用户及密码才能访问，可以使用htpasswd或openssl等生成用户密码</p><ol><li><p>安装htpasswod工具，在http-tools包下</p><pre class=" language-shell"><code class="language-shell">yum -y install httpd-tools</code></pre></li><li><p>生成用户密码</p><pre class=" language-shell"><code class="language-shell">mkdir /usr/local/nginx/passwdhtpasswd -c /usr/local/nginx/passwd/htpasswd username</code></pre></li></ol><ol start="3"><li><p>配置pass目录的验证需要登录</p><p>设置登录后的显示信息</p><pre class=" language-shell"><code class="language-shell">echo "Welcome to login" > index.html</code></pre><p>配置文件</p><pre><code>location /pass &#123;    auth_basic &quot;Login verification&quot;;    auth_basic_user_file /usr/local/nginx/passwd/htpasswd;&#125;</code></pre></li></ol><h4 id="防止盗链"><a href="#防止盗链" class="headerlink" title="防止盗链"></a><strong>防止盗链</strong></h4><p>防盗链功能基于HTTP协议支持的Referer机制，通过Referer跟踪来源，对来源进行识别和判断。</p><pre><code>location ~* \.(png|gif|bmp)$ &#123;alias /data/images/;    valid_referers none blocked *.images.com;    if ($invalid_referer) &#123;       return 403;    &#125;&#125;</code></pre><h4 id="虚拟主机"><a href="#虚拟主机" class="headerlink" title="虚拟主机"></a>虚拟主机</h4><ol><li><p>基于IP的虚拟主机 </p><pre><code>server &#123;    listen       192.168.0.20:80;    location / &#123;        root   html/app1;        index  index.html index.htm index.php;    &#125;&#125;server &#123;    listen       192.168.0.21:80;    location / &#123;        root   html/app2;        index  index.html index.htm;    &#125;&#125;</code></pre></li><li><p>基于端口的虚拟主机</p><pre><code>基于端口server &#123;    listen       80;    server_name  www.demo.com;    location / &#123;        root   html/app1;        index  index.html index.htm index.php;    &#125;&#125;server &#123;    listen       8080;    server_name  www.demo.com;    location / &#123;        root   html/app2;        index  index.html index.htm;    &#125;&#125;</code></pre></li><li><p>基于域名的虚拟主机</p><pre><code>server &#123;    listen       80;    server_name  app1.demo.com;    location / &#123;        root   html/app1;        index  index.html index.htm index.php;    &#125;&#125;server &#123;    listen       80;    server_name  app2.demo.com;    location / &#123;        root   html/app2;        index  index.html index.htm;    &#125;&#125;</code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NGINX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NGINX配置文件</title>
      <link href="articles/2020/2223132411.html"/>
      <url>articles/2020/2223132411.html</url>
      
        <content type="html"><![CDATA[<p>nginx的配置文件大致可以分为三个部分：全局块、EVENTS块、HTTP块，示意图如下</p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/nginx.conf.png" alt="nginx.conf.png" style="zoom:80%;" /><h3 id="全局块"><a href="#全局块" class="headerlink" title="全局块"></a>全局块</h3><p>从配置文件开始到events块之间的内容，主要会设置一些影响nginx服务器整体运行的配置指令，一般有运行nginx服务器的用户组，nginx进程pid存放路径，错误日志存放路径，允许生成worker process数等。</p><pre class=" language-config"><code class="language-config">#配置worker子进程用户或者组，默认nobody，安全问题，建议用nobody#user  nobody;#worker数和服务器的cpu数相等是最为适宜worker_processes  2;#配置Nginx worker进程最大打开文件数worker_rlimit_nofile 65535;#work绑定cpu(4 work绑定4cpu)worker_cpu_affinity 0001 0010 0100 1000#work绑定cpu (4 work绑定8cpu中的4个) 。worker_cpu_affinity 0000001 00000010 00000100 00001000  #error_log path(存放路径) level(日志等级)path表示日志路径，level表示日志等级，#具体如下：[ debug | info | notice | warn | error | crit ]# 从左至右，日志详细程度逐级递减，即debug最详细，crit最少，默认为crit。 #error_log  logs/error.log;#error_log  logs/error.log  notice;#error_log  logs/error.log  info;#进程运行文件所在位置#pid        logs/nginx.pid;</code></pre><h3 id="EVENTS块"><a href="#EVENTS块" class="headerlink" title="EVENTS块"></a>EVENTS块</h3><p>此部分涉及的主要是nginx工作模式，包括每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启网络连接序列化等。</p><pre class=" language-config"><code class="language-config">events &#123;    #这个值是表示每个worker进程所能建立连接的最大值，所以，一个nginx能建立的最大连接数，应该是                     #Max_client=worker_connections * worker_processes。    #当然，这里说的是最大连接数，对于HTTP请求本地资源来说，能够支持的最大并发数量是worker_connections *         #worker_processes，    #如果是支持http1.1的浏览器每次访问要占两个连接，    #所以普通的静态访问最大并发数是： worker_connections * worker_processes /2，    #而如果是HTTP作为反向代理来说，最大并发数量应该是worker_connections * worker_processes/4。    #因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。    worker_connections  1024;      #Nginx支持的工作模式有select、poll、kqueue、epoll、rtsig和/dev/poll。         #其中select和poll都是标准的工作模式，kqueue和epoll是高效的工作模式    #这个值是表示nginx要支持哪种多路io复用。    #一般的Linux选择epoll, 如果是(*BSD)系列的Linux使用kquene。    #windows版本的nginx不支持多路IO复用，这个值不用配。    use epoll;    #当一个worker抢占到一个链接时，是否尽可能的让其获得更多的连接,默认是off 。    multi_accept on;    #设置网路连接序列化，防止惊群现象发生，默认为on，这是一种保守的设置    #但是如果你的网站访问量比较大，为了系统的吞吐量，我还是建议大家关闭它。    accept_mutex  on;&#125;</code></pre><h3 id="HTTP-块"><a href="#HTTP-块" class="headerlink" title="HTTP 块"></a>HTTP 块</h3><p>这算是 Nginx 服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。 需要注意的是：http 块也可以包括 http全局块、[upstream] 、server 块。</p><h4 id="HTTP全局块"><a href="#HTTP全局块" class="headerlink" title="HTTP全局块"></a>HTTP全局块</h4><p>http全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。</p><p>以下给出一些参数设置，为了方便描述，全写在了一起。其中很多参数可以设置在http、server、location处，实际应根据具体业务设置位置。 一般来说，设置的位置越在内层，优先级越高。 详见nginx <a href="http://nginx.org/en/docs/http/ngx_http_core_module.html">官方文档</a></p><pre class=" language-config"><code class="language-config">http &#123;    #当web服务器收到静态的资源文件请求时，依据请求文件的后缀名在服务器的MIME配置文件中    #找到对应的MIME Type，再根据MIME Type设置HTTP Response的Content-Type，然后浏览器    #根据Content-Type的值处理文件。    include       mime.types;    #如果 不能从mime.types找到映射的话，用以下作为默认值    default_type  application/octet-stream;    #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.    server_names_hash_bucket_size 128;    ###################################HTTP请求####################################    #一个请求完成之后还要保持连接多久    keepalive_timeout  5;    #设定通过nginx上传文件的大小    client_max_body_size 300m;    #请求体缓存大小    client_body_buffer_size 64k;    #临时文件位置    #小于client_body_buffer_size直接在内存中高效存储。如果大于client_body_buffer_size小于client_max_body_size会存储临时文件，临时文件位于client_body_temp下，一定要有权限。    client_body_temp_path  /spool/nginx/client_body_temp 3 2;    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。    client_header_buffer_size 4k;    #读取大型客户端请求头的缓冲区的最大数量和大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取    large_client_header_buffers 8 128k;    #########################################################################     ###################################日志####################################     #访问日志位置  server、location中若有日志配置，优先级更高     access_log  logs/host.access.log  main;     access_log  logs/host.access.404.log  log404;     #日志格式化     log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '     '$status $body_bytes_sent "$http_referer" '     '"$http_user_agent" "$http_x_forwarded_for"';     #########################################################################    #################################高效文件传输######################################    #此配置项用来在两个文件描述符之间直接传递数据(完全在内核中操作)，从而避免了数据在内核         #缓冲区和用户缓冲区之间的拷贝，操作效率很高，被称之为零拷贝，适用于有大文件上传下载的情况         #如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统负载    #可以在http块，server块，location块。    sendfile  on;    #此选项允许或禁止使用sock的TCP_CORK的选项，此选项仅在使用sendfile的时候使用    #用户层可通过setsockopt系统调用设置TCP套接口的TCP_CORK选项。开启时，内核将阻塞不完整的报文，当关闭此选项时，发送阻塞的报文。此处的不完整指的是应用层发送的数据长度不足一个MSS长度。使用场景是在调用sendfile发送文件内容之前，提前发送一个描述文件信息的头部数据段，并且阻塞住此头部数据，与之后的sendfile数据一同发送。或者用于优化吞吐性能。但是，TCP_CORK最多只能将数据阻塞200毫秒，如果超过此时间值，内核将自动发送阻塞的数据       tcp_nopush on;       #tcp_nodelay off 会增加通信的延时，但是会提高带宽利用率。适用于在高延时、数据量大的通信场景    #tcp_nodelay on 会增加小包的数量，但是可以提高响应速度。适用于及时性高的通信场景    #tcp_nodelay与tcp_nopush是互斥的    tcp_nodelay off;    #########################################################################    #################################gzip###################################    #开启或者关闭gzip模块    #gzip  on ;    #设置允许压缩的页面最小字节数，页面字节数从header头中的Content-Length中进行获取。    #gzip_min_lenth 1k;    # gzip压缩比，1 压缩比最小处理速度最快，9 压缩比最大但处理最慢（传输快但比较消耗cpu）    #gzip_comp_level 4;    #匹配MIME类型进行压缩，（无论是否指定）"text/html"类型总是会被压缩的。    #gzip_types types text/plain text/css application/json  application/x-javascript text/xml      #########################################################################    ##############################文件缓存###########################################    #动静分离  指定缓存启用    #服务器端静态资源缓存，最大缓存到内存中的文件数，非活动的（没要求到的文件）会在20秒后从缓存中释放    open_file_cache max=102400 inactive=20s;       #活跃期限内最少使用的次数，否则视为不活跃。    open_file_cache_min_uses 2;    #验证缓存是否活跃的时间间隔    open_file_cache_valid 30s;    #文件错误是否缓存    open_file_cache_errors on    #########################################################################    #################################代理服务器###################################    #后端服务器连接的超时时间_发起握手等候响应超时时间    proxy_connect_timeout 90;    #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）    proxy_read_timeout 180;    #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据    proxy_send_timeout 180;    #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小    proxy_buffer_size 256k;    #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k    proxy_buffers 4 256k;    #proxy_busy_buffers_size不是独立的空间，他是proxy_buffers和proxy_buffer_size的一部分。nginx会在没有完全读完后端响应就开始向客户端传送数据，所以它会划出一部分busy状态的buffer来专门向客户端传送数据(建议为proxy_buffers中单个缓冲区的2倍)，然后它继续从后端取数据。proxy_busy_buffer_size参数用来设置处于busy状态的buffer有多大。1）如果完整数据大小小于busy_buffer大小，当数据传输完成后，马上传给客户端；2）如果完整数据大小不小于busy_buffer大小，则装满busy_buffer后，马上传给客户端；    proxy_busy_buffers_size 256k;    #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长    proxy_temp_file_write_size 256k;    #设置内存缓存空间大小为200MB，1天没有被访问的内容自动清除，硬盘缓存空间大小为30GB。    proxy_cache_path /data/proxy_cache_dir levels=1:2 keys_zone=cache_one:200m inactive=1d max_size=30g;    #表示使nginx阻止HTTP应答代码为300或者更高的应答    proxy_intercept_errors on;    #######################################################################################        upstream streamname&#123;...&#125;    server &#123;...&#125;&#125;</code></pre><ol><li><p>访问日志格式化参数说明</p><p>注：log_format可设为json格式以方便后续分析处理</p></li></ol><blockquote><p>​    #$http_x_forwarded_for 用以记录客户端的ip地址；</p><p>​    #$remote_addr  上一级代理的IP地址；</p><p>​    #$remote_user：用来记录客户端用户名称；<br>​    #$time_local： 用来记录访问时间与时区；<br>​    #$request： 用来记录请求的url与http协议；<br>​    #$status： 用来记录请求状态；成功是200，<br>​    #$body_bytes_sent ：记录发送给客户端文件主体内容大小；<br>​    #$http_referer：用来记录从那个页面链接访问过来的；<br>​    #$http_user_agent：记录客户浏览器的相关信息；</p><p>如下生成一种json格式的日志</p><pre><code>log_format main_json &#39;&#123;&quot;@timestamp&quot;:&quot;$time_local&quot;,&#39;&#39;&quot;client_ip&quot;: &quot;$remote_addr&quot;,&#39;&#39;&quot;request&quot;: &quot;$request&quot;,&#39;&#39;&quot;status&quot;: &quot;$status&quot;,&#39;&#39;&quot;bytes&quot;: &quot;$body_bytes_sent&quot;,&#39;&#39;&quot;x_forwarded&quot;: &quot;$http_x_forwarded_for&quot;,&#39;&#39;&quot;referer&quot;: &quot;$http_referer&quot;&#39;&#39;&#125;&#39;;access_log logs/access_json.log main_json;</code></pre></blockquote><ol start="2"><li>临时文件存储位置     </li></ol><blockquote><p>Syntax: client_body_temp_path path [level1 [level2 [level3]]]; </p><p>Default:    client_body_temp_path client_body_temp; </p><p>Context:    http, server, location</p><p>client_body_temp_path  /spool/nginx/client_body_temp 3 2 1;     //3 2 1代表目录名称长度</p><p>以上设置可能产生缓存文件格式：/spool/nginx/client_temp/456/78/9/20201127</p><p>chown -R username:usergroup /spool/nginx/client_body_temp  //为防止权限问题，可为文件设置所有者</p></blockquote><ol start="3"><li>文件引入</li></ol><blockquote><p>​    若server较多，为保持配置文件结构清晰，可以每个虚拟主机另起一个配置文件，如：<br>​    include /etc/nginx/conf.d/*.conf;  //配置在http全局块</p></blockquote><h4 id="Upstream"><a href="#Upstream" class="headerlink" title="Upstream"></a>Upstream</h4><p>upstream是nginx的HTTP Upstream模块，此模块不是必须的，这个模块通过一个指定的调度算法来实现客户端IP到后端服务器的负载均衡。</p><p>upstream中服务器的常见参数</p><blockquote><p>weight<code>=</code><em>number</em>   设置服务器的权重，默认为1</p><p>max_conns=number  限制到代理服务器的最大同时连接数，默认为0</p><p>fail_timeout=time     服务器不可用的时间 默认为10秒</p><p>max_fails=number   设置在fail_timeout参数设置的持续时间内与服务器通信的失败尝试次数</p><p>backup    备用服务器，主服务器不可用时启用，不能和hash和random负载平衡方法一起使用</p><p>down  标记服务器永久不可用</p></blockquote><pre class=" language-config"><code class="language-config">http &#123;    ...    # 1、轮询（默认）    # 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。     upstream myapp1 &#123;        server srv1.example.com;        server srv2.example.com;        server srv3.example.com;    &#125;    # 2、最小连接负载均衡    # nginx将尝试不使用存在过多的请求的应用服务器，而是将新请求分发到不太繁忙的服务器    upstream myapp1 &#123;        least_conn;        server srv1.example.com;        server srv2.example.com;        server srv3.example.com;    &#125;    # 3、指定权重    # 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。    upstream myapp1 &#123;        server srv1.example.com weight=3;        server srv2.example.com weight=2;        server srv3.example.com weight=2;    &#125;    #4、IP绑定 ip_hash    # 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。    upstream myapp1 &#123;        ip_hash;        server srv1.example.com;        server srv2.example.com;        server srv3.example.com;    &#125;    #5、备机方式 backup    # 正常情况不访问设定为backup的备机，只有当所有非备机全都宕机的情况下，服务才会进备机。    # backup 不能和ip_hash一起使用    upstream myapp1 &#123;        server srv1.example.com;        server srv2.example.com;        server srv3.example.com backup;    &#125;    #6、fair（第三方）    #按后端服务器的响应时间来分配请求，响应时间短的优先分配。 需要安装fair模块    upstream myapp1 &#123;        fair;        server srv1.example.com;        server srv2.example.com;        server srv3.example.com;    &#125;    #7、url_hash（第三方） 需要安装url_hash模块    #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。    upstream myapp1 &#123;        server srv1.example.com;        server srv2.example.com;        server srv3.example.com;        hash $request_uri    &#125;      server &#123;        listen 80;        location / &#123;            proxy_pass http://myapp1;      &#125;&#125;</code></pre><h4 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h4><p>server块：配置虚拟主机的相关参数，一个http中可以有多个server。而server块又包含多个<strong>location块</strong></p><p>location块：配置请求的路由，以及各种页面的处理情况。</p><pre class=" language-config"><code class="language-config">http &#123;    ...    upstream myserver&#123;&#125;    server &#123;        #监听端口号        listen       80;        #服务名        server_name  192.168.161.130;        #字符集        #charset utf-8;    #location [=|~|~*|^~] /uri/ &#123; … &#125;       # = 精确匹配    # ~ 正则匹配，区分大小写    # ~* 正则匹配，不区分大小写    # ^~  关闭正则匹配    #匹配原则：    # 1、所有匹配分两个阶段，第一个叫普通匹配，第二个叫正则匹配。    # 2、普通匹配，首先通过“=”来匹配完全精确的location        # 2.1、 如果没有精确匹配到， 那么按照最大前缀匹配的原则，来匹配location        # 2.2、 如果匹配到的location有^~,则以此location为匹配最终结果，如果没有那么会把匹配的结果暂存，继续进行正则匹配。        # 3、正则匹配，依次从上到下匹配前缀是~或~*的location, 一旦匹配成功一次，则立刻以此location为准，不再向下继续进行正则匹配。        # 4、如果正则匹配都不成功，则继续使用之前暂存的普通匹配成功的location.        # 匹配任何查询，因为所有请求都以 / 开头。但是正则表达式规则和长的块规则将被优先和查询匹配。        location / &#123;           #定义服务器的默认网站根目录位置        root   html;        #默认访问首页索引文件的名称        index  index.html index.htm;        #反向代理路径         proxy_pass http://myapp1;        #反向代理的超时时间         proxy_connect_timeout 10;         proxy_redirect default;         &#125;         location  /images/ &#123;                root images ;            deny 127.0.0.1;  #拒绝的ip              allow 172.18.5.54; #允许的ip         &#125;         # 匹配任何以/images/jpg/ 开头的任何查询并且停止搜索。任何正则表达式将不会被测试。          location ^~ /images/jpg/ &#123;              root images/jpg/ ;         &#125;         location ~*.(gif|jpg|jpeg)$ &#123;           #所有静态文件直接读取硬盘              root pic ;          #expires定义用户浏览器缓存的时间为3天，如果静态页面不常更新，可以设置更长，          #这样可以节省带宽和缓解服务器的压力              expires 3d; #缓存3天         &#125;        #error_page  404              /404.html;        # redirect server error pages to the static page /50x.html        error_page   500 502 503 504  /50x.html;        location = /50x.html &#123;            root   html;        &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NGINX </tag>
            
            <tag> CONFIG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NGINX简介及安装</title>
      <link href="articles/2020/2242062311.html"/>
      <url>articles/2020/2242062311.html</url>
      
        <content type="html"><![CDATA[<p>nginx这款优秀的反向代理服务器，在网站的运行中占的比例越来越高，不管工作中是否用到，都值得去学习一下，一个好的开头必不可少，本文记录一下nginx的安装。</p><h3 id="一、nginx概述"><a href="#一、nginx概述" class="headerlink" title="一、nginx概述"></a>一、nginx概述</h3><p><em>Nginx</em> (engine x) 是一个高性能的<a href="https://baike.baidu.com/item/HTTP">HTTP</a>和<a href="https://baike.baidu.com/item/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/7793488">反向代理</a>web服务器，同时也提供了IMAP/POP3/SMTP服务，nginx能够达到50000次并发，性能优异，且占用内存较小。国内大型的站点，例如百度、京东、新浪、网易、腾讯、淘宝等，都使用了<a href="http://nginx.org/">nginx</a> .</p><h3 id="二、常用功能"><a href="#二、常用功能" class="headerlink" title="二、常用功能"></a>二、常用功能</h3><ol><li><p>反向代理</p><ul><li> 正向代理：局域网中的客户端(如浏览器)访问Internet，通过配置代理访问，这种代理用户访问网站代理就是正向代理。</li><li> 反向代理：向代理服务器发送请求，反向代理转发到实际服务器，客户端不需要做任何配置。目标服务器对客户端是透明的。</li></ul></li><li><p>负载均衡</p><p>nginx服务器收到请求后，分发到不同的服务器上去处理，提高系统负载的过程，也就是我们所说的负载均衡。</p></li><li><p>Web缓存</p><p>Nginx可以对不同的文件做不同的缓存处理，配置灵活，并且支持FastCGI_Cache，主要用于对FastCGI的动态程序进行缓存。配合着第三方的ngx_cache_purge，对制定的URL缓存内容可以的进行增删管理</p></li></ol><h3 id="三、nginx安装"><a href="#三、nginx安装" class="headerlink" title="三、nginx安装"></a>三、nginx安装</h3><h4 id="YUM安装"><a href="#YUM安装" class="headerlink" title="YUM安装"></a>YUM安装</h4><ol><li>安装先决条件：</li></ol><blockquote><pre><code>sudo yum install yum-utils</code></pre></blockquote><ol start="2"><li>若要设置 yum 存储库，请创建具有以下内容命名的文件：<code>/etc/yum.repos.d/nginx.repo</code></li></ol><blockquote><pre class=" language-shell"><code class="language-shell">[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true[nginx-mainline]name=nginx mainline repobaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/gpgcheck=1enabled=0gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true</code></pre></blockquote><ol start="3"><li>默认情况下，使用稳定 nginx 包的存储库。如果要使用主线 nginx 包，请运行以下命令：</li></ol><blockquote><pre class=" language-shell"><code class="language-shell">sudo yum-config-manager --enable nginx-mainline</code></pre></blockquote><ol start="4"><li>要安装 nginx，请运行以下命令：</li></ol><blockquote><pre class=" language-shell"><code class="language-shell">sudo yum install nginx</code></pre></blockquote><ol start="5"><li><p>当提示接受 GPG 密钥时，请验证指纹是否匹配，如果匹配，请接受它。</p><p><code>573B FD6B 3D8F BC64 1079 A6AB ABF5 BD82 7BD9 BF62</code></p></li><li><p>命令手册 例：/usr/bin/nginx -v 查看版本情况</p></li></ol><blockquote><pre class=" language-shell"><code class="language-shell">-?,-h         : this help-v            : show version and exit-V            : show version and configure options then exit-t            : test configuration and exit-T            : test configuration, dump it and exit-q            : suppress non-error messages during configuration testing-s signal     : send signal to a master process: stop, quit, reopen, reload-p prefix     : set prefix path (default: NONE)-c filename   : set configuration file (default: conf/nginx.conf)-g directives : set global directives out of configuration file</code></pre></blockquote><ol start="7"><li>YUM安装默认位置：</li></ol><blockquote><pre class=" language-shell"><code class="language-shell">/usr/sbin/nginx   //执行程序位置/etc/nginx/  // nginx.conf所在/usr/share/nginx  //静态文件/var/log/nginx/  //访问记录日志 错误日志/var/run/nginx.pid   //进程ID文件</code></pre></blockquote><h4 id="从源包手动编译安装"><a href="#从源包手动编译安装" class="headerlink" title="从源包手动编译安装"></a>从源包手动编译安装</h4><ol><li><p>安装所需依赖</p><ul><li><p>gcc是编程语言编译器，支持c、c++等，而nginx是由C语言编写而成，所以手动安装的编译过程要依赖gcc编译器。</p></li><li><p>pcre库是一组函数，它们使用与 Perl 5 相同的语法和语义实现正则表达式模式匹配，nginx的请求分发需要用到正则匹配。 其中devel代表供开发使用，包括头文件链接库等， 如果安装基于pcre开发的程序，只需要安装pcre包就行了，但编译使用了PCRE库的源代码，则需要pcre-devel。</p></li><li><p>zlib 是通用的压缩库，nginx的压缩模块需要用到，主要对网络传输的资源进行压缩以提高传输效率。</p></li><li><p>nginx涉及到很多加密、解密的功能。如https中需要用到加密解密，所以编译的时候需要使用openssl</p></li></ul></li></ol><blockquote><pre class=" language-shell"><code class="language-shell">yum install -y gcc pcre-devel zlib-devel openssl-devel  //解决依赖问题</code></pre></blockquote><ol start="2"><li>下载并解压nginx程序包</li></ol><blockquote><pre class=" language-shell"><code class="language-shell">wget -P /usr/src https://nginx.org/download/nginx-1.18.0.tar.gztar zxvf nginx-1.18.0.tar.gz</code></pre></blockquote><ol start="3"><li><p>进入解压文件夹构建程序</p><p>configure命令作用是分析程序建立环境，检查是否安装了必要的外部工具和组件，</p><p>并创建配置文件makefile，此文件描述了包括最终完成的程序各组件之间的关系和依赖性<br>configure命令有多个可选项，如下所用的–prefix是告诉程序的安装位置<br>如不指定 则./configure –help里面有个path，就是默认安装路径<br>关于nginx的configure更多选项设置 详见 <a href="http://nginx.org/en/docs/configure.html">Configure</a></p></li></ol><blockquote><pre class=" language-shell"><code class="language-shell">cd nginx-1.18.0./configure  --prefix=/usr/local/nginx    </code></pre></blockquote><ol start="4"><li>编译与安装</li></ol><blockquote><pre class=" language-shell"><code class="language-shell">$ make && make install </code></pre></blockquote><ol start="5"><li>常用命令</li></ol><blockquote><pre class=" language-shell"><code class="language-shell">/usr/local/nginx/sbin/nginx    //启动/usr/local/nginx/sbin/nginx -c 具体nginx.conf配置文件路径   //根据指定配置文件启动/usr/local/nginx/sbin/nginx -v //查看版本/usr/local/nginx/sbin/nginx -s stop //停止/usr/local/nginx/sbin/nginx -s reload  //热启动，重新加载配置文件</code></pre></blockquote><ol start="6"><li><p>使用systemctl管理nginx</p><p>创建一个nginx.service文件</p></li></ol><blockquote><pre class=" language-shell"><code class="language-shell">touch /usr/lib/systemd/system/nginx.service</code></pre></blockquote><p>​    编辑文件内容为：</p><blockquote><pre class=" language-shell"><code class="language-shell">[Unit]Description=nginx - high performance web serverDocumentation=http://nginx.org/en/docs/After=network-online.target remote-fs.target nss-lookup.targetWants=network-online.target[Service]Type=forkingPIDFile=/var/run/nginx.pidExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.confExecReload=/bin/sh -c "/bin/kill -s HUP $(/bin/cat /var/run/nginx.pid)"ExecStop=/bin/sh -c "/bin/kill -s TERM $(/bin/cat /var/run/nginx.pid)PrivateTmp=true    //设置是否使用私有的tmp目录[Install]WantedBy=multi-user.target</code></pre></blockquote><p>​    常用命令</p><blockquote><pre class=" language-shell"><code class="language-shell">systemctl start nginxsystemctl stop nginxsystemctl reload nginxsystemctl status nginxsystemctl enable nginx  //设置开机自启systemctl disable nginx  //关闭开机自启</code></pre></blockquote><h3 id="四、开放必要的端口"><a href="#四、开放必要的端口" class="headerlink" title="四、开放必要的端口"></a>四、开放必要的端口</h3><ol><li><p>为nginx开放80端口</p><p> 由于linux默认开启了防火墙，nginx是访问不成功的，如果是个人学习，可以直接关闭防火墙</p></li></ol><blockquote><pre class=" language-shell"><code class="language-shell">systemctl stop firewalld</code></pre></blockquote><p>​        否则只开启指定的端口供外部访问，以下为一些端口操作命令</p><blockquote><pre class=" language-shell"><code class="language-shell">firewall-cmd --zone=public --add-port=80/tcp --permanent   //永久开放80端口firewall-cmd --reload   //重载使之生效firewall-cmd --zone= public --query-port=80/tcp   //查看是否开放firewall-cmd --zone= public --remove-port=80/tcp --permanent   //删除80端口firewall-cmd --zone=public --add-port=40000-45000/tcp --permanent  开放一段端口firewall-cmd --zone=public --list-ports  //查看开放的端口列表</code></pre></blockquote><p>​        若服务器使用的iptables，则：</p><blockquote><pre class=" language-shell"><code class="language-shell">iptables -I INPUT -p tcp --dport 80 -j ACCEPT   //开放80service iptables save  //保存策略service iptables restart  //重启防火墙iptables -D INPUT 2  // 删除规则，通过 iptables -L -n --line-number 可以显示规则和相对应的编号</code></pre></blockquote><h3 id="五、赋予用户权限"><a href="#五、赋予用户权限" class="headerlink" title="五、赋予用户权限"></a>五、赋予用户权限</h3><p>大多情况下并不建议使用root用户去操作数据，因此在使用普通用户时可能会遇到一些权限问题，以下步骤帮助用户获取nginx相关的操作权限。</p><ol><li><p>创建用户组</p><pre class=" language-shell"><code class="language-shell">sudo groupadd nginx</code></pre></li><li><p>将当前用户假如nginx用户组</p><pre class=" language-shell"><code class="language-shell">sudo usermod -g nginx username</code></pre></li><li><p>将nginx的权限给nginx用户组的用户</p><pre class=" language-shell"><code class="language-shell">sudo chown -R username:nginx /usr/local/nginx</code></pre></li><li><p>如有必要，给nginx用户组写权限</p><pre class=" language-shell"><code class="language-shell">sudo chmod g+w -R /usr/local/nginx</code></pre></li><li><p>如有必要，授予nginx目录segid权限，做用户组控制</p><pre class=" language-shell"><code class="language-shell">sudo chmod g+s -R /usr/local/nginx</code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NGINX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>正确使用SQL既是优化</title>
      <link href="articles/2020/5440082111.html"/>
      <url>articles/2020/5440082111.html</url>
      
        <content type="html"><![CDATA[<h2 id="SQL优化小结"><a href="#SQL优化小结" class="headerlink" title="SQL优化小结"></a>SQL优化小结</h2><h3 id="一、正确使用索引"><a href="#一、正确使用索引" class="headerlink" title="一、正确使用索引"></a>一、正确使用索引</h3><ol><li><p>对查询进行优化，应尽量避免全表扫描，首先应考虑在where及order by 涉及的列上建立索引</p></li><li><p>应尽量避免在where子句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：</p><pre class=" language-SQL"><code class="language-SQL">SELECT ID FROM TEST_INDEX WHERE NUM　IS NULL</code></pre><p>可以以在num上设置默认值0，确保表中null列没有null值，然后这样查询：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> ID <span class="token keyword">FROM</span> TEST_INDEX <span class="token keyword">WHERE</span> NUM <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span></code></pre></li><li><p>应尽量避免在WHERE子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描</p></li><li><p>应尽量避免在WHERE子句中使用OR来连接条件，否则只有当条件中的列都是索引字段，且等值比较时候，才能使用索引，如：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> ID <span class="token keyword">FROM</span> TEST_INDEX <span class="token keyword">WHERE</span>  NUM<span class="token operator">=</span><span class="token number">10</span> <span class="token operator">OR</span> AGE<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//使用的是index_merge</span><span class="token keyword">SELECT</span> ID <span class="token keyword">FROM</span> TEST_INDEX <span class="token keyword">WHERE</span>  NUM<span class="token operator">&lt;</span><span class="token number">10</span> <span class="token operator">OR</span> AGE<span class="token operator">></span><span class="token number">20</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//未使用索引</span></code></pre><p>可以这样查询：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> ID <span class="token keyword">FROM</span> TEST_INDEX <span class="token keyword">WHERE</span> NUM<span class="token operator">=</span><span class="token number">10</span><span class="token keyword">UNION</span> <span class="token keyword">ALL</span><span class="token keyword">SELECT</span> ID <span class="token keyword">FROM</span> TEST_INDEX <span class="token keyword">WHERE</span> NUM<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">;</span></code></pre></li><li><p>对于连续的数值能用BETWEEN就不要用IN，否则也会导致全表扫描，如</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> ID <span class="token keyword">FROM</span> TEST_INDEX <span class="token keyword">WHERE</span> NUM　<span class="token operator">IN</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>可以改为：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> ID <span class="token keyword">FROM</span> TEST_INDEX <span class="token keyword">WHERE</span> NUM <span class="token operator">BETWEEN</span> <span class="token number">1</span> <span class="token operator">AND</span> <span class="token number">3</span><span class="token punctuation">;</span></code></pre></li></ol><ol start="6"><li><p>应尽量避免在WHERE子句等号的左边进行函数、算术运算或其他表达式运算，这将导致引擎放弃使用索引。如</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> ID <span class="token keyword">FROM</span> TEST_INDEX <span class="token keyword">WHERE</span> SUBSTRING<span class="token punctuation">(</span>NUM<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">=</span><span class="token string">'sql'</span><span class="token punctuation">;</span></code></pre><p>可以改为：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> ID <span class="token keyword">FROM</span> TEST_INDEX <span class="token keyword">WHERE</span> NUM <span class="token operator">LIKE</span> sql<span class="token operator">%</span><span class="token punctuation">;</span></code></pre><p>在使用like关键字进行查询的时候，如果匹配字符串的第一个字符为”%”索引不会器作用。只有”%”不在第一个位置，索引才会起作用。</p></li><li><p>在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应让字段顺序与索引顺序相一致</p><blockquote><p>假如对col1、col2、col3创建组合索引，相当于创建了（col1）、（col1，col2）、（col1，col2，col3）3个索引</p></blockquote></li><li><p>并不是所有的列都适合做索引，离散型不高的列，即当一列数据有大量重复数据时不适合做索引，如性别、国家等有限数据列</p></li><li><p>索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率</p><p>​    </p></li><li><p>IN和EXIST的选择，in 是把外表和内表作hash 连接，而exists是对外表作loop循环，每次loop循环再对内表进行查询。其中in会使用外层查询表索引，而exist使用内层查询表索引，所以外层查询表小于子查询表，则用exists，外层查询表大于子查询表，则用in，如果外层和子查询表差不多，则爱用哪个用哪个。另外，如果查询语句使用了not in 那么内外表都进行全表扫描，没有用到索引；而not extsts 的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。</p></li></ol><hr><h3 id="二、常用SQL操作符"><a href="#二、常用SQL操作符" class="headerlink" title="二、常用SQL操作符"></a>二、常用SQL操作符</h3><ol><li><p>JOIN</p><p>包括LEFT JOIN、INNER JOIN、RIGHT JOIN、FULL JOIN等几种，我找来一张网图简单明了了说明了几个操作符的作用范围及基本使用方法，如下：</p><p><img src="https://cdn.jsdelivr.net/gh/noslime/noslime.github.io@master/source/images/sqljoins.png"></p><p>使用时应以小表驱动大表，左连接LEFT JOIN中，左表为驱动表，右表为被驱动表；右连接RIGHT JOIN中，右表为驱动表，左表为被驱动表。其中应尽量在被驱动表上建立索引。</p></li><li><p>UNION </p><p>UNION 内部的 SELECT 语句必须拥有相同数量的列。列也必须拥有相似的数据类型。同时，每条 SELECT 语句中的列的顺序必须相同。</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> column_name<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token keyword">FROM</span> table_name1<span class="token keyword">UNION</span><span class="token keyword">SELECT</span> column_name<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token keyword">FROM</span> table_name2</code></pre><p>默认地，UNION 操作符选取不同的值。如果允许重复的值，请使用 UNION ALL。</p></li></ol><hr><h3 id="三、表设计"><a href="#三、表设计" class="headerlink" title="三、表设计"></a>三、表设计</h3><ol><li><p>尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了</p></li><li><p>对于长度基本固定的列，如果该列恰好更新又特别频繁，适合char。</p></li><li><p>TIMESTAMP和 DATETIME选择</p><blockquote><p>DATETIME和 TIMESTAMP类型所占的存储空间不同，前者8字节，后者4字节。前者范围是 </p><p>1000-01-01-00:00:00 ~ 9999-12-31 23:59:59，后者范围是 1970-01-01 8:00:01 ~ 2038-01-19 </p><p>11:14:07。 所以 TIMESTAMP支持的范围比 DATETIME要小。</p><p>TIMESTAMP显示与时区有关，它把客户端插入的时间从当前时区转化为UTC（世界标准时间）进行存储。查询时，将其又转化为客户端当前时区进行返回。另外TIMESTAMP每个表允许一个自增时间戳，如：</p><pre class=" language-sql"><code class="language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> <span class="token punctuation">`</span><span class="token keyword">USER</span><span class="token punctuation">`</span> <span class="token keyword">ADD</span> <span class="token keyword">COLUMN</span> <span class="token punctuation">`</span>UTIME<span class="token punctuation">`</span> <span class="token keyword">TIMESTAMP</span> <span class="token boolean">NULL</span> <span class="token keyword">DEFAULT</span> <span class="token boolean">NULL</span> <span class="token keyword">ON</span> <span class="token keyword">UPDATE</span> <span class="token keyword">CURRENT_TIMESTAMP</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//UTIME字段插入更新数据时不需指定</span></code></pre><p>显然存储空间小且会自动切换的TIMESTAMP更方便一些，虽然表示时间范围小好多，但根据IT行业技术换代的速度，相信不用等到2038年，就已经有了更好的替换方案。</p></blockquote></li><li><p> 所有表都要指定主键，不要强制使用外键。如果没有主键或者唯一索引，update/delete 是通过所有字段来定位操作的行，相当于每行就是一次全表扫描。即使2个表的字段有明确的外键参考关系，也不建议使用 FOREIGN KEY，因为新纪录会去主键表做校验，影响性能。</p></li><li><p>对精度有要求可以用decimal。其中decimal(M,D) M表示总长度，D表示小数部分，M范围是1到65，D范围是0到30。</p><ol><li>float：浮点型，含字节数为4, 32bit，7个有效位</li><li>double：双精度实型，含字节数为8, 64bit，15个有效位</li><li>decimal：数字型，128bit，不存在精度损失，常用于银行账目计算，28个有效位。</li></ol></li><li><p>字段不要过多，取名见名思义，加注释</p><p>字段过多的表可以进行分表，如用户表USER有id、姓名、密码、地址、电话、爱好、备注等字段，可将地址、爱好、备注等不常用字段分解出另一个表USER_DETAIL。</p></li><li><p>对于经常联合查询的表，可根据需要看是否可以建立中间表存储需要联合查询的数据。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MYSQL </tag>
            
            <tag> 优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="articles/2020/2222141311.html"/>
      <url>articles/2020/2222141311.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HEXO </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
